{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Unx4NiKnfr"
      },
      "source": [
        "# 1. Training and I/O Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiUnyh55KrY_"
      },
      "source": [
        "## Setup: Installing Required Libraries\n",
        "\n",
        "Before we begin, let's install the necessary libraries. Run the following cells to install the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7IKDocnIKzE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2122877d-cf49-4db3-be3c-5b03e9a6d823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.8.2 in /usr/local/lib/python3.11/dist-packages (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (1.4.8)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.2) (1.17.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "/bin/bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n",
            "Collecting torchvision==0.17.0\n",
            "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (2.32.3)\n",
            "Collecting torch==2.2.0 (from torchvision==0.17.0)\n",
            "  Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.0) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0->torchvision==0.17.0)\n",
            "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchvision==0.17.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchvision==0.17.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchvision==0.17.0) (1.3.0)\n",
            "Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m820.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchvision-0.17.0 triton-2.2.0\n",
            "Collecting tqdm==4.66.2\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "Successfully installed tqdm-4.66.2\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib==3.8.2\n",
        "!pip install numpy==1.26.4\n",
        "!pip install torch==2.2.0\"\n",
        "!pip install torchvision==0.17.0\n",
        "!pip install tqdm==4.66.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdDItlGfK-FE"
      },
      "source": [
        "If all libraries are installed correctly, you should see their versions printed without any errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1L2BLLLL9H"
      },
      "source": [
        "\n",
        "## Problem 1 (30 points)\n",
        "\n",
        "We will work with a CNN in PyTorch to classify images. We will use the CIFAR10 dataset, which\n",
        "contains 50K 32×32 color images. The refence code is at pytorch-cifar. We will work with the ResNet-18 model, as described in **[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)**\n",
        "\n",
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH-N4iOMLsh2"
      },
      "source": [
        "Create a ResNet-18 model as defined in above reading. You can rely on existing open-source implementations. However, your code should define the layers and not just import\n",
        "the model using torch.\n",
        "\n",
        "Specifically, The first convolutional layer should have **3 input channels, 64 output channels, 3$\\times$3 kernel, with *stride=1* and *padding=1*.**\n",
        "\n",
        "Followed by 8 basic blocks in 4 sub groups (i.e. 2 basic blocks in each subgroup): \\\\\n",
        "\n",
        "\n",
        "• The first sub-group contains convolutional layer with 64 output channels, 3×3 kernel, stride=1, padding=1.\n",
        "\n",
        "• The second sub-group contains convolutional layer with 128 output channels, 3×3 kernel, stride=2,\n",
        "padding=1.\n",
        "\n",
        "• The third sub-group contains convolutional layer with 256 output channels, 3×3 kernel, stride=2,\n",
        "padding=1.\n",
        "\n",
        "• The forth sub-group contains convolutional layer with 512 output channels, 3×3 kernel, stride=2,\n",
        "padding=1.\n",
        "\n",
        "• The final linear layer is of 10 output classes.\n",
        "\n",
        "For all convolutional layers, use ReLU activation functions, and use batch normal layers to avoid covariant\n",
        "shift. Since batch-norm layers regularize the training, set bias to 0 for all the convolutional layers. Use SGD\n",
        "optimizers with 0.1 as the learning rate, momentum 0.9, weight decay 5e-4. The loss function is cross entropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g1ARVbO_VJXw"
      },
      "outputs": [],
      "source": [
        "# Relevant imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic building block for each ResNet-18 sub-group**"
      ],
      "metadata": {
        "id": "h_8BpaAe5f5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7lioPExrWfmj"
      },
      "outputs": [],
      "source": [
        "# Defining the basic block for each subgroup\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.batch_norm1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.batch_norm2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet18 Model**"
      ],
      "metadata": {
        "id": "znwfRJhx5r4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet18, self).__init__()\n",
        "        # Initial convolutional layer (3 input channels, 64 output channels)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.batch_n1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # ResNet sub-groups\n",
        "        self.layer1 = self._make_layer(64, 64, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, stride=2)\n",
        "\n",
        "        # Global average pooling and fully connected layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, stride):\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(in_channels, out_channels, stride, downsample))\n",
        "        layers.append(BasicBlock(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch_n1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4gYv3BJB1Z5d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q_CbhgWMWZv"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "Create a PyTorch program with a DataLoader that loads the images and the related labels from the The\n",
        "torchvision CIFAR10 dataset. Import CIFAR10 dataset for the torchvision package, with the following\n",
        "sequence of transformations\n",
        "\n",
        "\n",
        "    - Random cropping, with size 32×32 and padding 4\n",
        "\n",
        "    - Random horizontal flipping with a probability 0.5\n",
        "\n",
        "    - Normalize each image’s RGB channel with mean(0.4914, 0.4822, 0.4465) and variance (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "You will only need one data loader to complete this assignment.\n",
        "\n",
        "For your convenience, here are the default settings for the train loader: minibatch size of 128 and 3 IO processes (i.e., num workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def create_dataloader(data, batch_size, num_workers):\n",
        "    return torch.utils.data.DataLoader(data, batch_size,num_workers)\n",
        "\n",
        "def get_dataset(train=True, root='./data', batch_size=128, num_workers=2):\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToTensor(),  # Convert to Tensor\n",
        "      transforms.RandomCrop(32, padding=4),  # Random cropping with padding\n",
        "      transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flipping with a 50% chance\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean and std deviation\n",
        "    ])\n",
        "    if train:\n",
        "      trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "      return create_dataloader(data=trainset, batch_size=batch_size, num_workers=num_workers)\n",
        "    else:\n",
        "      testset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "      return create_dataloader(data=testset, batch_size=batch_size, num_workers=num_workers)\n"
      ],
      "metadata": {
        "id": "HRly7BB26tfr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QM59Es3NEfR"
      },
      "source": [
        "## C1: Training in Pytorch (10 points)\n",
        "\n",
        "Here the task is to create a main function that creates the **DataLoaders** *using code above* for the training set and the neural network, then you have to run for `5` epochs with a complete training phase on all minibatches of the training set.\n",
        "\n",
        "\n",
        "Write the code as device-agnostic, use the `ArgumentParser` to be able to read parameters from input, such as the use of cuda, the `data_path`, the number of dataloader workers and the optimizer (as string, eg: `sgd`).\n",
        "\n",
        "\n",
        "Calculate the per-batch training loss, value and the top-1 training accuracy of the predictions, measured on training data.\n",
        "\n",
        "\n",
        "> You don't need to submit any outputs for **C1**. Only submit relevant code for this question.\n",
        "\n",
        "> **C2-C3** will use the code of **C1**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,\n",
        "          device,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          epochs,\n",
        "          root,\n",
        "          batch_size,\n",
        "          num_workers):\n",
        "\n",
        "    # Initialize the device\n",
        "    device = torch.device(device)\n",
        "    #Initialize the model\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    train_loader = get_dataset(train=True,\n",
        "                               root=root,\n",
        "                               batch_size=batch_size,\n",
        "                               num_workers=num_workers)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Print training stats every minibatch\n",
        "            print(f'Epoch: {epoch} | Mini-Batch: {batch_idx} | Loss: {loss.item():.5f} | Accuracy: {100.*correct/total:.2f}%')"
      ],
      "metadata": {
        "id": "G9X6ZUDLAV0Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv = ['', '--use_cuda', '--data_path', './data', '--num_workers', '2', '--epochs', '5', '--optimizer', 'sgd', '--batch_size', '128']"
      ],
      "metadata": {
        "id": "wQ4sdnpsgYCk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "\n",
        "def main():\n",
        "  parser = argparse.ArgumentParser(description=\"Arguments for the ResNet18 Model for CIFAR10 Dataset\")\n",
        "  parser.add_argument('--use_cuda', action='store_true', help='Use CUDA if available')\n",
        "  parser.add_argument('--data_path', default='./data', type=str, help='Path to CIFAR10 data')\n",
        "  parser.add_argument('--num_workers', default=2, type=int, help='Number of workers for DataLoader')\n",
        "  parser.add_argument('--optimizer', default='sgd', type=str, help='Optimizer to use: sgd or adam')\n",
        "  parser.add_argument('--batch_size', default=128, type=int, help='Batch size for DataLoader')\n",
        "  parser.add_argument('--epochs', default=5, type=int, help='Number of epochs to train the model')\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  device = torch.device('cuda' if args.use_cuda and torch.cuda.is_available() else 'cpu')\n",
        "  model = ResNet18()\n",
        "  #print(summary(model, (32,32,3)))\n",
        "  if args.optimizer == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "  elif args.optimizer == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  train_model(model=model,\n",
        "              device=device,\n",
        "              optimizer=optimizer,\n",
        "              criterion=nn.CrossEntropyLoss(),\n",
        "              epochs=args.epochs,\n",
        "              root=args.data_path,\n",
        "              batch_size=args.batch_size,\n",
        "              num_workers=args.num_workers)\n"
      ],
      "metadata": {
        "id": "N9nxuTRM_kGF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eoMGjylE0Bj",
        "outputId": "48edd7c1-737b-4460-a0d6-4ae9c3b42791"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 30923966.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Epoch: 0 | Mini-Batch: 0 | Loss: 2.40993 | Accuracy: 7.03%\n",
            "Epoch: 0 | Mini-Batch: 1 | Loss: 2.81809 | Accuracy: 9.77%\n",
            "Epoch: 0 | Mini-Batch: 2 | Loss: 4.13312 | Accuracy: 10.94%\n",
            "Epoch: 0 | Mini-Batch: 3 | Loss: 5.08594 | Accuracy: 11.13%\n",
            "Epoch: 0 | Mini-Batch: 4 | Loss: 3.21116 | Accuracy: 11.09%\n",
            "Epoch: 0 | Mini-Batch: 5 | Loss: 2.99567 | Accuracy: 11.98%\n",
            "Epoch: 0 | Mini-Batch: 6 | Loss: 3.20716 | Accuracy: 12.05%\n",
            "Epoch: 0 | Mini-Batch: 7 | Loss: 3.91432 | Accuracy: 11.33%\n",
            "Epoch: 0 | Mini-Batch: 8 | Loss: 3.02344 | Accuracy: 11.89%\n",
            "Epoch: 0 | Mini-Batch: 9 | Loss: 3.46600 | Accuracy: 12.11%\n",
            "Epoch: 0 | Mini-Batch: 10 | Loss: 3.67571 | Accuracy: 11.72%\n",
            "Epoch: 0 | Mini-Batch: 11 | Loss: 4.11095 | Accuracy: 11.59%\n",
            "Epoch: 0 | Mini-Batch: 12 | Loss: 3.29164 | Accuracy: 11.42%\n",
            "Epoch: 0 | Mini-Batch: 13 | Loss: 2.99919 | Accuracy: 11.89%\n",
            "Epoch: 0 | Mini-Batch: 14 | Loss: 2.84890 | Accuracy: 12.29%\n",
            "Epoch: 0 | Mini-Batch: 15 | Loss: 2.65907 | Accuracy: 12.55%\n",
            "Epoch: 0 | Mini-Batch: 16 | Loss: 3.59991 | Accuracy: 12.68%\n",
            "Epoch: 0 | Mini-Batch: 17 | Loss: 2.68792 | Accuracy: 13.15%\n",
            "Epoch: 0 | Mini-Batch: 18 | Loss: 2.79283 | Accuracy: 13.12%\n",
            "Epoch: 0 | Mini-Batch: 19 | Loss: 2.36267 | Accuracy: 13.20%\n",
            "Epoch: 0 | Mini-Batch: 20 | Loss: 2.56098 | Accuracy: 13.17%\n",
            "Epoch: 0 | Mini-Batch: 21 | Loss: 2.47645 | Accuracy: 12.86%\n",
            "Epoch: 0 | Mini-Batch: 22 | Loss: 2.48868 | Accuracy: 12.98%\n",
            "Epoch: 0 | Mini-Batch: 23 | Loss: 2.23686 | Accuracy: 13.38%\n",
            "Epoch: 0 | Mini-Batch: 24 | Loss: 2.32304 | Accuracy: 13.62%\n",
            "Epoch: 0 | Mini-Batch: 25 | Loss: 2.55167 | Accuracy: 13.52%\n",
            "Epoch: 0 | Mini-Batch: 26 | Loss: 2.24286 | Accuracy: 13.57%\n",
            "Epoch: 0 | Mini-Batch: 27 | Loss: 2.15655 | Accuracy: 13.67%\n",
            "Epoch: 0 | Mini-Batch: 28 | Loss: 2.21311 | Accuracy: 13.87%\n",
            "Epoch: 0 | Mini-Batch: 29 | Loss: 2.21033 | Accuracy: 14.14%\n",
            "Epoch: 0 | Mini-Batch: 30 | Loss: 2.30082 | Accuracy: 14.39%\n",
            "Epoch: 0 | Mini-Batch: 31 | Loss: 2.51611 | Accuracy: 14.40%\n",
            "Epoch: 0 | Mini-Batch: 32 | Loss: 2.27343 | Accuracy: 14.44%\n",
            "Epoch: 0 | Mini-Batch: 33 | Loss: 2.53741 | Accuracy: 14.32%\n",
            "Epoch: 0 | Mini-Batch: 34 | Loss: 2.40850 | Accuracy: 14.31%\n",
            "Epoch: 0 | Mini-Batch: 35 | Loss: 2.06134 | Accuracy: 14.50%\n",
            "Epoch: 0 | Mini-Batch: 36 | Loss: 2.37043 | Accuracy: 14.65%\n",
            "Epoch: 0 | Mini-Batch: 37 | Loss: 2.21099 | Accuracy: 14.80%\n",
            "Epoch: 0 | Mini-Batch: 38 | Loss: 2.24727 | Accuracy: 15.00%\n",
            "Epoch: 0 | Mini-Batch: 39 | Loss: 2.33817 | Accuracy: 15.08%\n",
            "Epoch: 0 | Mini-Batch: 40 | Loss: 2.19025 | Accuracy: 15.36%\n",
            "Epoch: 0 | Mini-Batch: 41 | Loss: 2.53515 | Accuracy: 15.44%\n",
            "Epoch: 0 | Mini-Batch: 42 | Loss: 2.42488 | Accuracy: 15.35%\n",
            "Epoch: 0 | Mini-Batch: 43 | Loss: 2.26142 | Accuracy: 15.34%\n",
            "Epoch: 0 | Mini-Batch: 44 | Loss: 2.17679 | Accuracy: 15.40%\n",
            "Epoch: 0 | Mini-Batch: 45 | Loss: 2.39354 | Accuracy: 15.34%\n",
            "Epoch: 0 | Mini-Batch: 46 | Loss: 2.14969 | Accuracy: 15.31%\n",
            "Epoch: 0 | Mini-Batch: 47 | Loss: 1.93622 | Accuracy: 15.45%\n",
            "Epoch: 0 | Mini-Batch: 48 | Loss: 2.32873 | Accuracy: 15.37%\n",
            "Epoch: 0 | Mini-Batch: 49 | Loss: 2.19105 | Accuracy: 15.44%\n",
            "Epoch: 0 | Mini-Batch: 50 | Loss: 2.22885 | Accuracy: 15.58%\n",
            "Epoch: 0 | Mini-Batch: 51 | Loss: 2.08080 | Accuracy: 15.73%\n",
            "Epoch: 0 | Mini-Batch: 52 | Loss: 2.14779 | Accuracy: 15.76%\n",
            "Epoch: 0 | Mini-Batch: 53 | Loss: 2.08214 | Accuracy: 15.84%\n",
            "Epoch: 0 | Mini-Batch: 54 | Loss: 1.98026 | Accuracy: 15.99%\n",
            "Epoch: 0 | Mini-Batch: 55 | Loss: 2.11314 | Accuracy: 16.06%\n",
            "Epoch: 0 | Mini-Batch: 56 | Loss: 1.96666 | Accuracy: 16.16%\n",
            "Epoch: 0 | Mini-Batch: 57 | Loss: 2.16110 | Accuracy: 16.29%\n",
            "Epoch: 0 | Mini-Batch: 58 | Loss: 1.99883 | Accuracy: 16.38%\n",
            "Epoch: 0 | Mini-Batch: 59 | Loss: 1.95407 | Accuracy: 16.54%\n",
            "Epoch: 0 | Mini-Batch: 60 | Loss: 1.98698 | Accuracy: 16.71%\n",
            "Epoch: 0 | Mini-Batch: 61 | Loss: 2.10209 | Accuracy: 16.86%\n",
            "Epoch: 0 | Mini-Batch: 62 | Loss: 2.06574 | Accuracy: 16.87%\n",
            "Epoch: 0 | Mini-Batch: 63 | Loss: 2.09705 | Accuracy: 16.99%\n",
            "Epoch: 0 | Mini-Batch: 64 | Loss: 2.25016 | Accuracy: 17.07%\n",
            "Epoch: 0 | Mini-Batch: 65 | Loss: 2.02479 | Accuracy: 17.15%\n",
            "Epoch: 0 | Mini-Batch: 66 | Loss: 2.12247 | Accuracy: 17.33%\n",
            "Epoch: 0 | Mini-Batch: 67 | Loss: 2.08139 | Accuracy: 17.38%\n",
            "Epoch: 0 | Mini-Batch: 68 | Loss: 2.01119 | Accuracy: 17.46%\n",
            "Epoch: 0 | Mini-Batch: 69 | Loss: 2.01792 | Accuracy: 17.57%\n",
            "Epoch: 0 | Mini-Batch: 70 | Loss: 2.10869 | Accuracy: 17.58%\n",
            "Epoch: 0 | Mini-Batch: 71 | Loss: 2.07709 | Accuracy: 17.60%\n",
            "Epoch: 0 | Mini-Batch: 72 | Loss: 1.88824 | Accuracy: 17.80%\n",
            "Epoch: 0 | Mini-Batch: 73 | Loss: 1.97421 | Accuracy: 17.92%\n",
            "Epoch: 0 | Mini-Batch: 74 | Loss: 2.10860 | Accuracy: 17.95%\n",
            "Epoch: 0 | Mini-Batch: 75 | Loss: 2.00764 | Accuracy: 18.00%\n",
            "Epoch: 0 | Mini-Batch: 76 | Loss: 1.95179 | Accuracy: 18.02%\n",
            "Epoch: 0 | Mini-Batch: 77 | Loss: 2.05174 | Accuracy: 18.04%\n",
            "Epoch: 0 | Mini-Batch: 78 | Loss: 2.09831 | Accuracy: 18.18%\n",
            "Epoch: 0 | Mini-Batch: 79 | Loss: 2.03625 | Accuracy: 18.25%\n",
            "Epoch: 0 | Mini-Batch: 80 | Loss: 1.96588 | Accuracy: 18.31%\n",
            "Epoch: 0 | Mini-Batch: 81 | Loss: 2.05310 | Accuracy: 18.34%\n",
            "Epoch: 0 | Mini-Batch: 82 | Loss: 2.06860 | Accuracy: 18.40%\n",
            "Epoch: 0 | Mini-Batch: 83 | Loss: 2.00769 | Accuracy: 18.50%\n",
            "Epoch: 0 | Mini-Batch: 84 | Loss: 2.11385 | Accuracy: 18.54%\n",
            "Epoch: 0 | Mini-Batch: 85 | Loss: 1.93094 | Accuracy: 18.57%\n",
            "Epoch: 0 | Mini-Batch: 86 | Loss: 1.84144 | Accuracy: 18.71%\n",
            "Epoch: 0 | Mini-Batch: 87 | Loss: 1.86344 | Accuracy: 18.76%\n",
            "Epoch: 0 | Mini-Batch: 88 | Loss: 1.86680 | Accuracy: 18.92%\n",
            "Epoch: 0 | Mini-Batch: 89 | Loss: 1.91275 | Accuracy: 19.05%\n",
            "Epoch: 0 | Mini-Batch: 90 | Loss: 1.99531 | Accuracy: 19.06%\n",
            "Epoch: 0 | Mini-Batch: 91 | Loss: 2.05237 | Accuracy: 19.10%\n",
            "Epoch: 0 | Mini-Batch: 92 | Loss: 1.96919 | Accuracy: 19.13%\n",
            "Epoch: 0 | Mini-Batch: 93 | Loss: 1.88595 | Accuracy: 19.18%\n",
            "Epoch: 0 | Mini-Batch: 94 | Loss: 1.99111 | Accuracy: 19.26%\n",
            "Epoch: 0 | Mini-Batch: 95 | Loss: 1.87808 | Accuracy: 19.38%\n",
            "Epoch: 0 | Mini-Batch: 96 | Loss: 1.88039 | Accuracy: 19.42%\n",
            "Epoch: 0 | Mini-Batch: 97 | Loss: 1.75446 | Accuracy: 19.53%\n",
            "Epoch: 0 | Mini-Batch: 98 | Loss: 1.98179 | Accuracy: 19.63%\n",
            "Epoch: 0 | Mini-Batch: 99 | Loss: 1.93982 | Accuracy: 19.70%\n",
            "Epoch: 0 | Mini-Batch: 100 | Loss: 1.87992 | Accuracy: 19.72%\n",
            "Epoch: 0 | Mini-Batch: 101 | Loss: 1.94038 | Accuracy: 19.72%\n",
            "Epoch: 0 | Mini-Batch: 102 | Loss: 1.72624 | Accuracy: 19.89%\n",
            "Epoch: 0 | Mini-Batch: 103 | Loss: 1.93482 | Accuracy: 19.98%\n",
            "Epoch: 0 | Mini-Batch: 104 | Loss: 1.81655 | Accuracy: 20.12%\n",
            "Epoch: 0 | Mini-Batch: 105 | Loss: 1.95119 | Accuracy: 20.14%\n",
            "Epoch: 0 | Mini-Batch: 106 | Loss: 1.91210 | Accuracy: 20.23%\n",
            "Epoch: 0 | Mini-Batch: 107 | Loss: 1.86380 | Accuracy: 20.35%\n",
            "Epoch: 0 | Mini-Batch: 108 | Loss: 1.97716 | Accuracy: 20.38%\n",
            "Epoch: 0 | Mini-Batch: 109 | Loss: 1.91703 | Accuracy: 20.44%\n",
            "Epoch: 0 | Mini-Batch: 110 | Loss: 1.99895 | Accuracy: 20.52%\n",
            "Epoch: 0 | Mini-Batch: 111 | Loss: 1.75944 | Accuracy: 20.60%\n",
            "Epoch: 0 | Mini-Batch: 112 | Loss: 2.00578 | Accuracy: 20.63%\n",
            "Epoch: 0 | Mini-Batch: 113 | Loss: 1.82963 | Accuracy: 20.72%\n",
            "Epoch: 0 | Mini-Batch: 114 | Loss: 1.85211 | Accuracy: 20.85%\n",
            "Epoch: 0 | Mini-Batch: 115 | Loss: 1.91232 | Accuracy: 20.92%\n",
            "Epoch: 0 | Mini-Batch: 116 | Loss: 1.81976 | Accuracy: 20.94%\n",
            "Epoch: 0 | Mini-Batch: 117 | Loss: 1.99004 | Accuracy: 20.95%\n",
            "Epoch: 0 | Mini-Batch: 118 | Loss: 1.96266 | Accuracy: 21.00%\n",
            "Epoch: 0 | Mini-Batch: 119 | Loss: 1.88682 | Accuracy: 21.04%\n",
            "Epoch: 0 | Mini-Batch: 120 | Loss: 1.79947 | Accuracy: 21.15%\n",
            "Epoch: 0 | Mini-Batch: 121 | Loss: 1.78723 | Accuracy: 21.20%\n",
            "Epoch: 0 | Mini-Batch: 122 | Loss: 1.74819 | Accuracy: 21.30%\n",
            "Epoch: 0 | Mini-Batch: 123 | Loss: 1.84874 | Accuracy: 21.38%\n",
            "Epoch: 0 | Mini-Batch: 124 | Loss: 1.83057 | Accuracy: 21.49%\n",
            "Epoch: 0 | Mini-Batch: 125 | Loss: 1.90450 | Accuracy: 21.56%\n",
            "Epoch: 0 | Mini-Batch: 126 | Loss: 1.98349 | Accuracy: 21.60%\n",
            "Epoch: 0 | Mini-Batch: 127 | Loss: 1.73592 | Accuracy: 21.72%\n",
            "Epoch: 0 | Mini-Batch: 128 | Loss: 1.76818 | Accuracy: 21.85%\n",
            "Epoch: 0 | Mini-Batch: 129 | Loss: 1.91986 | Accuracy: 21.89%\n",
            "Epoch: 0 | Mini-Batch: 130 | Loss: 1.83852 | Accuracy: 21.98%\n",
            "Epoch: 0 | Mini-Batch: 131 | Loss: 1.78136 | Accuracy: 22.06%\n",
            "Epoch: 0 | Mini-Batch: 132 | Loss: 1.86268 | Accuracy: 22.11%\n",
            "Epoch: 0 | Mini-Batch: 133 | Loss: 1.94397 | Accuracy: 22.13%\n",
            "Epoch: 0 | Mini-Batch: 134 | Loss: 1.83496 | Accuracy: 22.20%\n",
            "Epoch: 0 | Mini-Batch: 135 | Loss: 1.86433 | Accuracy: 22.25%\n",
            "Epoch: 0 | Mini-Batch: 136 | Loss: 1.81316 | Accuracy: 22.30%\n",
            "Epoch: 0 | Mini-Batch: 137 | Loss: 1.91526 | Accuracy: 22.32%\n",
            "Epoch: 0 | Mini-Batch: 138 | Loss: 1.88136 | Accuracy: 22.39%\n",
            "Epoch: 0 | Mini-Batch: 139 | Loss: 1.91954 | Accuracy: 22.42%\n",
            "Epoch: 0 | Mini-Batch: 140 | Loss: 1.78796 | Accuracy: 22.46%\n",
            "Epoch: 0 | Mini-Batch: 141 | Loss: 1.84059 | Accuracy: 22.56%\n",
            "Epoch: 0 | Mini-Batch: 142 | Loss: 1.96382 | Accuracy: 22.56%\n",
            "Epoch: 0 | Mini-Batch: 143 | Loss: 1.71787 | Accuracy: 22.62%\n",
            "Epoch: 0 | Mini-Batch: 144 | Loss: 1.84656 | Accuracy: 22.67%\n",
            "Epoch: 0 | Mini-Batch: 145 | Loss: 1.72425 | Accuracy: 22.77%\n",
            "Epoch: 0 | Mini-Batch: 146 | Loss: 1.84614 | Accuracy: 22.82%\n",
            "Epoch: 0 | Mini-Batch: 147 | Loss: 1.94565 | Accuracy: 22.83%\n",
            "Epoch: 0 | Mini-Batch: 148 | Loss: 1.83562 | Accuracy: 22.88%\n",
            "Epoch: 0 | Mini-Batch: 149 | Loss: 1.81062 | Accuracy: 22.99%\n",
            "Epoch: 0 | Mini-Batch: 150 | Loss: 1.77638 | Accuracy: 23.06%\n",
            "Epoch: 0 | Mini-Batch: 151 | Loss: 1.77219 | Accuracy: 23.13%\n",
            "Epoch: 0 | Mini-Batch: 152 | Loss: 1.73885 | Accuracy: 23.22%\n",
            "Epoch: 0 | Mini-Batch: 153 | Loss: 1.70570 | Accuracy: 23.28%\n",
            "Epoch: 0 | Mini-Batch: 154 | Loss: 1.64476 | Accuracy: 23.37%\n",
            "Epoch: 0 | Mini-Batch: 155 | Loss: 1.75736 | Accuracy: 23.43%\n",
            "Epoch: 0 | Mini-Batch: 156 | Loss: 1.80938 | Accuracy: 23.48%\n",
            "Epoch: 0 | Mini-Batch: 157 | Loss: 1.99359 | Accuracy: 23.59%\n",
            "Epoch: 0 | Mini-Batch: 158 | Loss: 1.72529 | Accuracy: 23.64%\n",
            "Epoch: 0 | Mini-Batch: 159 | Loss: 1.80443 | Accuracy: 23.67%\n",
            "Epoch: 0 | Mini-Batch: 160 | Loss: 1.76578 | Accuracy: 23.75%\n",
            "Epoch: 0 | Mini-Batch: 161 | Loss: 1.65711 | Accuracy: 23.88%\n",
            "Epoch: 0 | Mini-Batch: 162 | Loss: 1.86003 | Accuracy: 23.96%\n",
            "Epoch: 0 | Mini-Batch: 163 | Loss: 1.82768 | Accuracy: 24.01%\n",
            "Epoch: 0 | Mini-Batch: 164 | Loss: 1.83022 | Accuracy: 24.05%\n",
            "Epoch: 0 | Mini-Batch: 165 | Loss: 1.75886 | Accuracy: 24.12%\n",
            "Epoch: 0 | Mini-Batch: 166 | Loss: 1.75918 | Accuracy: 24.16%\n",
            "Epoch: 0 | Mini-Batch: 167 | Loss: 1.84404 | Accuracy: 24.24%\n",
            "Epoch: 0 | Mini-Batch: 168 | Loss: 1.89110 | Accuracy: 24.27%\n",
            "Epoch: 0 | Mini-Batch: 169 | Loss: 1.78039 | Accuracy: 24.35%\n",
            "Epoch: 0 | Mini-Batch: 170 | Loss: 1.77215 | Accuracy: 24.42%\n",
            "Epoch: 0 | Mini-Batch: 171 | Loss: 1.85328 | Accuracy: 24.45%\n",
            "Epoch: 0 | Mini-Batch: 172 | Loss: 1.81054 | Accuracy: 24.52%\n",
            "Epoch: 0 | Mini-Batch: 173 | Loss: 1.72757 | Accuracy: 24.57%\n",
            "Epoch: 0 | Mini-Batch: 174 | Loss: 1.69957 | Accuracy: 24.65%\n",
            "Epoch: 0 | Mini-Batch: 175 | Loss: 1.79677 | Accuracy: 24.68%\n",
            "Epoch: 0 | Mini-Batch: 176 | Loss: 1.88403 | Accuracy: 24.73%\n",
            "Epoch: 0 | Mini-Batch: 177 | Loss: 1.69487 | Accuracy: 24.81%\n",
            "Epoch: 0 | Mini-Batch: 178 | Loss: 1.80819 | Accuracy: 24.85%\n",
            "Epoch: 0 | Mini-Batch: 179 | Loss: 1.87967 | Accuracy: 24.87%\n",
            "Epoch: 0 | Mini-Batch: 180 | Loss: 1.72273 | Accuracy: 24.93%\n",
            "Epoch: 0 | Mini-Batch: 181 | Loss: 1.80507 | Accuracy: 24.97%\n",
            "Epoch: 0 | Mini-Batch: 182 | Loss: 1.75838 | Accuracy: 24.99%\n",
            "Epoch: 0 | Mini-Batch: 183 | Loss: 1.94210 | Accuracy: 25.03%\n",
            "Epoch: 0 | Mini-Batch: 184 | Loss: 1.65836 | Accuracy: 25.11%\n",
            "Epoch: 0 | Mini-Batch: 185 | Loss: 1.80042 | Accuracy: 25.16%\n",
            "Epoch: 0 | Mini-Batch: 186 | Loss: 1.77960 | Accuracy: 25.22%\n",
            "Epoch: 0 | Mini-Batch: 187 | Loss: 1.70451 | Accuracy: 25.26%\n",
            "Epoch: 0 | Mini-Batch: 188 | Loss: 1.78468 | Accuracy: 25.32%\n",
            "Epoch: 0 | Mini-Batch: 189 | Loss: 1.89322 | Accuracy: 25.38%\n",
            "Epoch: 0 | Mini-Batch: 190 | Loss: 1.67142 | Accuracy: 25.45%\n",
            "Epoch: 0 | Mini-Batch: 191 | Loss: 1.71851 | Accuracy: 25.50%\n",
            "Epoch: 0 | Mini-Batch: 192 | Loss: 1.74242 | Accuracy: 25.54%\n",
            "Epoch: 0 | Mini-Batch: 193 | Loss: 1.72132 | Accuracy: 25.59%\n",
            "Epoch: 0 | Mini-Batch: 194 | Loss: 1.77110 | Accuracy: 25.66%\n",
            "Epoch: 0 | Mini-Batch: 195 | Loss: 1.62407 | Accuracy: 25.73%\n",
            "Epoch: 0 | Mini-Batch: 196 | Loss: 1.51050 | Accuracy: 25.83%\n",
            "Epoch: 0 | Mini-Batch: 197 | Loss: 1.63965 | Accuracy: 25.88%\n",
            "Epoch: 0 | Mini-Batch: 198 | Loss: 1.68423 | Accuracy: 25.94%\n",
            "Epoch: 0 | Mini-Batch: 199 | Loss: 1.77150 | Accuracy: 25.96%\n",
            "Epoch: 0 | Mini-Batch: 200 | Loss: 1.79925 | Accuracy: 26.01%\n",
            "Epoch: 0 | Mini-Batch: 201 | Loss: 1.72079 | Accuracy: 26.08%\n",
            "Epoch: 0 | Mini-Batch: 202 | Loss: 1.71723 | Accuracy: 26.13%\n",
            "Epoch: 0 | Mini-Batch: 203 | Loss: 1.72982 | Accuracy: 26.18%\n",
            "Epoch: 0 | Mini-Batch: 204 | Loss: 1.82749 | Accuracy: 26.17%\n",
            "Epoch: 0 | Mini-Batch: 205 | Loss: 1.74212 | Accuracy: 26.19%\n",
            "Epoch: 0 | Mini-Batch: 206 | Loss: 1.69753 | Accuracy: 26.23%\n",
            "Epoch: 0 | Mini-Batch: 207 | Loss: 1.72620 | Accuracy: 26.27%\n",
            "Epoch: 0 | Mini-Batch: 208 | Loss: 1.78093 | Accuracy: 26.29%\n",
            "Epoch: 0 | Mini-Batch: 209 | Loss: 1.73106 | Accuracy: 26.31%\n",
            "Epoch: 0 | Mini-Batch: 210 | Loss: 1.75036 | Accuracy: 26.37%\n",
            "Epoch: 0 | Mini-Batch: 211 | Loss: 1.78720 | Accuracy: 26.37%\n",
            "Epoch: 0 | Mini-Batch: 212 | Loss: 1.68900 | Accuracy: 26.41%\n",
            "Epoch: 0 | Mini-Batch: 213 | Loss: 1.64456 | Accuracy: 26.47%\n",
            "Epoch: 0 | Mini-Batch: 214 | Loss: 1.62976 | Accuracy: 26.52%\n",
            "Epoch: 0 | Mini-Batch: 215 | Loss: 1.71661 | Accuracy: 26.55%\n",
            "Epoch: 0 | Mini-Batch: 216 | Loss: 1.64547 | Accuracy: 26.59%\n",
            "Epoch: 0 | Mini-Batch: 217 | Loss: 1.80129 | Accuracy: 26.62%\n",
            "Epoch: 0 | Mini-Batch: 218 | Loss: 1.70394 | Accuracy: 26.66%\n",
            "Epoch: 0 | Mini-Batch: 219 | Loss: 1.78965 | Accuracy: 26.69%\n",
            "Epoch: 0 | Mini-Batch: 220 | Loss: 1.76540 | Accuracy: 26.72%\n",
            "Epoch: 0 | Mini-Batch: 221 | Loss: 1.74145 | Accuracy: 26.75%\n",
            "Epoch: 0 | Mini-Batch: 222 | Loss: 1.86565 | Accuracy: 26.79%\n",
            "Epoch: 0 | Mini-Batch: 223 | Loss: 1.75947 | Accuracy: 26.85%\n",
            "Epoch: 0 | Mini-Batch: 224 | Loss: 1.68522 | Accuracy: 26.89%\n",
            "Epoch: 0 | Mini-Batch: 225 | Loss: 1.69924 | Accuracy: 26.90%\n",
            "Epoch: 0 | Mini-Batch: 226 | Loss: 1.72060 | Accuracy: 26.96%\n",
            "Epoch: 0 | Mini-Batch: 227 | Loss: 1.61125 | Accuracy: 27.03%\n",
            "Epoch: 0 | Mini-Batch: 228 | Loss: 1.57592 | Accuracy: 27.10%\n",
            "Epoch: 0 | Mini-Batch: 229 | Loss: 1.65651 | Accuracy: 27.16%\n",
            "Epoch: 0 | Mini-Batch: 230 | Loss: 1.60705 | Accuracy: 27.22%\n",
            "Epoch: 0 | Mini-Batch: 231 | Loss: 1.59750 | Accuracy: 27.25%\n",
            "Epoch: 0 | Mini-Batch: 232 | Loss: 1.86842 | Accuracy: 27.26%\n",
            "Epoch: 0 | Mini-Batch: 233 | Loss: 1.63627 | Accuracy: 27.31%\n",
            "Epoch: 0 | Mini-Batch: 234 | Loss: 1.87582 | Accuracy: 27.35%\n",
            "Epoch: 0 | Mini-Batch: 235 | Loss: 1.73874 | Accuracy: 27.38%\n",
            "Epoch: 0 | Mini-Batch: 236 | Loss: 1.70800 | Accuracy: 27.41%\n",
            "Epoch: 0 | Mini-Batch: 237 | Loss: 1.67238 | Accuracy: 27.42%\n",
            "Epoch: 0 | Mini-Batch: 238 | Loss: 1.53414 | Accuracy: 27.49%\n",
            "Epoch: 0 | Mini-Batch: 239 | Loss: 1.68029 | Accuracy: 27.52%\n",
            "Epoch: 0 | Mini-Batch: 240 | Loss: 1.64807 | Accuracy: 27.56%\n",
            "Epoch: 0 | Mini-Batch: 241 | Loss: 1.75329 | Accuracy: 27.57%\n",
            "Epoch: 0 | Mini-Batch: 242 | Loss: 1.69829 | Accuracy: 27.61%\n",
            "Epoch: 0 | Mini-Batch: 243 | Loss: 1.60000 | Accuracy: 27.67%\n",
            "Epoch: 0 | Mini-Batch: 244 | Loss: 1.71031 | Accuracy: 27.73%\n",
            "Epoch: 0 | Mini-Batch: 245 | Loss: 1.67574 | Accuracy: 27.78%\n",
            "Epoch: 0 | Mini-Batch: 246 | Loss: 1.56716 | Accuracy: 27.83%\n",
            "Epoch: 0 | Mini-Batch: 247 | Loss: 1.64657 | Accuracy: 27.87%\n",
            "Epoch: 0 | Mini-Batch: 248 | Loss: 1.61831 | Accuracy: 27.92%\n",
            "Epoch: 0 | Mini-Batch: 249 | Loss: 1.52014 | Accuracy: 27.97%\n",
            "Epoch: 0 | Mini-Batch: 250 | Loss: 1.74876 | Accuracy: 28.01%\n",
            "Epoch: 0 | Mini-Batch: 251 | Loss: 1.61019 | Accuracy: 28.04%\n",
            "Epoch: 0 | Mini-Batch: 252 | Loss: 1.69486 | Accuracy: 28.07%\n",
            "Epoch: 0 | Mini-Batch: 253 | Loss: 1.70323 | Accuracy: 28.08%\n",
            "Epoch: 0 | Mini-Batch: 254 | Loss: 1.55288 | Accuracy: 28.14%\n",
            "Epoch: 0 | Mini-Batch: 255 | Loss: 1.59169 | Accuracy: 28.18%\n",
            "Epoch: 0 | Mini-Batch: 256 | Loss: 1.75972 | Accuracy: 28.22%\n",
            "Epoch: 0 | Mini-Batch: 257 | Loss: 1.86415 | Accuracy: 28.23%\n",
            "Epoch: 0 | Mini-Batch: 258 | Loss: 1.79443 | Accuracy: 28.26%\n",
            "Epoch: 0 | Mini-Batch: 259 | Loss: 1.62995 | Accuracy: 28.32%\n",
            "Epoch: 0 | Mini-Batch: 260 | Loss: 1.56424 | Accuracy: 28.36%\n",
            "Epoch: 0 | Mini-Batch: 261 | Loss: 1.63995 | Accuracy: 28.38%\n",
            "Epoch: 0 | Mini-Batch: 262 | Loss: 1.86011 | Accuracy: 28.41%\n",
            "Epoch: 0 | Mini-Batch: 263 | Loss: 1.67279 | Accuracy: 28.44%\n",
            "Epoch: 0 | Mini-Batch: 264 | Loss: 1.71223 | Accuracy: 28.46%\n",
            "Epoch: 0 | Mini-Batch: 265 | Loss: 1.78305 | Accuracy: 28.48%\n",
            "Epoch: 0 | Mini-Batch: 266 | Loss: 1.69509 | Accuracy: 28.50%\n",
            "Epoch: 0 | Mini-Batch: 267 | Loss: 1.71888 | Accuracy: 28.51%\n",
            "Epoch: 0 | Mini-Batch: 268 | Loss: 1.74840 | Accuracy: 28.51%\n",
            "Epoch: 0 | Mini-Batch: 269 | Loss: 1.64044 | Accuracy: 28.54%\n",
            "Epoch: 0 | Mini-Batch: 270 | Loss: 1.81195 | Accuracy: 28.55%\n",
            "Epoch: 0 | Mini-Batch: 271 | Loss: 1.73391 | Accuracy: 28.58%\n",
            "Epoch: 0 | Mini-Batch: 272 | Loss: 1.73082 | Accuracy: 28.60%\n",
            "Epoch: 0 | Mini-Batch: 273 | Loss: 1.70046 | Accuracy: 28.63%\n",
            "Epoch: 0 | Mini-Batch: 274 | Loss: 1.61582 | Accuracy: 28.67%\n",
            "Epoch: 0 | Mini-Batch: 275 | Loss: 1.65217 | Accuracy: 28.70%\n",
            "Epoch: 0 | Mini-Batch: 276 | Loss: 1.76054 | Accuracy: 28.73%\n",
            "Epoch: 0 | Mini-Batch: 277 | Loss: 1.71990 | Accuracy: 28.76%\n",
            "Epoch: 0 | Mini-Batch: 278 | Loss: 1.71372 | Accuracy: 28.77%\n",
            "Epoch: 0 | Mini-Batch: 279 | Loss: 1.55328 | Accuracy: 28.81%\n",
            "Epoch: 0 | Mini-Batch: 280 | Loss: 1.62683 | Accuracy: 28.83%\n",
            "Epoch: 0 | Mini-Batch: 281 | Loss: 1.78448 | Accuracy: 28.85%\n",
            "Epoch: 0 | Mini-Batch: 282 | Loss: 1.61978 | Accuracy: 28.87%\n",
            "Epoch: 0 | Mini-Batch: 283 | Loss: 1.56869 | Accuracy: 28.91%\n",
            "Epoch: 0 | Mini-Batch: 284 | Loss: 1.70772 | Accuracy: 28.94%\n",
            "Epoch: 0 | Mini-Batch: 285 | Loss: 1.55414 | Accuracy: 28.96%\n",
            "Epoch: 0 | Mini-Batch: 286 | Loss: 1.67952 | Accuracy: 28.97%\n",
            "Epoch: 0 | Mini-Batch: 287 | Loss: 1.65267 | Accuracy: 29.02%\n",
            "Epoch: 0 | Mini-Batch: 288 | Loss: 1.65575 | Accuracy: 29.06%\n",
            "Epoch: 0 | Mini-Batch: 289 | Loss: 1.67850 | Accuracy: 29.10%\n",
            "Epoch: 0 | Mini-Batch: 290 | Loss: 1.72016 | Accuracy: 29.10%\n",
            "Epoch: 0 | Mini-Batch: 291 | Loss: 1.57037 | Accuracy: 29.14%\n",
            "Epoch: 0 | Mini-Batch: 292 | Loss: 1.72819 | Accuracy: 29.18%\n",
            "Epoch: 0 | Mini-Batch: 293 | Loss: 1.61822 | Accuracy: 29.22%\n",
            "Epoch: 0 | Mini-Batch: 294 | Loss: 1.71209 | Accuracy: 29.25%\n",
            "Epoch: 0 | Mini-Batch: 295 | Loss: 1.57568 | Accuracy: 29.29%\n",
            "Epoch: 0 | Mini-Batch: 296 | Loss: 1.68844 | Accuracy: 29.32%\n",
            "Epoch: 0 | Mini-Batch: 297 | Loss: 1.64129 | Accuracy: 29.36%\n",
            "Epoch: 0 | Mini-Batch: 298 | Loss: 1.59419 | Accuracy: 29.38%\n",
            "Epoch: 0 | Mini-Batch: 299 | Loss: 1.64757 | Accuracy: 29.40%\n",
            "Epoch: 0 | Mini-Batch: 300 | Loss: 1.64542 | Accuracy: 29.44%\n",
            "Epoch: 0 | Mini-Batch: 301 | Loss: 1.53092 | Accuracy: 29.49%\n",
            "Epoch: 0 | Mini-Batch: 302 | Loss: 1.55865 | Accuracy: 29.52%\n",
            "Epoch: 0 | Mini-Batch: 303 | Loss: 1.70244 | Accuracy: 29.55%\n",
            "Epoch: 0 | Mini-Batch: 304 | Loss: 1.62150 | Accuracy: 29.58%\n",
            "Epoch: 0 | Mini-Batch: 305 | Loss: 1.55431 | Accuracy: 29.61%\n",
            "Epoch: 0 | Mini-Batch: 306 | Loss: 1.74139 | Accuracy: 29.62%\n",
            "Epoch: 0 | Mini-Batch: 307 | Loss: 1.61526 | Accuracy: 29.65%\n",
            "Epoch: 0 | Mini-Batch: 308 | Loss: 1.55294 | Accuracy: 29.71%\n",
            "Epoch: 0 | Mini-Batch: 309 | Loss: 1.56654 | Accuracy: 29.76%\n",
            "Epoch: 0 | Mini-Batch: 310 | Loss: 1.56132 | Accuracy: 29.80%\n",
            "Epoch: 0 | Mini-Batch: 311 | Loss: 1.65948 | Accuracy: 29.84%\n",
            "Epoch: 0 | Mini-Batch: 312 | Loss: 1.67566 | Accuracy: 29.87%\n",
            "Epoch: 0 | Mini-Batch: 313 | Loss: 1.55058 | Accuracy: 29.89%\n",
            "Epoch: 0 | Mini-Batch: 314 | Loss: 1.78863 | Accuracy: 29.91%\n",
            "Epoch: 0 | Mini-Batch: 315 | Loss: 1.54529 | Accuracy: 29.95%\n",
            "Epoch: 0 | Mini-Batch: 316 | Loss: 1.67076 | Accuracy: 29.97%\n",
            "Epoch: 0 | Mini-Batch: 317 | Loss: 1.65475 | Accuracy: 30.00%\n",
            "Epoch: 0 | Mini-Batch: 318 | Loss: 1.59751 | Accuracy: 30.04%\n",
            "Epoch: 0 | Mini-Batch: 319 | Loss: 1.62948 | Accuracy: 30.07%\n",
            "Epoch: 0 | Mini-Batch: 320 | Loss: 1.63003 | Accuracy: 30.10%\n",
            "Epoch: 0 | Mini-Batch: 321 | Loss: 1.67458 | Accuracy: 30.14%\n",
            "Epoch: 0 | Mini-Batch: 322 | Loss: 1.57494 | Accuracy: 30.18%\n",
            "Epoch: 0 | Mini-Batch: 323 | Loss: 1.62063 | Accuracy: 30.19%\n",
            "Epoch: 0 | Mini-Batch: 324 | Loss: 1.62719 | Accuracy: 30.23%\n",
            "Epoch: 0 | Mini-Batch: 325 | Loss: 1.68989 | Accuracy: 30.25%\n",
            "Epoch: 0 | Mini-Batch: 326 | Loss: 1.66997 | Accuracy: 30.28%\n",
            "Epoch: 0 | Mini-Batch: 327 | Loss: 1.51741 | Accuracy: 30.31%\n",
            "Epoch: 0 | Mini-Batch: 328 | Loss: 1.74522 | Accuracy: 30.34%\n",
            "Epoch: 0 | Mini-Batch: 329 | Loss: 1.80930 | Accuracy: 30.35%\n",
            "Epoch: 0 | Mini-Batch: 330 | Loss: 1.55169 | Accuracy: 30.39%\n",
            "Epoch: 0 | Mini-Batch: 331 | Loss: 1.52039 | Accuracy: 30.43%\n",
            "Epoch: 0 | Mini-Batch: 332 | Loss: 1.55340 | Accuracy: 30.46%\n",
            "Epoch: 0 | Mini-Batch: 333 | Loss: 1.61202 | Accuracy: 30.50%\n",
            "Epoch: 0 | Mini-Batch: 334 | Loss: 1.70300 | Accuracy: 30.51%\n",
            "Epoch: 0 | Mini-Batch: 335 | Loss: 1.46291 | Accuracy: 30.56%\n",
            "Epoch: 0 | Mini-Batch: 336 | Loss: 1.60596 | Accuracy: 30.60%\n",
            "Epoch: 0 | Mini-Batch: 337 | Loss: 1.50483 | Accuracy: 30.64%\n",
            "Epoch: 0 | Mini-Batch: 338 | Loss: 1.44581 | Accuracy: 30.69%\n",
            "Epoch: 0 | Mini-Batch: 339 | Loss: 1.57954 | Accuracy: 30.73%\n",
            "Epoch: 0 | Mini-Batch: 340 | Loss: 1.58587 | Accuracy: 30.76%\n",
            "Epoch: 0 | Mini-Batch: 341 | Loss: 1.51811 | Accuracy: 30.80%\n",
            "Epoch: 0 | Mini-Batch: 342 | Loss: 1.40156 | Accuracy: 30.86%\n",
            "Epoch: 0 | Mini-Batch: 343 | Loss: 1.53668 | Accuracy: 30.89%\n",
            "Epoch: 0 | Mini-Batch: 344 | Loss: 1.51567 | Accuracy: 30.94%\n",
            "Epoch: 0 | Mini-Batch: 345 | Loss: 1.58066 | Accuracy: 30.96%\n",
            "Epoch: 0 | Mini-Batch: 346 | Loss: 1.61372 | Accuracy: 31.00%\n",
            "Epoch: 0 | Mini-Batch: 347 | Loss: 1.64984 | Accuracy: 31.03%\n",
            "Epoch: 0 | Mini-Batch: 348 | Loss: 1.60001 | Accuracy: 31.05%\n",
            "Epoch: 0 | Mini-Batch: 349 | Loss: 1.55293 | Accuracy: 31.08%\n",
            "Epoch: 0 | Mini-Batch: 350 | Loss: 1.59904 | Accuracy: 31.10%\n",
            "Epoch: 0 | Mini-Batch: 351 | Loss: 1.36184 | Accuracy: 31.16%\n",
            "Epoch: 0 | Mini-Batch: 352 | Loss: 1.59071 | Accuracy: 31.20%\n",
            "Epoch: 0 | Mini-Batch: 353 | Loss: 1.65466 | Accuracy: 31.20%\n",
            "Epoch: 0 | Mini-Batch: 354 | Loss: 1.48379 | Accuracy: 31.23%\n",
            "Epoch: 0 | Mini-Batch: 355 | Loss: 1.62546 | Accuracy: 31.26%\n",
            "Epoch: 0 | Mini-Batch: 356 | Loss: 1.55118 | Accuracy: 31.30%\n",
            "Epoch: 0 | Mini-Batch: 357 | Loss: 1.55967 | Accuracy: 31.33%\n",
            "Epoch: 0 | Mini-Batch: 358 | Loss: 1.59832 | Accuracy: 31.35%\n",
            "Epoch: 0 | Mini-Batch: 359 | Loss: 1.53259 | Accuracy: 31.38%\n",
            "Epoch: 0 | Mini-Batch: 360 | Loss: 1.48045 | Accuracy: 31.42%\n",
            "Epoch: 0 | Mini-Batch: 361 | Loss: 1.46631 | Accuracy: 31.46%\n",
            "Epoch: 0 | Mini-Batch: 362 | Loss: 1.68159 | Accuracy: 31.49%\n",
            "Epoch: 0 | Mini-Batch: 363 | Loss: 1.47645 | Accuracy: 31.52%\n",
            "Epoch: 0 | Mini-Batch: 364 | Loss: 1.50521 | Accuracy: 31.54%\n",
            "Epoch: 0 | Mini-Batch: 365 | Loss: 1.64852 | Accuracy: 31.57%\n",
            "Epoch: 0 | Mini-Batch: 366 | Loss: 1.48169 | Accuracy: 31.61%\n",
            "Epoch: 0 | Mini-Batch: 367 | Loss: 1.42804 | Accuracy: 31.65%\n",
            "Epoch: 0 | Mini-Batch: 368 | Loss: 1.67292 | Accuracy: 31.68%\n",
            "Epoch: 0 | Mini-Batch: 369 | Loss: 1.38975 | Accuracy: 31.73%\n",
            "Epoch: 0 | Mini-Batch: 370 | Loss: 1.63227 | Accuracy: 31.74%\n",
            "Epoch: 0 | Mini-Batch: 371 | Loss: 1.47690 | Accuracy: 31.78%\n",
            "Epoch: 0 | Mini-Batch: 372 | Loss: 1.59809 | Accuracy: 31.79%\n",
            "Epoch: 0 | Mini-Batch: 373 | Loss: 1.56139 | Accuracy: 31.81%\n",
            "Epoch: 0 | Mini-Batch: 374 | Loss: 1.46859 | Accuracy: 31.85%\n",
            "Epoch: 0 | Mini-Batch: 375 | Loss: 1.65470 | Accuracy: 31.87%\n",
            "Epoch: 0 | Mini-Batch: 376 | Loss: 1.51584 | Accuracy: 31.90%\n",
            "Epoch: 0 | Mini-Batch: 377 | Loss: 1.64569 | Accuracy: 31.92%\n",
            "Epoch: 0 | Mini-Batch: 378 | Loss: 1.43494 | Accuracy: 31.95%\n",
            "Epoch: 0 | Mini-Batch: 379 | Loss: 1.59877 | Accuracy: 31.99%\n",
            "Epoch: 0 | Mini-Batch: 380 | Loss: 1.49437 | Accuracy: 32.02%\n",
            "Epoch: 0 | Mini-Batch: 381 | Loss: 1.52336 | Accuracy: 32.05%\n",
            "Epoch: 0 | Mini-Batch: 382 | Loss: 1.35495 | Accuracy: 32.10%\n",
            "Epoch: 0 | Mini-Batch: 383 | Loss: 1.50966 | Accuracy: 32.12%\n",
            "Epoch: 0 | Mini-Batch: 384 | Loss: 1.46762 | Accuracy: 32.15%\n",
            "Epoch: 0 | Mini-Batch: 385 | Loss: 1.37571 | Accuracy: 32.19%\n",
            "Epoch: 0 | Mini-Batch: 386 | Loss: 1.50714 | Accuracy: 32.21%\n",
            "Epoch: 0 | Mini-Batch: 387 | Loss: 1.70522 | Accuracy: 32.23%\n",
            "Epoch: 0 | Mini-Batch: 388 | Loss: 1.68244 | Accuracy: 32.24%\n",
            "Epoch: 0 | Mini-Batch: 389 | Loss: 1.77630 | Accuracy: 32.26%\n",
            "Epoch: 0 | Mini-Batch: 390 | Loss: 1.46620 | Accuracy: 32.28%\n",
            "Epoch: 1 | Mini-Batch: 0 | Loss: 1.53344 | Accuracy: 46.09%\n",
            "Epoch: 1 | Mini-Batch: 1 | Loss: 1.42177 | Accuracy: 45.31%\n",
            "Epoch: 1 | Mini-Batch: 2 | Loss: 1.75702 | Accuracy: 41.93%\n",
            "Epoch: 1 | Mini-Batch: 3 | Loss: 1.85329 | Accuracy: 40.82%\n",
            "Epoch: 1 | Mini-Batch: 4 | Loss: 1.53282 | Accuracy: 40.94%\n",
            "Epoch: 1 | Mini-Batch: 5 | Loss: 1.48883 | Accuracy: 40.76%\n",
            "Epoch: 1 | Mini-Batch: 6 | Loss: 1.41803 | Accuracy: 42.08%\n",
            "Epoch: 1 | Mini-Batch: 7 | Loss: 1.59497 | Accuracy: 42.38%\n",
            "Epoch: 1 | Mini-Batch: 8 | Loss: 1.57673 | Accuracy: 42.10%\n",
            "Epoch: 1 | Mini-Batch: 9 | Loss: 1.67561 | Accuracy: 41.56%\n",
            "Epoch: 1 | Mini-Batch: 10 | Loss: 1.52853 | Accuracy: 41.62%\n",
            "Epoch: 1 | Mini-Batch: 11 | Loss: 1.55151 | Accuracy: 41.34%\n",
            "Epoch: 1 | Mini-Batch: 12 | Loss: 1.59906 | Accuracy: 41.35%\n",
            "Epoch: 1 | Mini-Batch: 13 | Loss: 1.52090 | Accuracy: 41.57%\n",
            "Epoch: 1 | Mini-Batch: 14 | Loss: 1.43938 | Accuracy: 41.77%\n",
            "Epoch: 1 | Mini-Batch: 15 | Loss: 1.48192 | Accuracy: 42.38%\n",
            "Epoch: 1 | Mini-Batch: 16 | Loss: 1.50935 | Accuracy: 42.51%\n",
            "Epoch: 1 | Mini-Batch: 17 | Loss: 1.63092 | Accuracy: 42.45%\n",
            "Epoch: 1 | Mini-Batch: 18 | Loss: 1.40554 | Accuracy: 42.72%\n",
            "Epoch: 1 | Mini-Batch: 19 | Loss: 1.47069 | Accuracy: 42.89%\n",
            "Epoch: 1 | Mini-Batch: 20 | Loss: 1.47301 | Accuracy: 43.12%\n",
            "Epoch: 1 | Mini-Batch: 21 | Loss: 1.47021 | Accuracy: 43.25%\n",
            "Epoch: 1 | Mini-Batch: 22 | Loss: 1.72759 | Accuracy: 43.00%\n",
            "Epoch: 1 | Mini-Batch: 23 | Loss: 1.50583 | Accuracy: 43.00%\n",
            "Epoch: 1 | Mini-Batch: 24 | Loss: 1.34231 | Accuracy: 43.53%\n",
            "Epoch: 1 | Mini-Batch: 25 | Loss: 1.43187 | Accuracy: 43.54%\n",
            "Epoch: 1 | Mini-Batch: 26 | Loss: 1.60535 | Accuracy: 43.46%\n",
            "Epoch: 1 | Mini-Batch: 27 | Loss: 1.47799 | Accuracy: 43.61%\n",
            "Epoch: 1 | Mini-Batch: 28 | Loss: 1.49513 | Accuracy: 43.67%\n",
            "Epoch: 1 | Mini-Batch: 29 | Loss: 1.40100 | Accuracy: 43.83%\n",
            "Epoch: 1 | Mini-Batch: 30 | Loss: 1.64804 | Accuracy: 43.57%\n",
            "Epoch: 1 | Mini-Batch: 31 | Loss: 1.57502 | Accuracy: 43.36%\n",
            "Epoch: 1 | Mini-Batch: 32 | Loss: 1.49521 | Accuracy: 43.39%\n",
            "Epoch: 1 | Mini-Batch: 33 | Loss: 1.62666 | Accuracy: 43.31%\n",
            "Epoch: 1 | Mini-Batch: 34 | Loss: 1.44721 | Accuracy: 43.35%\n",
            "Epoch: 1 | Mini-Batch: 35 | Loss: 1.49945 | Accuracy: 43.27%\n",
            "Epoch: 1 | Mini-Batch: 36 | Loss: 1.57610 | Accuracy: 43.18%\n",
            "Epoch: 1 | Mini-Batch: 37 | Loss: 1.49289 | Accuracy: 43.36%\n",
            "Epoch: 1 | Mini-Batch: 38 | Loss: 1.48264 | Accuracy: 43.43%\n",
            "Epoch: 1 | Mini-Batch: 39 | Loss: 1.53093 | Accuracy: 43.52%\n",
            "Epoch: 1 | Mini-Batch: 40 | Loss: 1.50390 | Accuracy: 43.69%\n",
            "Epoch: 1 | Mini-Batch: 41 | Loss: 1.44632 | Accuracy: 43.75%\n",
            "Epoch: 1 | Mini-Batch: 42 | Loss: 1.49007 | Accuracy: 43.70%\n",
            "Epoch: 1 | Mini-Batch: 43 | Loss: 1.41837 | Accuracy: 43.66%\n",
            "Epoch: 1 | Mini-Batch: 44 | Loss: 1.37141 | Accuracy: 43.89%\n",
            "Epoch: 1 | Mini-Batch: 45 | Loss: 1.37331 | Accuracy: 44.04%\n",
            "Epoch: 1 | Mini-Batch: 46 | Loss: 1.60890 | Accuracy: 43.90%\n",
            "Epoch: 1 | Mini-Batch: 47 | Loss: 1.41119 | Accuracy: 44.04%\n",
            "Epoch: 1 | Mini-Batch: 48 | Loss: 1.40193 | Accuracy: 44.21%\n",
            "Epoch: 1 | Mini-Batch: 49 | Loss: 1.49355 | Accuracy: 44.25%\n",
            "Epoch: 1 | Mini-Batch: 50 | Loss: 1.32024 | Accuracy: 44.38%\n",
            "Epoch: 1 | Mini-Batch: 51 | Loss: 1.38195 | Accuracy: 44.46%\n",
            "Epoch: 1 | Mini-Batch: 52 | Loss: 1.42575 | Accuracy: 44.50%\n",
            "Epoch: 1 | Mini-Batch: 53 | Loss: 1.30261 | Accuracy: 44.57%\n",
            "Epoch: 1 | Mini-Batch: 54 | Loss: 1.59901 | Accuracy: 44.55%\n",
            "Epoch: 1 | Mini-Batch: 55 | Loss: 1.69638 | Accuracy: 44.42%\n",
            "Epoch: 1 | Mini-Batch: 56 | Loss: 1.60713 | Accuracy: 44.41%\n",
            "Epoch: 1 | Mini-Batch: 57 | Loss: 1.51008 | Accuracy: 44.46%\n",
            "Epoch: 1 | Mini-Batch: 58 | Loss: 1.45970 | Accuracy: 44.43%\n",
            "Epoch: 1 | Mini-Batch: 59 | Loss: 1.36810 | Accuracy: 44.48%\n",
            "Epoch: 1 | Mini-Batch: 60 | Loss: 1.52534 | Accuracy: 44.44%\n",
            "Epoch: 1 | Mini-Batch: 61 | Loss: 1.57849 | Accuracy: 44.39%\n",
            "Epoch: 1 | Mini-Batch: 62 | Loss: 1.34822 | Accuracy: 44.44%\n",
            "Epoch: 1 | Mini-Batch: 63 | Loss: 1.63299 | Accuracy: 44.47%\n",
            "Epoch: 1 | Mini-Batch: 64 | Loss: 1.51548 | Accuracy: 44.42%\n",
            "Epoch: 1 | Mini-Batch: 65 | Loss: 1.56085 | Accuracy: 44.45%\n",
            "Epoch: 1 | Mini-Batch: 66 | Loss: 1.47533 | Accuracy: 44.47%\n",
            "Epoch: 1 | Mini-Batch: 67 | Loss: 1.64762 | Accuracy: 44.43%\n",
            "Epoch: 1 | Mini-Batch: 68 | Loss: 1.62369 | Accuracy: 44.38%\n",
            "Epoch: 1 | Mini-Batch: 69 | Loss: 1.50607 | Accuracy: 44.48%\n",
            "Epoch: 1 | Mini-Batch: 70 | Loss: 1.50740 | Accuracy: 44.39%\n",
            "Epoch: 1 | Mini-Batch: 71 | Loss: 1.50916 | Accuracy: 44.41%\n",
            "Epoch: 1 | Mini-Batch: 72 | Loss: 1.36164 | Accuracy: 44.49%\n",
            "Epoch: 1 | Mini-Batch: 73 | Loss: 1.53105 | Accuracy: 44.53%\n",
            "Epoch: 1 | Mini-Batch: 74 | Loss: 1.38803 | Accuracy: 44.57%\n",
            "Epoch: 1 | Mini-Batch: 75 | Loss: 1.49275 | Accuracy: 44.57%\n",
            "Epoch: 1 | Mini-Batch: 76 | Loss: 1.46108 | Accuracy: 44.65%\n",
            "Epoch: 1 | Mini-Batch: 77 | Loss: 1.45485 | Accuracy: 44.68%\n",
            "Epoch: 1 | Mini-Batch: 78 | Loss: 1.36449 | Accuracy: 44.74%\n",
            "Epoch: 1 | Mini-Batch: 79 | Loss: 1.55331 | Accuracy: 44.71%\n",
            "Epoch: 1 | Mini-Batch: 80 | Loss: 1.40850 | Accuracy: 44.71%\n",
            "Epoch: 1 | Mini-Batch: 81 | Loss: 1.40628 | Accuracy: 44.74%\n",
            "Epoch: 1 | Mini-Batch: 82 | Loss: 1.58803 | Accuracy: 44.67%\n",
            "Epoch: 1 | Mini-Batch: 83 | Loss: 1.49699 | Accuracy: 44.65%\n",
            "Epoch: 1 | Mini-Batch: 84 | Loss: 1.35222 | Accuracy: 44.72%\n",
            "Epoch: 1 | Mini-Batch: 85 | Loss: 1.40524 | Accuracy: 44.79%\n",
            "Epoch: 1 | Mini-Batch: 86 | Loss: 1.52900 | Accuracy: 44.78%\n",
            "Epoch: 1 | Mini-Batch: 87 | Loss: 1.57839 | Accuracy: 44.80%\n",
            "Epoch: 1 | Mini-Batch: 88 | Loss: 1.42522 | Accuracy: 44.86%\n",
            "Epoch: 1 | Mini-Batch: 89 | Loss: 1.45433 | Accuracy: 44.89%\n",
            "Epoch: 1 | Mini-Batch: 90 | Loss: 1.37114 | Accuracy: 44.91%\n",
            "Epoch: 1 | Mini-Batch: 91 | Loss: 1.44885 | Accuracy: 44.95%\n",
            "Epoch: 1 | Mini-Batch: 92 | Loss: 1.46198 | Accuracy: 44.92%\n",
            "Epoch: 1 | Mini-Batch: 93 | Loss: 1.43283 | Accuracy: 44.96%\n",
            "Epoch: 1 | Mini-Batch: 94 | Loss: 1.50097 | Accuracy: 44.96%\n",
            "Epoch: 1 | Mini-Batch: 95 | Loss: 1.62467 | Accuracy: 44.91%\n",
            "Epoch: 1 | Mini-Batch: 96 | Loss: 1.53737 | Accuracy: 44.90%\n",
            "Epoch: 1 | Mini-Batch: 97 | Loss: 1.30950 | Accuracy: 44.94%\n",
            "Epoch: 1 | Mini-Batch: 98 | Loss: 1.45489 | Accuracy: 44.94%\n",
            "Epoch: 1 | Mini-Batch: 99 | Loss: 1.38132 | Accuracy: 45.03%\n",
            "Epoch: 1 | Mini-Batch: 100 | Loss: 1.37211 | Accuracy: 45.13%\n",
            "Epoch: 1 | Mini-Batch: 101 | Loss: 1.52939 | Accuracy: 45.09%\n",
            "Epoch: 1 | Mini-Batch: 102 | Loss: 1.40966 | Accuracy: 45.12%\n",
            "Epoch: 1 | Mini-Batch: 103 | Loss: 1.61209 | Accuracy: 45.11%\n",
            "Epoch: 1 | Mini-Batch: 104 | Loss: 1.29098 | Accuracy: 45.18%\n",
            "Epoch: 1 | Mini-Batch: 105 | Loss: 1.40479 | Accuracy: 45.22%\n",
            "Epoch: 1 | Mini-Batch: 106 | Loss: 1.45052 | Accuracy: 45.21%\n",
            "Epoch: 1 | Mini-Batch: 107 | Loss: 1.48017 | Accuracy: 45.18%\n",
            "Epoch: 1 | Mini-Batch: 108 | Loss: 1.42514 | Accuracy: 45.23%\n",
            "Epoch: 1 | Mini-Batch: 109 | Loss: 1.37544 | Accuracy: 45.31%\n",
            "Epoch: 1 | Mini-Batch: 110 | Loss: 1.49622 | Accuracy: 45.31%\n",
            "Epoch: 1 | Mini-Batch: 111 | Loss: 1.45630 | Accuracy: 45.34%\n",
            "Epoch: 1 | Mini-Batch: 112 | Loss: 1.40287 | Accuracy: 45.37%\n",
            "Epoch: 1 | Mini-Batch: 113 | Loss: 1.52879 | Accuracy: 45.37%\n",
            "Epoch: 1 | Mini-Batch: 114 | Loss: 1.47316 | Accuracy: 45.38%\n",
            "Epoch: 1 | Mini-Batch: 115 | Loss: 1.55341 | Accuracy: 45.39%\n",
            "Epoch: 1 | Mini-Batch: 116 | Loss: 1.16258 | Accuracy: 45.47%\n",
            "Epoch: 1 | Mini-Batch: 117 | Loss: 1.38368 | Accuracy: 45.48%\n",
            "Epoch: 1 | Mini-Batch: 118 | Loss: 1.52233 | Accuracy: 45.48%\n",
            "Epoch: 1 | Mini-Batch: 119 | Loss: 1.74942 | Accuracy: 45.40%\n",
            "Epoch: 1 | Mini-Batch: 120 | Loss: 1.48513 | Accuracy: 45.42%\n",
            "Epoch: 1 | Mini-Batch: 121 | Loss: 1.51654 | Accuracy: 45.43%\n",
            "Epoch: 1 | Mini-Batch: 122 | Loss: 1.29824 | Accuracy: 45.46%\n",
            "Epoch: 1 | Mini-Batch: 123 | Loss: 1.49281 | Accuracy: 45.48%\n",
            "Epoch: 1 | Mini-Batch: 124 | Loss: 1.48923 | Accuracy: 45.48%\n",
            "Epoch: 1 | Mini-Batch: 125 | Loss: 1.52639 | Accuracy: 45.43%\n",
            "Epoch: 1 | Mini-Batch: 126 | Loss: 1.31220 | Accuracy: 45.50%\n",
            "Epoch: 1 | Mini-Batch: 127 | Loss: 1.42782 | Accuracy: 45.54%\n",
            "Epoch: 1 | Mini-Batch: 128 | Loss: 1.44380 | Accuracy: 45.52%\n",
            "Epoch: 1 | Mini-Batch: 129 | Loss: 1.49135 | Accuracy: 45.52%\n",
            "Epoch: 1 | Mini-Batch: 130 | Loss: 1.38433 | Accuracy: 45.57%\n",
            "Epoch: 1 | Mini-Batch: 131 | Loss: 1.32287 | Accuracy: 45.61%\n",
            "Epoch: 1 | Mini-Batch: 132 | Loss: 1.50202 | Accuracy: 45.60%\n",
            "Epoch: 1 | Mini-Batch: 133 | Loss: 1.36365 | Accuracy: 45.62%\n",
            "Epoch: 1 | Mini-Batch: 134 | Loss: 1.59999 | Accuracy: 45.60%\n",
            "Epoch: 1 | Mini-Batch: 135 | Loss: 1.37034 | Accuracy: 45.61%\n",
            "Epoch: 1 | Mini-Batch: 136 | Loss: 1.46462 | Accuracy: 45.61%\n",
            "Epoch: 1 | Mini-Batch: 137 | Loss: 1.36330 | Accuracy: 45.62%\n",
            "Epoch: 1 | Mini-Batch: 138 | Loss: 1.46326 | Accuracy: 45.64%\n",
            "Epoch: 1 | Mini-Batch: 139 | Loss: 1.39957 | Accuracy: 45.67%\n",
            "Epoch: 1 | Mini-Batch: 140 | Loss: 1.29645 | Accuracy: 45.70%\n",
            "Epoch: 1 | Mini-Batch: 141 | Loss: 1.45048 | Accuracy: 45.67%\n",
            "Epoch: 1 | Mini-Batch: 142 | Loss: 1.52720 | Accuracy: 45.69%\n",
            "Epoch: 1 | Mini-Batch: 143 | Loss: 1.30661 | Accuracy: 45.69%\n",
            "Epoch: 1 | Mini-Batch: 144 | Loss: 1.43319 | Accuracy: 45.68%\n",
            "Epoch: 1 | Mini-Batch: 145 | Loss: 1.34335 | Accuracy: 45.70%\n",
            "Epoch: 1 | Mini-Batch: 146 | Loss: 1.41701 | Accuracy: 45.70%\n",
            "Epoch: 1 | Mini-Batch: 147 | Loss: 1.46000 | Accuracy: 45.71%\n",
            "Epoch: 1 | Mini-Batch: 148 | Loss: 1.55920 | Accuracy: 45.69%\n",
            "Epoch: 1 | Mini-Batch: 149 | Loss: 1.47907 | Accuracy: 45.67%\n",
            "Epoch: 1 | Mini-Batch: 150 | Loss: 1.34441 | Accuracy: 45.70%\n",
            "Epoch: 1 | Mini-Batch: 151 | Loss: 1.32860 | Accuracy: 45.72%\n",
            "Epoch: 1 | Mini-Batch: 152 | Loss: 1.43269 | Accuracy: 45.73%\n",
            "Epoch: 1 | Mini-Batch: 153 | Loss: 1.42795 | Accuracy: 45.74%\n",
            "Epoch: 1 | Mini-Batch: 154 | Loss: 1.55622 | Accuracy: 45.71%\n",
            "Epoch: 1 | Mini-Batch: 155 | Loss: 1.34149 | Accuracy: 45.73%\n",
            "Epoch: 1 | Mini-Batch: 156 | Loss: 1.37233 | Accuracy: 45.77%\n",
            "Epoch: 1 | Mini-Batch: 157 | Loss: 1.28064 | Accuracy: 45.78%\n",
            "Epoch: 1 | Mini-Batch: 158 | Loss: 1.50887 | Accuracy: 45.76%\n",
            "Epoch: 1 | Mini-Batch: 159 | Loss: 1.31673 | Accuracy: 45.80%\n",
            "Epoch: 1 | Mini-Batch: 160 | Loss: 1.43747 | Accuracy: 45.79%\n",
            "Epoch: 1 | Mini-Batch: 161 | Loss: 1.41845 | Accuracy: 45.81%\n",
            "Epoch: 1 | Mini-Batch: 162 | Loss: 1.21650 | Accuracy: 45.86%\n",
            "Epoch: 1 | Mini-Batch: 163 | Loss: 1.27736 | Accuracy: 45.90%\n",
            "Epoch: 1 | Mini-Batch: 164 | Loss: 1.44335 | Accuracy: 45.92%\n",
            "Epoch: 1 | Mini-Batch: 165 | Loss: 1.13098 | Accuracy: 46.02%\n",
            "Epoch: 1 | Mini-Batch: 166 | Loss: 1.28155 | Accuracy: 46.07%\n",
            "Epoch: 1 | Mini-Batch: 167 | Loss: 1.37399 | Accuracy: 46.08%\n",
            "Epoch: 1 | Mini-Batch: 168 | Loss: 1.54702 | Accuracy: 46.06%\n",
            "Epoch: 1 | Mini-Batch: 169 | Loss: 1.54935 | Accuracy: 46.09%\n",
            "Epoch: 1 | Mini-Batch: 170 | Loss: 1.39469 | Accuracy: 46.09%\n",
            "Epoch: 1 | Mini-Batch: 171 | Loss: 1.40573 | Accuracy: 46.10%\n",
            "Epoch: 1 | Mini-Batch: 172 | Loss: 1.36961 | Accuracy: 46.13%\n",
            "Epoch: 1 | Mini-Batch: 173 | Loss: 1.54065 | Accuracy: 46.12%\n",
            "Epoch: 1 | Mini-Batch: 174 | Loss: 1.38102 | Accuracy: 46.15%\n",
            "Epoch: 1 | Mini-Batch: 175 | Loss: 1.36866 | Accuracy: 46.18%\n",
            "Epoch: 1 | Mini-Batch: 176 | Loss: 1.35379 | Accuracy: 46.20%\n",
            "Epoch: 1 | Mini-Batch: 177 | Loss: 1.31410 | Accuracy: 46.23%\n",
            "Epoch: 1 | Mini-Batch: 178 | Loss: 1.22777 | Accuracy: 46.26%\n",
            "Epoch: 1 | Mini-Batch: 179 | Loss: 1.21419 | Accuracy: 46.32%\n",
            "Epoch: 1 | Mini-Batch: 180 | Loss: 1.42434 | Accuracy: 46.32%\n",
            "Epoch: 1 | Mini-Batch: 181 | Loss: 1.24370 | Accuracy: 46.36%\n",
            "Epoch: 1 | Mini-Batch: 182 | Loss: 1.51121 | Accuracy: 46.36%\n",
            "Epoch: 1 | Mini-Batch: 183 | Loss: 1.41943 | Accuracy: 46.37%\n",
            "Epoch: 1 | Mini-Batch: 184 | Loss: 1.37311 | Accuracy: 46.39%\n",
            "Epoch: 1 | Mini-Batch: 185 | Loss: 1.37972 | Accuracy: 46.40%\n",
            "Epoch: 1 | Mini-Batch: 186 | Loss: 1.31397 | Accuracy: 46.41%\n",
            "Epoch: 1 | Mini-Batch: 187 | Loss: 1.38092 | Accuracy: 46.43%\n",
            "Epoch: 1 | Mini-Batch: 188 | Loss: 1.36765 | Accuracy: 46.46%\n",
            "Epoch: 1 | Mini-Batch: 189 | Loss: 1.37902 | Accuracy: 46.49%\n",
            "Epoch: 1 | Mini-Batch: 190 | Loss: 1.38584 | Accuracy: 46.50%\n",
            "Epoch: 1 | Mini-Batch: 191 | Loss: 1.52925 | Accuracy: 46.48%\n",
            "Epoch: 1 | Mini-Batch: 192 | Loss: 1.35104 | Accuracy: 46.49%\n",
            "Epoch: 1 | Mini-Batch: 193 | Loss: 1.42866 | Accuracy: 46.48%\n",
            "Epoch: 1 | Mini-Batch: 194 | Loss: 1.33990 | Accuracy: 46.51%\n",
            "Epoch: 1 | Mini-Batch: 195 | Loss: 1.58533 | Accuracy: 46.51%\n",
            "Epoch: 1 | Mini-Batch: 196 | Loss: 1.39251 | Accuracy: 46.51%\n",
            "Epoch: 1 | Mini-Batch: 197 | Loss: 1.28672 | Accuracy: 46.53%\n",
            "Epoch: 1 | Mini-Batch: 198 | Loss: 1.40878 | Accuracy: 46.54%\n",
            "Epoch: 1 | Mini-Batch: 199 | Loss: 1.39425 | Accuracy: 46.53%\n",
            "Epoch: 1 | Mini-Batch: 200 | Loss: 1.35881 | Accuracy: 46.57%\n",
            "Epoch: 1 | Mini-Batch: 201 | Loss: 1.39197 | Accuracy: 46.56%\n",
            "Epoch: 1 | Mini-Batch: 202 | Loss: 1.21274 | Accuracy: 46.59%\n",
            "Epoch: 1 | Mini-Batch: 203 | Loss: 1.39003 | Accuracy: 46.60%\n",
            "Epoch: 1 | Mini-Batch: 204 | Loss: 1.33229 | Accuracy: 46.62%\n",
            "Epoch: 1 | Mini-Batch: 205 | Loss: 1.23016 | Accuracy: 46.65%\n",
            "Epoch: 1 | Mini-Batch: 206 | Loss: 1.32497 | Accuracy: 46.67%\n",
            "Epoch: 1 | Mini-Batch: 207 | Loss: 1.20173 | Accuracy: 46.72%\n",
            "Epoch: 1 | Mini-Batch: 208 | Loss: 1.46533 | Accuracy: 46.72%\n",
            "Epoch: 1 | Mini-Batch: 209 | Loss: 1.43722 | Accuracy: 46.73%\n",
            "Epoch: 1 | Mini-Batch: 210 | Loss: 1.36092 | Accuracy: 46.75%\n",
            "Epoch: 1 | Mini-Batch: 211 | Loss: 1.32655 | Accuracy: 46.76%\n",
            "Epoch: 1 | Mini-Batch: 212 | Loss: 1.63023 | Accuracy: 46.76%\n",
            "Epoch: 1 | Mini-Batch: 213 | Loss: 1.27496 | Accuracy: 46.78%\n",
            "Epoch: 1 | Mini-Batch: 214 | Loss: 1.47187 | Accuracy: 46.78%\n",
            "Epoch: 1 | Mini-Batch: 215 | Loss: 1.20685 | Accuracy: 46.84%\n",
            "Epoch: 1 | Mini-Batch: 216 | Loss: 1.47357 | Accuracy: 46.85%\n",
            "Epoch: 1 | Mini-Batch: 217 | Loss: 1.47571 | Accuracy: 46.85%\n",
            "Epoch: 1 | Mini-Batch: 218 | Loss: 1.28722 | Accuracy: 46.87%\n",
            "Epoch: 1 | Mini-Batch: 219 | Loss: 1.46783 | Accuracy: 46.86%\n",
            "Epoch: 1 | Mini-Batch: 220 | Loss: 1.61698 | Accuracy: 46.84%\n",
            "Epoch: 1 | Mini-Batch: 221 | Loss: 1.71110 | Accuracy: 46.81%\n",
            "Epoch: 1 | Mini-Batch: 222 | Loss: 1.48005 | Accuracy: 46.79%\n",
            "Epoch: 1 | Mini-Batch: 223 | Loss: 1.48963 | Accuracy: 46.79%\n",
            "Epoch: 1 | Mini-Batch: 224 | Loss: 1.43877 | Accuracy: 46.78%\n",
            "Epoch: 1 | Mini-Batch: 225 | Loss: 1.41035 | Accuracy: 46.77%\n",
            "Epoch: 1 | Mini-Batch: 226 | Loss: 1.15052 | Accuracy: 46.83%\n",
            "Epoch: 1 | Mini-Batch: 227 | Loss: 1.42383 | Accuracy: 46.84%\n",
            "Epoch: 1 | Mini-Batch: 228 | Loss: 1.27815 | Accuracy: 46.89%\n",
            "Epoch: 1 | Mini-Batch: 229 | Loss: 1.49917 | Accuracy: 46.89%\n",
            "Epoch: 1 | Mini-Batch: 230 | Loss: 1.31337 | Accuracy: 46.90%\n",
            "Epoch: 1 | Mini-Batch: 231 | Loss: 1.28411 | Accuracy: 46.92%\n",
            "Epoch: 1 | Mini-Batch: 232 | Loss: 1.41072 | Accuracy: 46.94%\n",
            "Epoch: 1 | Mini-Batch: 233 | Loss: 1.61868 | Accuracy: 46.90%\n",
            "Epoch: 1 | Mini-Batch: 234 | Loss: 1.34418 | Accuracy: 46.91%\n",
            "Epoch: 1 | Mini-Batch: 235 | Loss: 1.33643 | Accuracy: 46.93%\n",
            "Epoch: 1 | Mini-Batch: 236 | Loss: 1.66019 | Accuracy: 46.91%\n",
            "Epoch: 1 | Mini-Batch: 237 | Loss: 1.27177 | Accuracy: 46.95%\n",
            "Epoch: 1 | Mini-Batch: 238 | Loss: 1.63627 | Accuracy: 46.94%\n",
            "Epoch: 1 | Mini-Batch: 239 | Loss: 1.27404 | Accuracy: 46.96%\n",
            "Epoch: 1 | Mini-Batch: 240 | Loss: 1.43038 | Accuracy: 46.97%\n",
            "Epoch: 1 | Mini-Batch: 241 | Loss: 1.27325 | Accuracy: 46.99%\n",
            "Epoch: 1 | Mini-Batch: 242 | Loss: 1.32959 | Accuracy: 47.00%\n",
            "Epoch: 1 | Mini-Batch: 243 | Loss: 1.38649 | Accuracy: 47.03%\n",
            "Epoch: 1 | Mini-Batch: 244 | Loss: 1.49389 | Accuracy: 47.01%\n",
            "Epoch: 1 | Mini-Batch: 245 | Loss: 1.28308 | Accuracy: 47.03%\n",
            "Epoch: 1 | Mini-Batch: 246 | Loss: 1.37517 | Accuracy: 47.05%\n",
            "Epoch: 1 | Mini-Batch: 247 | Loss: 1.43989 | Accuracy: 47.08%\n",
            "Epoch: 1 | Mini-Batch: 248 | Loss: 1.27103 | Accuracy: 47.11%\n",
            "Epoch: 1 | Mini-Batch: 249 | Loss: 1.24915 | Accuracy: 47.12%\n",
            "Epoch: 1 | Mini-Batch: 250 | Loss: 1.24711 | Accuracy: 47.16%\n",
            "Epoch: 1 | Mini-Batch: 251 | Loss: 1.34817 | Accuracy: 47.17%\n",
            "Epoch: 1 | Mini-Batch: 252 | Loss: 1.36772 | Accuracy: 47.17%\n",
            "Epoch: 1 | Mini-Batch: 253 | Loss: 1.34756 | Accuracy: 47.17%\n",
            "Epoch: 1 | Mini-Batch: 254 | Loss: 1.51927 | Accuracy: 47.18%\n",
            "Epoch: 1 | Mini-Batch: 255 | Loss: 1.29284 | Accuracy: 47.19%\n",
            "Epoch: 1 | Mini-Batch: 256 | Loss: 1.30227 | Accuracy: 47.21%\n",
            "Epoch: 1 | Mini-Batch: 257 | Loss: 1.38484 | Accuracy: 47.21%\n",
            "Epoch: 1 | Mini-Batch: 258 | Loss: 1.41479 | Accuracy: 47.22%\n",
            "Epoch: 1 | Mini-Batch: 259 | Loss: 1.40274 | Accuracy: 47.21%\n",
            "Epoch: 1 | Mini-Batch: 260 | Loss: 1.52117 | Accuracy: 47.20%\n",
            "Epoch: 1 | Mini-Batch: 261 | Loss: 1.41765 | Accuracy: 47.20%\n",
            "Epoch: 1 | Mini-Batch: 262 | Loss: 1.29790 | Accuracy: 47.21%\n",
            "Epoch: 1 | Mini-Batch: 263 | Loss: 1.35754 | Accuracy: 47.22%\n",
            "Epoch: 1 | Mini-Batch: 264 | Loss: 1.26209 | Accuracy: 47.26%\n",
            "Epoch: 1 | Mini-Batch: 265 | Loss: 1.37335 | Accuracy: 47.23%\n",
            "Epoch: 1 | Mini-Batch: 266 | Loss: 1.17388 | Accuracy: 47.26%\n",
            "Epoch: 1 | Mini-Batch: 267 | Loss: 1.18807 | Accuracy: 47.30%\n",
            "Epoch: 1 | Mini-Batch: 268 | Loss: 1.29598 | Accuracy: 47.34%\n",
            "Epoch: 1 | Mini-Batch: 269 | Loss: 1.44348 | Accuracy: 47.34%\n",
            "Epoch: 1 | Mini-Batch: 270 | Loss: 1.28763 | Accuracy: 47.35%\n",
            "Epoch: 1 | Mini-Batch: 271 | Loss: 1.34970 | Accuracy: 47.37%\n",
            "Epoch: 1 | Mini-Batch: 272 | Loss: 1.35355 | Accuracy: 47.39%\n",
            "Epoch: 1 | Mini-Batch: 273 | Loss: 1.51468 | Accuracy: 47.39%\n",
            "Epoch: 1 | Mini-Batch: 274 | Loss: 1.36339 | Accuracy: 47.41%\n",
            "Epoch: 1 | Mini-Batch: 275 | Loss: 1.41153 | Accuracy: 47.42%\n",
            "Epoch: 1 | Mini-Batch: 276 | Loss: 1.11478 | Accuracy: 47.45%\n",
            "Epoch: 1 | Mini-Batch: 277 | Loss: 1.17594 | Accuracy: 47.46%\n",
            "Epoch: 1 | Mini-Batch: 278 | Loss: 1.39010 | Accuracy: 47.46%\n",
            "Epoch: 1 | Mini-Batch: 279 | Loss: 1.20341 | Accuracy: 47.50%\n",
            "Epoch: 1 | Mini-Batch: 280 | Loss: 1.34391 | Accuracy: 47.52%\n",
            "Epoch: 1 | Mini-Batch: 281 | Loss: 1.42246 | Accuracy: 47.51%\n",
            "Epoch: 1 | Mini-Batch: 282 | Loss: 1.37200 | Accuracy: 47.51%\n",
            "Epoch: 1 | Mini-Batch: 283 | Loss: 1.37779 | Accuracy: 47.52%\n",
            "Epoch: 1 | Mini-Batch: 284 | Loss: 1.37545 | Accuracy: 47.54%\n",
            "Epoch: 1 | Mini-Batch: 285 | Loss: 1.43838 | Accuracy: 47.54%\n",
            "Epoch: 1 | Mini-Batch: 286 | Loss: 1.25481 | Accuracy: 47.56%\n",
            "Epoch: 1 | Mini-Batch: 287 | Loss: 1.32316 | Accuracy: 47.58%\n",
            "Epoch: 1 | Mini-Batch: 288 | Loss: 1.37818 | Accuracy: 47.59%\n",
            "Epoch: 1 | Mini-Batch: 289 | Loss: 1.38241 | Accuracy: 47.60%\n",
            "Epoch: 1 | Mini-Batch: 290 | Loss: 1.31350 | Accuracy: 47.62%\n",
            "Epoch: 1 | Mini-Batch: 291 | Loss: 1.28429 | Accuracy: 47.63%\n",
            "Epoch: 1 | Mini-Batch: 292 | Loss: 1.31336 | Accuracy: 47.64%\n",
            "Epoch: 1 | Mini-Batch: 293 | Loss: 1.22159 | Accuracy: 47.66%\n",
            "Epoch: 1 | Mini-Batch: 294 | Loss: 1.16420 | Accuracy: 47.69%\n",
            "Epoch: 1 | Mini-Batch: 295 | Loss: 1.41436 | Accuracy: 47.70%\n",
            "Epoch: 1 | Mini-Batch: 296 | Loss: 1.12395 | Accuracy: 47.73%\n",
            "Epoch: 1 | Mini-Batch: 297 | Loss: 1.46305 | Accuracy: 47.72%\n",
            "Epoch: 1 | Mini-Batch: 298 | Loss: 1.30250 | Accuracy: 47.72%\n",
            "Epoch: 1 | Mini-Batch: 299 | Loss: 1.34331 | Accuracy: 47.74%\n",
            "Epoch: 1 | Mini-Batch: 300 | Loss: 1.37218 | Accuracy: 47.74%\n",
            "Epoch: 1 | Mini-Batch: 301 | Loss: 1.14640 | Accuracy: 47.76%\n",
            "Epoch: 1 | Mini-Batch: 302 | Loss: 1.35550 | Accuracy: 47.76%\n",
            "Epoch: 1 | Mini-Batch: 303 | Loss: 1.41548 | Accuracy: 47.78%\n",
            "Epoch: 1 | Mini-Batch: 304 | Loss: 1.30360 | Accuracy: 47.80%\n",
            "Epoch: 1 | Mini-Batch: 305 | Loss: 1.41026 | Accuracy: 47.81%\n",
            "Epoch: 1 | Mini-Batch: 306 | Loss: 1.38954 | Accuracy: 47.82%\n",
            "Epoch: 1 | Mini-Batch: 307 | Loss: 1.42223 | Accuracy: 47.82%\n",
            "Epoch: 1 | Mini-Batch: 308 | Loss: 1.52853 | Accuracy: 47.82%\n",
            "Epoch: 1 | Mini-Batch: 309 | Loss: 1.19850 | Accuracy: 47.84%\n",
            "Epoch: 1 | Mini-Batch: 310 | Loss: 1.34161 | Accuracy: 47.87%\n",
            "Epoch: 1 | Mini-Batch: 311 | Loss: 1.26962 | Accuracy: 47.89%\n",
            "Epoch: 1 | Mini-Batch: 312 | Loss: 1.35235 | Accuracy: 47.90%\n",
            "Epoch: 1 | Mini-Batch: 313 | Loss: 1.20405 | Accuracy: 47.93%\n",
            "Epoch: 1 | Mini-Batch: 314 | Loss: 1.33023 | Accuracy: 47.94%\n",
            "Epoch: 1 | Mini-Batch: 315 | Loss: 1.24271 | Accuracy: 47.96%\n",
            "Epoch: 1 | Mini-Batch: 316 | Loss: 1.30307 | Accuracy: 47.97%\n",
            "Epoch: 1 | Mini-Batch: 317 | Loss: 1.24127 | Accuracy: 47.99%\n",
            "Epoch: 1 | Mini-Batch: 318 | Loss: 1.30101 | Accuracy: 48.00%\n",
            "Epoch: 1 | Mini-Batch: 319 | Loss: 1.32886 | Accuracy: 48.02%\n",
            "Epoch: 1 | Mini-Batch: 320 | Loss: 1.26572 | Accuracy: 48.05%\n",
            "Epoch: 1 | Mini-Batch: 321 | Loss: 1.36354 | Accuracy: 48.05%\n",
            "Epoch: 1 | Mini-Batch: 322 | Loss: 1.22754 | Accuracy: 48.06%\n",
            "Epoch: 1 | Mini-Batch: 323 | Loss: 1.36348 | Accuracy: 48.07%\n",
            "Epoch: 1 | Mini-Batch: 324 | Loss: 1.38133 | Accuracy: 48.09%\n",
            "Epoch: 1 | Mini-Batch: 325 | Loss: 1.30499 | Accuracy: 48.11%\n",
            "Epoch: 1 | Mini-Batch: 326 | Loss: 1.20765 | Accuracy: 48.13%\n",
            "Epoch: 1 | Mini-Batch: 327 | Loss: 1.25838 | Accuracy: 48.15%\n",
            "Epoch: 1 | Mini-Batch: 328 | Loss: 1.45597 | Accuracy: 48.13%\n",
            "Epoch: 1 | Mini-Batch: 329 | Loss: 1.32790 | Accuracy: 48.15%\n",
            "Epoch: 1 | Mini-Batch: 330 | Loss: 1.23298 | Accuracy: 48.18%\n",
            "Epoch: 1 | Mini-Batch: 331 | Loss: 1.30643 | Accuracy: 48.20%\n",
            "Epoch: 1 | Mini-Batch: 332 | Loss: 1.14544 | Accuracy: 48.24%\n",
            "Epoch: 1 | Mini-Batch: 333 | Loss: 1.37110 | Accuracy: 48.24%\n",
            "Epoch: 1 | Mini-Batch: 334 | Loss: 1.11052 | Accuracy: 48.27%\n",
            "Epoch: 1 | Mini-Batch: 335 | Loss: 1.16143 | Accuracy: 48.29%\n",
            "Epoch: 1 | Mini-Batch: 336 | Loss: 1.28372 | Accuracy: 48.31%\n",
            "Epoch: 1 | Mini-Batch: 337 | Loss: 1.30419 | Accuracy: 48.32%\n",
            "Epoch: 1 | Mini-Batch: 338 | Loss: 1.25734 | Accuracy: 48.35%\n",
            "Epoch: 1 | Mini-Batch: 339 | Loss: 1.17382 | Accuracy: 48.37%\n",
            "Epoch: 1 | Mini-Batch: 340 | Loss: 1.22653 | Accuracy: 48.39%\n",
            "Epoch: 1 | Mini-Batch: 341 | Loss: 1.20148 | Accuracy: 48.41%\n",
            "Epoch: 1 | Mini-Batch: 342 | Loss: 1.35758 | Accuracy: 48.43%\n",
            "Epoch: 1 | Mini-Batch: 343 | Loss: 1.27044 | Accuracy: 48.44%\n",
            "Epoch: 1 | Mini-Batch: 344 | Loss: 1.18096 | Accuracy: 48.45%\n",
            "Epoch: 1 | Mini-Batch: 345 | Loss: 1.25990 | Accuracy: 48.45%\n",
            "Epoch: 1 | Mini-Batch: 346 | Loss: 1.33780 | Accuracy: 48.47%\n",
            "Epoch: 1 | Mini-Batch: 347 | Loss: 1.23032 | Accuracy: 48.49%\n",
            "Epoch: 1 | Mini-Batch: 348 | Loss: 1.28791 | Accuracy: 48.51%\n",
            "Epoch: 1 | Mini-Batch: 349 | Loss: 1.26485 | Accuracy: 48.52%\n",
            "Epoch: 1 | Mini-Batch: 350 | Loss: 1.31967 | Accuracy: 48.52%\n",
            "Epoch: 1 | Mini-Batch: 351 | Loss: 1.33096 | Accuracy: 48.53%\n",
            "Epoch: 1 | Mini-Batch: 352 | Loss: 1.29973 | Accuracy: 48.53%\n",
            "Epoch: 1 | Mini-Batch: 353 | Loss: 1.41605 | Accuracy: 48.53%\n",
            "Epoch: 1 | Mini-Batch: 354 | Loss: 1.21494 | Accuracy: 48.57%\n",
            "Epoch: 1 | Mini-Batch: 355 | Loss: 1.42416 | Accuracy: 48.57%\n",
            "Epoch: 1 | Mini-Batch: 356 | Loss: 1.34856 | Accuracy: 48.59%\n",
            "Epoch: 1 | Mini-Batch: 357 | Loss: 1.28445 | Accuracy: 48.61%\n",
            "Epoch: 1 | Mini-Batch: 358 | Loss: 1.29590 | Accuracy: 48.61%\n",
            "Epoch: 1 | Mini-Batch: 359 | Loss: 1.44056 | Accuracy: 48.62%\n",
            "Epoch: 1 | Mini-Batch: 360 | Loss: 1.33644 | Accuracy: 48.63%\n",
            "Epoch: 1 | Mini-Batch: 361 | Loss: 1.28723 | Accuracy: 48.64%\n",
            "Epoch: 1 | Mini-Batch: 362 | Loss: 1.35148 | Accuracy: 48.65%\n",
            "Epoch: 1 | Mini-Batch: 363 | Loss: 1.28151 | Accuracy: 48.67%\n",
            "Epoch: 1 | Mini-Batch: 364 | Loss: 1.19079 | Accuracy: 48.69%\n",
            "Epoch: 1 | Mini-Batch: 365 | Loss: 1.30428 | Accuracy: 48.70%\n",
            "Epoch: 1 | Mini-Batch: 366 | Loss: 1.30735 | Accuracy: 48.71%\n",
            "Epoch: 1 | Mini-Batch: 367 | Loss: 1.29674 | Accuracy: 48.74%\n",
            "Epoch: 1 | Mini-Batch: 368 | Loss: 1.39002 | Accuracy: 48.74%\n",
            "Epoch: 1 | Mini-Batch: 369 | Loss: 1.26318 | Accuracy: 48.75%\n",
            "Epoch: 1 | Mini-Batch: 370 | Loss: 1.16330 | Accuracy: 48.77%\n",
            "Epoch: 1 | Mini-Batch: 371 | Loss: 1.25476 | Accuracy: 48.78%\n",
            "Epoch: 1 | Mini-Batch: 372 | Loss: 1.18674 | Accuracy: 48.81%\n",
            "Epoch: 1 | Mini-Batch: 373 | Loss: 1.20463 | Accuracy: 48.83%\n",
            "Epoch: 1 | Mini-Batch: 374 | Loss: 1.27431 | Accuracy: 48.84%\n",
            "Epoch: 1 | Mini-Batch: 375 | Loss: 1.16461 | Accuracy: 48.87%\n",
            "Epoch: 1 | Mini-Batch: 376 | Loss: 1.24378 | Accuracy: 48.88%\n",
            "Epoch: 1 | Mini-Batch: 377 | Loss: 1.23115 | Accuracy: 48.90%\n",
            "Epoch: 1 | Mini-Batch: 378 | Loss: 1.25182 | Accuracy: 48.92%\n",
            "Epoch: 1 | Mini-Batch: 379 | Loss: 1.15586 | Accuracy: 48.94%\n",
            "Epoch: 1 | Mini-Batch: 380 | Loss: 1.35603 | Accuracy: 48.95%\n",
            "Epoch: 1 | Mini-Batch: 381 | Loss: 1.20994 | Accuracy: 48.98%\n",
            "Epoch: 1 | Mini-Batch: 382 | Loss: 1.48396 | Accuracy: 48.97%\n",
            "Epoch: 1 | Mini-Batch: 383 | Loss: 1.35989 | Accuracy: 48.97%\n",
            "Epoch: 1 | Mini-Batch: 384 | Loss: 1.29463 | Accuracy: 48.98%\n",
            "Epoch: 1 | Mini-Batch: 385 | Loss: 1.30470 | Accuracy: 48.98%\n",
            "Epoch: 1 | Mini-Batch: 386 | Loss: 1.15320 | Accuracy: 49.01%\n",
            "Epoch: 1 | Mini-Batch: 387 | Loss: 1.39387 | Accuracy: 49.02%\n",
            "Epoch: 1 | Mini-Batch: 388 | Loss: 1.19346 | Accuracy: 49.04%\n",
            "Epoch: 1 | Mini-Batch: 389 | Loss: 1.43670 | Accuracy: 49.03%\n",
            "Epoch: 1 | Mini-Batch: 390 | Loss: 1.39849 | Accuracy: 49.02%\n",
            "Epoch: 2 | Mini-Batch: 0 | Loss: 1.21390 | Accuracy: 53.91%\n",
            "Epoch: 2 | Mini-Batch: 1 | Loss: 1.20391 | Accuracy: 53.91%\n",
            "Epoch: 2 | Mini-Batch: 2 | Loss: 1.34358 | Accuracy: 54.17%\n",
            "Epoch: 2 | Mini-Batch: 3 | Loss: 1.13671 | Accuracy: 55.47%\n",
            "Epoch: 2 | Mini-Batch: 4 | Loss: 1.44622 | Accuracy: 53.91%\n",
            "Epoch: 2 | Mini-Batch: 5 | Loss: 1.33719 | Accuracy: 53.12%\n",
            "Epoch: 2 | Mini-Batch: 6 | Loss: 1.28349 | Accuracy: 53.35%\n",
            "Epoch: 2 | Mini-Batch: 7 | Loss: 1.17915 | Accuracy: 53.42%\n",
            "Epoch: 2 | Mini-Batch: 8 | Loss: 1.22088 | Accuracy: 53.73%\n",
            "Epoch: 2 | Mini-Batch: 9 | Loss: 1.40611 | Accuracy: 53.44%\n",
            "Epoch: 2 | Mini-Batch: 10 | Loss: 1.20913 | Accuracy: 53.62%\n",
            "Epoch: 2 | Mini-Batch: 11 | Loss: 1.19121 | Accuracy: 54.23%\n",
            "Epoch: 2 | Mini-Batch: 12 | Loss: 1.17142 | Accuracy: 54.63%\n",
            "Epoch: 2 | Mini-Batch: 13 | Loss: 1.41301 | Accuracy: 54.46%\n",
            "Epoch: 2 | Mini-Batch: 14 | Loss: 1.06075 | Accuracy: 54.95%\n",
            "Epoch: 2 | Mini-Batch: 15 | Loss: 1.21817 | Accuracy: 55.13%\n",
            "Epoch: 2 | Mini-Batch: 16 | Loss: 1.55170 | Accuracy: 54.64%\n",
            "Epoch: 2 | Mini-Batch: 17 | Loss: 1.15424 | Accuracy: 54.73%\n",
            "Epoch: 2 | Mini-Batch: 18 | Loss: 1.25966 | Accuracy: 54.56%\n",
            "Epoch: 2 | Mini-Batch: 19 | Loss: 1.27347 | Accuracy: 54.69%\n",
            "Epoch: 2 | Mini-Batch: 20 | Loss: 1.27271 | Accuracy: 54.72%\n",
            "Epoch: 2 | Mini-Batch: 21 | Loss: 1.15096 | Accuracy: 54.90%\n",
            "Epoch: 2 | Mini-Batch: 22 | Loss: 1.20675 | Accuracy: 54.86%\n",
            "Epoch: 2 | Mini-Batch: 23 | Loss: 1.53887 | Accuracy: 54.52%\n",
            "Epoch: 2 | Mini-Batch: 24 | Loss: 1.16272 | Accuracy: 54.47%\n",
            "Epoch: 2 | Mini-Batch: 25 | Loss: 1.32354 | Accuracy: 54.39%\n",
            "Epoch: 2 | Mini-Batch: 26 | Loss: 1.29512 | Accuracy: 54.51%\n",
            "Epoch: 2 | Mini-Batch: 27 | Loss: 1.24756 | Accuracy: 54.41%\n",
            "Epoch: 2 | Mini-Batch: 28 | Loss: 1.34318 | Accuracy: 54.42%\n",
            "Epoch: 2 | Mini-Batch: 29 | Loss: 1.32200 | Accuracy: 54.30%\n",
            "Epoch: 2 | Mini-Batch: 30 | Loss: 1.41103 | Accuracy: 54.16%\n",
            "Epoch: 2 | Mini-Batch: 31 | Loss: 1.44337 | Accuracy: 54.03%\n",
            "Epoch: 2 | Mini-Batch: 32 | Loss: 1.17876 | Accuracy: 53.81%\n",
            "Epoch: 2 | Mini-Batch: 33 | Loss: 1.31911 | Accuracy: 53.88%\n",
            "Epoch: 2 | Mini-Batch: 34 | Loss: 1.20954 | Accuracy: 53.84%\n",
            "Epoch: 2 | Mini-Batch: 35 | Loss: 1.21761 | Accuracy: 53.97%\n",
            "Epoch: 2 | Mini-Batch: 36 | Loss: 1.10826 | Accuracy: 54.29%\n",
            "Epoch: 2 | Mini-Batch: 37 | Loss: 1.16588 | Accuracy: 54.40%\n",
            "Epoch: 2 | Mini-Batch: 38 | Loss: 1.35649 | Accuracy: 54.37%\n",
            "Epoch: 2 | Mini-Batch: 39 | Loss: 1.23818 | Accuracy: 54.34%\n",
            "Epoch: 2 | Mini-Batch: 40 | Loss: 1.26147 | Accuracy: 54.44%\n",
            "Epoch: 2 | Mini-Batch: 41 | Loss: 1.20612 | Accuracy: 54.45%\n",
            "Epoch: 2 | Mini-Batch: 42 | Loss: 1.27441 | Accuracy: 54.45%\n",
            "Epoch: 2 | Mini-Batch: 43 | Loss: 1.20429 | Accuracy: 54.44%\n",
            "Epoch: 2 | Mini-Batch: 44 | Loss: 1.21973 | Accuracy: 54.44%\n",
            "Epoch: 2 | Mini-Batch: 45 | Loss: 1.39403 | Accuracy: 54.33%\n",
            "Epoch: 2 | Mini-Batch: 46 | Loss: 1.26106 | Accuracy: 54.42%\n",
            "Epoch: 2 | Mini-Batch: 47 | Loss: 1.13901 | Accuracy: 54.56%\n",
            "Epoch: 2 | Mini-Batch: 48 | Loss: 1.32281 | Accuracy: 54.54%\n",
            "Epoch: 2 | Mini-Batch: 49 | Loss: 1.24322 | Accuracy: 54.47%\n",
            "Epoch: 2 | Mini-Batch: 50 | Loss: 1.27254 | Accuracy: 54.44%\n",
            "Epoch: 2 | Mini-Batch: 51 | Loss: 1.26028 | Accuracy: 54.48%\n",
            "Epoch: 2 | Mini-Batch: 52 | Loss: 1.39400 | Accuracy: 54.32%\n",
            "Epoch: 2 | Mini-Batch: 53 | Loss: 1.18188 | Accuracy: 54.37%\n",
            "Epoch: 2 | Mini-Batch: 54 | Loss: 1.17218 | Accuracy: 54.45%\n",
            "Epoch: 2 | Mini-Batch: 55 | Loss: 1.46788 | Accuracy: 54.24%\n",
            "Epoch: 2 | Mini-Batch: 56 | Loss: 1.25289 | Accuracy: 54.21%\n",
            "Epoch: 2 | Mini-Batch: 57 | Loss: 1.22770 | Accuracy: 54.24%\n",
            "Epoch: 2 | Mini-Batch: 58 | Loss: 1.27017 | Accuracy: 54.34%\n",
            "Epoch: 2 | Mini-Batch: 59 | Loss: 1.35115 | Accuracy: 54.35%\n",
            "Epoch: 2 | Mini-Batch: 60 | Loss: 1.09276 | Accuracy: 54.43%\n",
            "Epoch: 2 | Mini-Batch: 61 | Loss: 1.37527 | Accuracy: 54.37%\n",
            "Epoch: 2 | Mini-Batch: 62 | Loss: 1.11174 | Accuracy: 54.49%\n",
            "Epoch: 2 | Mini-Batch: 63 | Loss: 1.26102 | Accuracy: 54.55%\n",
            "Epoch: 2 | Mini-Batch: 64 | Loss: 1.25603 | Accuracy: 54.56%\n",
            "Epoch: 2 | Mini-Batch: 65 | Loss: 1.34824 | Accuracy: 54.62%\n",
            "Epoch: 2 | Mini-Batch: 66 | Loss: 1.18192 | Accuracy: 54.70%\n",
            "Epoch: 2 | Mini-Batch: 67 | Loss: 1.28180 | Accuracy: 54.72%\n",
            "Epoch: 2 | Mini-Batch: 68 | Loss: 1.18766 | Accuracy: 54.83%\n",
            "Epoch: 2 | Mini-Batch: 69 | Loss: 1.30847 | Accuracy: 54.77%\n",
            "Epoch: 2 | Mini-Batch: 70 | Loss: 1.09980 | Accuracy: 54.86%\n",
            "Epoch: 2 | Mini-Batch: 71 | Loss: 1.28235 | Accuracy: 54.86%\n",
            "Epoch: 2 | Mini-Batch: 72 | Loss: 1.21893 | Accuracy: 54.79%\n",
            "Epoch: 2 | Mini-Batch: 73 | Loss: 1.18993 | Accuracy: 54.80%\n",
            "Epoch: 2 | Mini-Batch: 74 | Loss: 1.05249 | Accuracy: 54.92%\n",
            "Epoch: 2 | Mini-Batch: 75 | Loss: 1.39236 | Accuracy: 54.84%\n",
            "Epoch: 2 | Mini-Batch: 76 | Loss: 1.19230 | Accuracy: 54.87%\n",
            "Epoch: 2 | Mini-Batch: 77 | Loss: 1.12303 | Accuracy: 54.94%\n",
            "Epoch: 2 | Mini-Batch: 78 | Loss: 1.37958 | Accuracy: 54.82%\n",
            "Epoch: 2 | Mini-Batch: 79 | Loss: 1.26977 | Accuracy: 54.79%\n",
            "Epoch: 2 | Mini-Batch: 80 | Loss: 1.26170 | Accuracy: 54.76%\n",
            "Epoch: 2 | Mini-Batch: 81 | Loss: 1.13219 | Accuracy: 54.86%\n",
            "Epoch: 2 | Mini-Batch: 82 | Loss: 0.97324 | Accuracy: 55.05%\n",
            "Epoch: 2 | Mini-Batch: 83 | Loss: 1.25754 | Accuracy: 55.03%\n",
            "Epoch: 2 | Mini-Batch: 84 | Loss: 1.27972 | Accuracy: 55.06%\n",
            "Epoch: 2 | Mini-Batch: 85 | Loss: 1.48091 | Accuracy: 54.99%\n",
            "Epoch: 2 | Mini-Batch: 86 | Loss: 1.25382 | Accuracy: 54.97%\n",
            "Epoch: 2 | Mini-Batch: 87 | Loss: 1.15992 | Accuracy: 54.97%\n",
            "Epoch: 2 | Mini-Batch: 88 | Loss: 1.15891 | Accuracy: 54.97%\n",
            "Epoch: 2 | Mini-Batch: 89 | Loss: 0.99592 | Accuracy: 55.10%\n",
            "Epoch: 2 | Mini-Batch: 90 | Loss: 1.08069 | Accuracy: 55.16%\n",
            "Epoch: 2 | Mini-Batch: 91 | Loss: 1.25772 | Accuracy: 55.18%\n",
            "Epoch: 2 | Mini-Batch: 92 | Loss: 1.15636 | Accuracy: 55.24%\n",
            "Epoch: 2 | Mini-Batch: 93 | Loss: 1.27378 | Accuracy: 55.22%\n",
            "Epoch: 2 | Mini-Batch: 94 | Loss: 1.15351 | Accuracy: 55.31%\n",
            "Epoch: 2 | Mini-Batch: 95 | Loss: 1.05504 | Accuracy: 55.39%\n",
            "Epoch: 2 | Mini-Batch: 96 | Loss: 1.29912 | Accuracy: 55.38%\n",
            "Epoch: 2 | Mini-Batch: 97 | Loss: 1.33662 | Accuracy: 55.32%\n",
            "Epoch: 2 | Mini-Batch: 98 | Loss: 1.17781 | Accuracy: 55.31%\n",
            "Epoch: 2 | Mini-Batch: 99 | Loss: 1.12446 | Accuracy: 55.34%\n",
            "Epoch: 2 | Mini-Batch: 100 | Loss: 1.18113 | Accuracy: 55.36%\n",
            "Epoch: 2 | Mini-Batch: 101 | Loss: 1.23837 | Accuracy: 55.35%\n",
            "Epoch: 2 | Mini-Batch: 102 | Loss: 1.32224 | Accuracy: 55.38%\n",
            "Epoch: 2 | Mini-Batch: 103 | Loss: 1.30416 | Accuracy: 55.42%\n",
            "Epoch: 2 | Mini-Batch: 104 | Loss: 1.24181 | Accuracy: 55.39%\n",
            "Epoch: 2 | Mini-Batch: 105 | Loss: 1.14755 | Accuracy: 55.37%\n",
            "Epoch: 2 | Mini-Batch: 106 | Loss: 1.19165 | Accuracy: 55.41%\n",
            "Epoch: 2 | Mini-Batch: 107 | Loss: 1.20537 | Accuracy: 55.37%\n",
            "Epoch: 2 | Mini-Batch: 108 | Loss: 1.12258 | Accuracy: 55.43%\n",
            "Epoch: 2 | Mini-Batch: 109 | Loss: 1.22649 | Accuracy: 55.44%\n",
            "Epoch: 2 | Mini-Batch: 110 | Loss: 1.23323 | Accuracy: 55.42%\n",
            "Epoch: 2 | Mini-Batch: 111 | Loss: 1.21405 | Accuracy: 55.41%\n",
            "Epoch: 2 | Mini-Batch: 112 | Loss: 1.23753 | Accuracy: 55.38%\n",
            "Epoch: 2 | Mini-Batch: 113 | Loss: 1.25650 | Accuracy: 55.35%\n",
            "Epoch: 2 | Mini-Batch: 114 | Loss: 1.15498 | Accuracy: 55.39%\n",
            "Epoch: 2 | Mini-Batch: 115 | Loss: 1.29023 | Accuracy: 55.39%\n",
            "Epoch: 2 | Mini-Batch: 116 | Loss: 1.22048 | Accuracy: 55.38%\n",
            "Epoch: 2 | Mini-Batch: 117 | Loss: 1.12089 | Accuracy: 55.42%\n",
            "Epoch: 2 | Mini-Batch: 118 | Loss: 1.17018 | Accuracy: 55.44%\n",
            "Epoch: 2 | Mini-Batch: 119 | Loss: 1.19825 | Accuracy: 55.47%\n",
            "Epoch: 2 | Mini-Batch: 120 | Loss: 1.10601 | Accuracy: 55.50%\n",
            "Epoch: 2 | Mini-Batch: 121 | Loss: 1.09954 | Accuracy: 55.56%\n",
            "Epoch: 2 | Mini-Batch: 122 | Loss: 1.29924 | Accuracy: 55.49%\n",
            "Epoch: 2 | Mini-Batch: 123 | Loss: 1.12273 | Accuracy: 55.54%\n",
            "Epoch: 2 | Mini-Batch: 124 | Loss: 1.16135 | Accuracy: 55.58%\n",
            "Epoch: 2 | Mini-Batch: 125 | Loss: 1.09436 | Accuracy: 55.64%\n",
            "Epoch: 2 | Mini-Batch: 126 | Loss: 1.07797 | Accuracy: 55.68%\n",
            "Epoch: 2 | Mini-Batch: 127 | Loss: 1.13109 | Accuracy: 55.72%\n",
            "Epoch: 2 | Mini-Batch: 128 | Loss: 1.12015 | Accuracy: 55.73%\n",
            "Epoch: 2 | Mini-Batch: 129 | Loss: 1.08816 | Accuracy: 55.80%\n",
            "Epoch: 2 | Mini-Batch: 130 | Loss: 1.06598 | Accuracy: 55.80%\n",
            "Epoch: 2 | Mini-Batch: 131 | Loss: 1.17929 | Accuracy: 55.81%\n",
            "Epoch: 2 | Mini-Batch: 132 | Loss: 1.13439 | Accuracy: 55.82%\n",
            "Epoch: 2 | Mini-Batch: 133 | Loss: 1.20805 | Accuracy: 55.82%\n",
            "Epoch: 2 | Mini-Batch: 134 | Loss: 1.25463 | Accuracy: 55.86%\n",
            "Epoch: 2 | Mini-Batch: 135 | Loss: 1.21171 | Accuracy: 55.87%\n",
            "Epoch: 2 | Mini-Batch: 136 | Loss: 1.25352 | Accuracy: 55.84%\n",
            "Epoch: 2 | Mini-Batch: 137 | Loss: 1.00017 | Accuracy: 55.88%\n",
            "Epoch: 2 | Mini-Batch: 138 | Loss: 1.29453 | Accuracy: 55.86%\n",
            "Epoch: 2 | Mini-Batch: 139 | Loss: 1.19208 | Accuracy: 55.87%\n",
            "Epoch: 2 | Mini-Batch: 140 | Loss: 1.06468 | Accuracy: 55.93%\n",
            "Epoch: 2 | Mini-Batch: 141 | Loss: 1.08690 | Accuracy: 56.00%\n",
            "Epoch: 2 | Mini-Batch: 142 | Loss: 1.16398 | Accuracy: 56.03%\n",
            "Epoch: 2 | Mini-Batch: 143 | Loss: 1.17515 | Accuracy: 55.98%\n",
            "Epoch: 2 | Mini-Batch: 144 | Loss: 1.15263 | Accuracy: 56.01%\n",
            "Epoch: 2 | Mini-Batch: 145 | Loss: 1.33334 | Accuracy: 56.01%\n",
            "Epoch: 2 | Mini-Batch: 146 | Loss: 1.08207 | Accuracy: 56.03%\n",
            "Epoch: 2 | Mini-Batch: 147 | Loss: 1.29453 | Accuracy: 55.99%\n",
            "Epoch: 2 | Mini-Batch: 148 | Loss: 1.03574 | Accuracy: 56.04%\n",
            "Epoch: 2 | Mini-Batch: 149 | Loss: 1.02082 | Accuracy: 56.09%\n",
            "Epoch: 2 | Mini-Batch: 150 | Loss: 1.16508 | Accuracy: 56.09%\n",
            "Epoch: 2 | Mini-Batch: 151 | Loss: 1.13989 | Accuracy: 56.11%\n",
            "Epoch: 2 | Mini-Batch: 152 | Loss: 1.23080 | Accuracy: 56.12%\n",
            "Epoch: 2 | Mini-Batch: 153 | Loss: 1.10114 | Accuracy: 56.15%\n",
            "Epoch: 2 | Mini-Batch: 154 | Loss: 1.17095 | Accuracy: 56.17%\n",
            "Epoch: 2 | Mini-Batch: 155 | Loss: 1.25968 | Accuracy: 56.18%\n",
            "Epoch: 2 | Mini-Batch: 156 | Loss: 1.17100 | Accuracy: 56.19%\n",
            "Epoch: 2 | Mini-Batch: 157 | Loss: 1.30248 | Accuracy: 56.16%\n",
            "Epoch: 2 | Mini-Batch: 158 | Loss: 1.29603 | Accuracy: 56.11%\n",
            "Epoch: 2 | Mini-Batch: 159 | Loss: 1.16491 | Accuracy: 56.09%\n",
            "Epoch: 2 | Mini-Batch: 160 | Loss: 1.10184 | Accuracy: 56.13%\n",
            "Epoch: 2 | Mini-Batch: 161 | Loss: 1.24651 | Accuracy: 56.12%\n",
            "Epoch: 2 | Mini-Batch: 162 | Loss: 1.08049 | Accuracy: 56.12%\n",
            "Epoch: 2 | Mini-Batch: 163 | Loss: 1.10020 | Accuracy: 56.13%\n",
            "Epoch: 2 | Mini-Batch: 164 | Loss: 1.22707 | Accuracy: 56.11%\n",
            "Epoch: 2 | Mini-Batch: 165 | Loss: 1.21261 | Accuracy: 56.13%\n",
            "Epoch: 2 | Mini-Batch: 166 | Loss: 1.16770 | Accuracy: 56.14%\n",
            "Epoch: 2 | Mini-Batch: 167 | Loss: 1.20172 | Accuracy: 56.14%\n",
            "Epoch: 2 | Mini-Batch: 168 | Loss: 1.01029 | Accuracy: 56.17%\n",
            "Epoch: 2 | Mini-Batch: 169 | Loss: 1.20314 | Accuracy: 56.16%\n",
            "Epoch: 2 | Mini-Batch: 170 | Loss: 1.07707 | Accuracy: 56.20%\n",
            "Epoch: 2 | Mini-Batch: 171 | Loss: 1.19004 | Accuracy: 56.23%\n",
            "Epoch: 2 | Mini-Batch: 172 | Loss: 1.11092 | Accuracy: 56.23%\n",
            "Epoch: 2 | Mini-Batch: 173 | Loss: 1.01679 | Accuracy: 56.29%\n",
            "Epoch: 2 | Mini-Batch: 174 | Loss: 0.96513 | Accuracy: 56.33%\n",
            "Epoch: 2 | Mini-Batch: 175 | Loss: 1.17038 | Accuracy: 56.36%\n",
            "Epoch: 2 | Mini-Batch: 176 | Loss: 1.03783 | Accuracy: 56.38%\n",
            "Epoch: 2 | Mini-Batch: 177 | Loss: 1.33214 | Accuracy: 56.38%\n",
            "Epoch: 2 | Mini-Batch: 178 | Loss: 1.23922 | Accuracy: 56.38%\n",
            "Epoch: 2 | Mini-Batch: 179 | Loss: 1.17653 | Accuracy: 56.35%\n",
            "Epoch: 2 | Mini-Batch: 180 | Loss: 1.06730 | Accuracy: 56.37%\n",
            "Epoch: 2 | Mini-Batch: 181 | Loss: 1.11661 | Accuracy: 56.40%\n",
            "Epoch: 2 | Mini-Batch: 182 | Loss: 1.06730 | Accuracy: 56.44%\n",
            "Epoch: 2 | Mini-Batch: 183 | Loss: 1.24626 | Accuracy: 56.42%\n",
            "Epoch: 2 | Mini-Batch: 184 | Loss: 1.23382 | Accuracy: 56.44%\n",
            "Epoch: 2 | Mini-Batch: 185 | Loss: 1.18259 | Accuracy: 56.45%\n",
            "Epoch: 2 | Mini-Batch: 186 | Loss: 1.23281 | Accuracy: 56.43%\n",
            "Epoch: 2 | Mini-Batch: 187 | Loss: 1.09544 | Accuracy: 56.44%\n",
            "Epoch: 2 | Mini-Batch: 188 | Loss: 1.13474 | Accuracy: 56.46%\n",
            "Epoch: 2 | Mini-Batch: 189 | Loss: 1.33429 | Accuracy: 56.46%\n",
            "Epoch: 2 | Mini-Batch: 190 | Loss: 1.12740 | Accuracy: 56.48%\n",
            "Epoch: 2 | Mini-Batch: 191 | Loss: 1.14470 | Accuracy: 56.47%\n",
            "Epoch: 2 | Mini-Batch: 192 | Loss: 1.16902 | Accuracy: 56.49%\n",
            "Epoch: 2 | Mini-Batch: 193 | Loss: 1.18851 | Accuracy: 56.48%\n",
            "Epoch: 2 | Mini-Batch: 194 | Loss: 1.11917 | Accuracy: 56.48%\n",
            "Epoch: 2 | Mini-Batch: 195 | Loss: 1.11162 | Accuracy: 56.50%\n",
            "Epoch: 2 | Mini-Batch: 196 | Loss: 1.09744 | Accuracy: 56.52%\n",
            "Epoch: 2 | Mini-Batch: 197 | Loss: 1.21236 | Accuracy: 56.54%\n",
            "Epoch: 2 | Mini-Batch: 198 | Loss: 1.33426 | Accuracy: 56.51%\n",
            "Epoch: 2 | Mini-Batch: 199 | Loss: 1.04610 | Accuracy: 56.54%\n",
            "Epoch: 2 | Mini-Batch: 200 | Loss: 1.07903 | Accuracy: 56.54%\n",
            "Epoch: 2 | Mini-Batch: 201 | Loss: 1.20824 | Accuracy: 56.53%\n",
            "Epoch: 2 | Mini-Batch: 202 | Loss: 1.20730 | Accuracy: 56.55%\n",
            "Epoch: 2 | Mini-Batch: 203 | Loss: 1.18707 | Accuracy: 56.57%\n",
            "Epoch: 2 | Mini-Batch: 204 | Loss: 1.02988 | Accuracy: 56.59%\n",
            "Epoch: 2 | Mini-Batch: 205 | Loss: 1.12842 | Accuracy: 56.60%\n",
            "Epoch: 2 | Mini-Batch: 206 | Loss: 1.10585 | Accuracy: 56.60%\n",
            "Epoch: 2 | Mini-Batch: 207 | Loss: 1.14392 | Accuracy: 56.62%\n",
            "Epoch: 2 | Mini-Batch: 208 | Loss: 1.25645 | Accuracy: 56.62%\n",
            "Epoch: 2 | Mini-Batch: 209 | Loss: 1.33691 | Accuracy: 56.58%\n",
            "Epoch: 2 | Mini-Batch: 210 | Loss: 1.13172 | Accuracy: 56.59%\n",
            "Epoch: 2 | Mini-Batch: 211 | Loss: 1.21248 | Accuracy: 56.61%\n",
            "Epoch: 2 | Mini-Batch: 212 | Loss: 1.17732 | Accuracy: 56.61%\n",
            "Epoch: 2 | Mini-Batch: 213 | Loss: 1.19043 | Accuracy: 56.62%\n",
            "Epoch: 2 | Mini-Batch: 214 | Loss: 1.04233 | Accuracy: 56.65%\n",
            "Epoch: 2 | Mini-Batch: 215 | Loss: 1.27469 | Accuracy: 56.65%\n",
            "Epoch: 2 | Mini-Batch: 216 | Loss: 1.17382 | Accuracy: 56.68%\n",
            "Epoch: 2 | Mini-Batch: 217 | Loss: 0.96121 | Accuracy: 56.72%\n",
            "Epoch: 2 | Mini-Batch: 218 | Loss: 1.17003 | Accuracy: 56.74%\n",
            "Epoch: 2 | Mini-Batch: 219 | Loss: 1.08731 | Accuracy: 56.74%\n",
            "Epoch: 2 | Mini-Batch: 220 | Loss: 1.07554 | Accuracy: 56.78%\n",
            "Epoch: 2 | Mini-Batch: 221 | Loss: 1.06095 | Accuracy: 56.77%\n",
            "Epoch: 2 | Mini-Batch: 222 | Loss: 0.98803 | Accuracy: 56.82%\n",
            "Epoch: 2 | Mini-Batch: 223 | Loss: 1.02218 | Accuracy: 56.85%\n",
            "Epoch: 2 | Mini-Batch: 224 | Loss: 0.97436 | Accuracy: 56.90%\n",
            "Epoch: 2 | Mini-Batch: 225 | Loss: 1.01090 | Accuracy: 56.93%\n",
            "Epoch: 2 | Mini-Batch: 226 | Loss: 1.29017 | Accuracy: 56.92%\n",
            "Epoch: 2 | Mini-Batch: 227 | Loss: 1.21670 | Accuracy: 56.91%\n",
            "Epoch: 2 | Mini-Batch: 228 | Loss: 1.29523 | Accuracy: 56.91%\n",
            "Epoch: 2 | Mini-Batch: 229 | Loss: 1.16483 | Accuracy: 56.93%\n",
            "Epoch: 2 | Mini-Batch: 230 | Loss: 1.08950 | Accuracy: 56.93%\n",
            "Epoch: 2 | Mini-Batch: 231 | Loss: 1.22718 | Accuracy: 56.94%\n",
            "Epoch: 2 | Mini-Batch: 232 | Loss: 1.01331 | Accuracy: 56.97%\n",
            "Epoch: 2 | Mini-Batch: 233 | Loss: 1.07728 | Accuracy: 56.99%\n",
            "Epoch: 2 | Mini-Batch: 234 | Loss: 1.14778 | Accuracy: 57.00%\n",
            "Epoch: 2 | Mini-Batch: 235 | Loss: 1.21213 | Accuracy: 56.98%\n",
            "Epoch: 2 | Mini-Batch: 236 | Loss: 1.30674 | Accuracy: 56.98%\n",
            "Epoch: 2 | Mini-Batch: 237 | Loss: 1.15128 | Accuracy: 56.98%\n",
            "Epoch: 2 | Mini-Batch: 238 | Loss: 1.10219 | Accuracy: 57.01%\n",
            "Epoch: 2 | Mini-Batch: 239 | Loss: 1.18759 | Accuracy: 57.00%\n",
            "Epoch: 2 | Mini-Batch: 240 | Loss: 1.05132 | Accuracy: 57.03%\n",
            "Epoch: 2 | Mini-Batch: 241 | Loss: 1.12568 | Accuracy: 57.03%\n",
            "Epoch: 2 | Mini-Batch: 242 | Loss: 1.21117 | Accuracy: 57.03%\n",
            "Epoch: 2 | Mini-Batch: 243 | Loss: 1.11497 | Accuracy: 57.06%\n",
            "Epoch: 2 | Mini-Batch: 244 | Loss: 1.22084 | Accuracy: 57.04%\n",
            "Epoch: 2 | Mini-Batch: 245 | Loss: 1.20913 | Accuracy: 57.05%\n",
            "Epoch: 2 | Mini-Batch: 246 | Loss: 0.93046 | Accuracy: 57.10%\n",
            "Epoch: 2 | Mini-Batch: 247 | Loss: 1.19869 | Accuracy: 57.09%\n",
            "Epoch: 2 | Mini-Batch: 248 | Loss: 1.10577 | Accuracy: 57.11%\n",
            "Epoch: 2 | Mini-Batch: 249 | Loss: 1.08243 | Accuracy: 57.12%\n",
            "Epoch: 2 | Mini-Batch: 250 | Loss: 0.99074 | Accuracy: 57.14%\n",
            "Epoch: 2 | Mini-Batch: 251 | Loss: 1.09921 | Accuracy: 57.15%\n",
            "Epoch: 2 | Mini-Batch: 252 | Loss: 1.13145 | Accuracy: 57.18%\n",
            "Epoch: 2 | Mini-Batch: 253 | Loss: 1.33175 | Accuracy: 57.18%\n",
            "Epoch: 2 | Mini-Batch: 254 | Loss: 1.01024 | Accuracy: 57.21%\n",
            "Epoch: 2 | Mini-Batch: 255 | Loss: 1.09409 | Accuracy: 57.23%\n",
            "Epoch: 2 | Mini-Batch: 256 | Loss: 1.00568 | Accuracy: 57.25%\n",
            "Epoch: 2 | Mini-Batch: 257 | Loss: 1.11643 | Accuracy: 57.25%\n",
            "Epoch: 2 | Mini-Batch: 258 | Loss: 1.17935 | Accuracy: 57.25%\n",
            "Epoch: 2 | Mini-Batch: 259 | Loss: 1.06286 | Accuracy: 57.29%\n",
            "Epoch: 2 | Mini-Batch: 260 | Loss: 1.08842 | Accuracy: 57.32%\n",
            "Epoch: 2 | Mini-Batch: 261 | Loss: 1.13587 | Accuracy: 57.30%\n",
            "Epoch: 2 | Mini-Batch: 262 | Loss: 1.15336 | Accuracy: 57.31%\n",
            "Epoch: 2 | Mini-Batch: 263 | Loss: 1.02963 | Accuracy: 57.33%\n",
            "Epoch: 2 | Mini-Batch: 264 | Loss: 1.13183 | Accuracy: 57.36%\n",
            "Epoch: 2 | Mini-Batch: 265 | Loss: 1.06420 | Accuracy: 57.40%\n",
            "Epoch: 2 | Mini-Batch: 266 | Loss: 1.07221 | Accuracy: 57.42%\n",
            "Epoch: 2 | Mini-Batch: 267 | Loss: 1.01933 | Accuracy: 57.45%\n",
            "Epoch: 2 | Mini-Batch: 268 | Loss: 1.14699 | Accuracy: 57.47%\n",
            "Epoch: 2 | Mini-Batch: 269 | Loss: 1.09388 | Accuracy: 57.50%\n",
            "Epoch: 2 | Mini-Batch: 270 | Loss: 1.03555 | Accuracy: 57.51%\n",
            "Epoch: 2 | Mini-Batch: 271 | Loss: 1.11000 | Accuracy: 57.53%\n",
            "Epoch: 2 | Mini-Batch: 272 | Loss: 1.11274 | Accuracy: 57.52%\n",
            "Epoch: 2 | Mini-Batch: 273 | Loss: 1.01521 | Accuracy: 57.55%\n",
            "Epoch: 2 | Mini-Batch: 274 | Loss: 1.22785 | Accuracy: 57.56%\n",
            "Epoch: 2 | Mini-Batch: 275 | Loss: 1.29141 | Accuracy: 57.54%\n",
            "Epoch: 2 | Mini-Batch: 276 | Loss: 1.22414 | Accuracy: 57.55%\n",
            "Epoch: 2 | Mini-Batch: 277 | Loss: 1.20413 | Accuracy: 57.55%\n",
            "Epoch: 2 | Mini-Batch: 278 | Loss: 1.24363 | Accuracy: 57.53%\n",
            "Epoch: 2 | Mini-Batch: 279 | Loss: 1.15916 | Accuracy: 57.54%\n",
            "Epoch: 2 | Mini-Batch: 280 | Loss: 1.20162 | Accuracy: 57.55%\n",
            "Epoch: 2 | Mini-Batch: 281 | Loss: 1.27755 | Accuracy: 57.53%\n",
            "Epoch: 2 | Mini-Batch: 282 | Loss: 1.01210 | Accuracy: 57.56%\n",
            "Epoch: 2 | Mini-Batch: 283 | Loss: 1.07292 | Accuracy: 57.58%\n",
            "Epoch: 2 | Mini-Batch: 284 | Loss: 0.92262 | Accuracy: 57.62%\n",
            "Epoch: 2 | Mini-Batch: 285 | Loss: 0.98112 | Accuracy: 57.63%\n",
            "Epoch: 2 | Mini-Batch: 286 | Loss: 1.13483 | Accuracy: 57.63%\n",
            "Epoch: 2 | Mini-Batch: 287 | Loss: 1.23658 | Accuracy: 57.63%\n",
            "Epoch: 2 | Mini-Batch: 288 | Loss: 1.16230 | Accuracy: 57.64%\n",
            "Epoch: 2 | Mini-Batch: 289 | Loss: 1.10550 | Accuracy: 57.65%\n",
            "Epoch: 2 | Mini-Batch: 290 | Loss: 0.94443 | Accuracy: 57.69%\n",
            "Epoch: 2 | Mini-Batch: 291 | Loss: 1.04740 | Accuracy: 57.72%\n",
            "Epoch: 2 | Mini-Batch: 292 | Loss: 1.14797 | Accuracy: 57.72%\n",
            "Epoch: 2 | Mini-Batch: 293 | Loss: 1.13017 | Accuracy: 57.72%\n",
            "Epoch: 2 | Mini-Batch: 294 | Loss: 1.11046 | Accuracy: 57.73%\n",
            "Epoch: 2 | Mini-Batch: 295 | Loss: 0.99861 | Accuracy: 57.75%\n",
            "Epoch: 2 | Mini-Batch: 296 | Loss: 1.21800 | Accuracy: 57.76%\n",
            "Epoch: 2 | Mini-Batch: 297 | Loss: 1.13128 | Accuracy: 57.78%\n",
            "Epoch: 2 | Mini-Batch: 298 | Loss: 1.13596 | Accuracy: 57.78%\n",
            "Epoch: 2 | Mini-Batch: 299 | Loss: 0.97409 | Accuracy: 57.80%\n",
            "Epoch: 2 | Mini-Batch: 300 | Loss: 1.32077 | Accuracy: 57.77%\n",
            "Epoch: 2 | Mini-Batch: 301 | Loss: 0.98395 | Accuracy: 57.81%\n",
            "Epoch: 2 | Mini-Batch: 302 | Loss: 1.13944 | Accuracy: 57.82%\n",
            "Epoch: 2 | Mini-Batch: 303 | Loss: 1.26818 | Accuracy: 57.80%\n",
            "Epoch: 2 | Mini-Batch: 304 | Loss: 1.10165 | Accuracy: 57.81%\n",
            "Epoch: 2 | Mini-Batch: 305 | Loss: 1.05051 | Accuracy: 57.83%\n",
            "Epoch: 2 | Mini-Batch: 306 | Loss: 1.16652 | Accuracy: 57.83%\n",
            "Epoch: 2 | Mini-Batch: 307 | Loss: 1.06779 | Accuracy: 57.84%\n",
            "Epoch: 2 | Mini-Batch: 308 | Loss: 1.13989 | Accuracy: 57.86%\n",
            "Epoch: 2 | Mini-Batch: 309 | Loss: 1.01007 | Accuracy: 57.88%\n",
            "Epoch: 2 | Mini-Batch: 310 | Loss: 1.02094 | Accuracy: 57.89%\n",
            "Epoch: 2 | Mini-Batch: 311 | Loss: 1.14423 | Accuracy: 57.90%\n",
            "Epoch: 2 | Mini-Batch: 312 | Loss: 1.17197 | Accuracy: 57.89%\n",
            "Epoch: 2 | Mini-Batch: 313 | Loss: 1.05680 | Accuracy: 57.90%\n",
            "Epoch: 2 | Mini-Batch: 314 | Loss: 1.09032 | Accuracy: 57.92%\n",
            "Epoch: 2 | Mini-Batch: 315 | Loss: 1.05226 | Accuracy: 57.95%\n",
            "Epoch: 2 | Mini-Batch: 316 | Loss: 1.09921 | Accuracy: 57.95%\n",
            "Epoch: 2 | Mini-Batch: 317 | Loss: 0.91317 | Accuracy: 57.98%\n",
            "Epoch: 2 | Mini-Batch: 318 | Loss: 1.02399 | Accuracy: 58.00%\n",
            "Epoch: 2 | Mini-Batch: 319 | Loss: 1.05443 | Accuracy: 58.01%\n",
            "Epoch: 2 | Mini-Batch: 320 | Loss: 0.98299 | Accuracy: 58.02%\n",
            "Epoch: 2 | Mini-Batch: 321 | Loss: 0.96683 | Accuracy: 58.04%\n",
            "Epoch: 2 | Mini-Batch: 322 | Loss: 0.95652 | Accuracy: 58.07%\n",
            "Epoch: 2 | Mini-Batch: 323 | Loss: 1.30549 | Accuracy: 58.06%\n",
            "Epoch: 2 | Mini-Batch: 324 | Loss: 0.90609 | Accuracy: 58.08%\n",
            "Epoch: 2 | Mini-Batch: 325 | Loss: 1.15127 | Accuracy: 58.08%\n",
            "Epoch: 2 | Mini-Batch: 326 | Loss: 1.14087 | Accuracy: 58.09%\n",
            "Epoch: 2 | Mini-Batch: 327 | Loss: 1.21339 | Accuracy: 58.08%\n",
            "Epoch: 2 | Mini-Batch: 328 | Loss: 0.98000 | Accuracy: 58.12%\n",
            "Epoch: 2 | Mini-Batch: 329 | Loss: 0.96413 | Accuracy: 58.12%\n",
            "Epoch: 2 | Mini-Batch: 330 | Loss: 0.96550 | Accuracy: 58.14%\n",
            "Epoch: 2 | Mini-Batch: 331 | Loss: 1.26429 | Accuracy: 58.13%\n",
            "Epoch: 2 | Mini-Batch: 332 | Loss: 0.88371 | Accuracy: 58.17%\n",
            "Epoch: 2 | Mini-Batch: 333 | Loss: 1.02126 | Accuracy: 58.18%\n",
            "Epoch: 2 | Mini-Batch: 334 | Loss: 1.31693 | Accuracy: 58.17%\n",
            "Epoch: 2 | Mini-Batch: 335 | Loss: 0.94179 | Accuracy: 58.20%\n",
            "Epoch: 2 | Mini-Batch: 336 | Loss: 1.14851 | Accuracy: 58.21%\n",
            "Epoch: 2 | Mini-Batch: 337 | Loss: 1.08911 | Accuracy: 58.22%\n",
            "Epoch: 2 | Mini-Batch: 338 | Loss: 0.97526 | Accuracy: 58.24%\n",
            "Epoch: 2 | Mini-Batch: 339 | Loss: 1.19628 | Accuracy: 58.22%\n",
            "Epoch: 2 | Mini-Batch: 340 | Loss: 1.05052 | Accuracy: 58.22%\n",
            "Epoch: 2 | Mini-Batch: 341 | Loss: 0.91214 | Accuracy: 58.26%\n",
            "Epoch: 2 | Mini-Batch: 342 | Loss: 1.15737 | Accuracy: 58.26%\n",
            "Epoch: 2 | Mini-Batch: 343 | Loss: 1.20734 | Accuracy: 58.24%\n",
            "Epoch: 2 | Mini-Batch: 344 | Loss: 1.13292 | Accuracy: 58.25%\n",
            "Epoch: 2 | Mini-Batch: 345 | Loss: 1.05329 | Accuracy: 58.28%\n",
            "Epoch: 2 | Mini-Batch: 346 | Loss: 0.93909 | Accuracy: 58.28%\n",
            "Epoch: 2 | Mini-Batch: 347 | Loss: 1.06847 | Accuracy: 58.30%\n",
            "Epoch: 2 | Mini-Batch: 348 | Loss: 1.33460 | Accuracy: 58.30%\n",
            "Epoch: 2 | Mini-Batch: 349 | Loss: 1.17077 | Accuracy: 58.31%\n",
            "Epoch: 2 | Mini-Batch: 350 | Loss: 1.09390 | Accuracy: 58.31%\n",
            "Epoch: 2 | Mini-Batch: 351 | Loss: 1.07606 | Accuracy: 58.32%\n",
            "Epoch: 2 | Mini-Batch: 352 | Loss: 1.18890 | Accuracy: 58.30%\n",
            "Epoch: 2 | Mini-Batch: 353 | Loss: 0.94811 | Accuracy: 58.34%\n",
            "Epoch: 2 | Mini-Batch: 354 | Loss: 1.12638 | Accuracy: 58.35%\n",
            "Epoch: 2 | Mini-Batch: 355 | Loss: 1.08804 | Accuracy: 58.35%\n",
            "Epoch: 2 | Mini-Batch: 356 | Loss: 1.21937 | Accuracy: 58.36%\n",
            "Epoch: 2 | Mini-Batch: 357 | Loss: 1.16478 | Accuracy: 58.36%\n",
            "Epoch: 2 | Mini-Batch: 358 | Loss: 1.06263 | Accuracy: 58.36%\n",
            "Epoch: 2 | Mini-Batch: 359 | Loss: 1.03065 | Accuracy: 58.37%\n",
            "Epoch: 2 | Mini-Batch: 360 | Loss: 0.98497 | Accuracy: 58.40%\n",
            "Epoch: 2 | Mini-Batch: 361 | Loss: 1.20939 | Accuracy: 58.38%\n",
            "Epoch: 2 | Mini-Batch: 362 | Loss: 1.17155 | Accuracy: 58.38%\n",
            "Epoch: 2 | Mini-Batch: 363 | Loss: 1.28442 | Accuracy: 58.37%\n",
            "Epoch: 2 | Mini-Batch: 364 | Loss: 0.91112 | Accuracy: 58.39%\n",
            "Epoch: 2 | Mini-Batch: 365 | Loss: 1.01679 | Accuracy: 58.41%\n",
            "Epoch: 2 | Mini-Batch: 366 | Loss: 1.13300 | Accuracy: 58.41%\n",
            "Epoch: 2 | Mini-Batch: 367 | Loss: 1.06846 | Accuracy: 58.40%\n",
            "Epoch: 2 | Mini-Batch: 368 | Loss: 1.01444 | Accuracy: 58.41%\n",
            "Epoch: 2 | Mini-Batch: 369 | Loss: 0.93359 | Accuracy: 58.44%\n",
            "Epoch: 2 | Mini-Batch: 370 | Loss: 1.05300 | Accuracy: 58.45%\n",
            "Epoch: 2 | Mini-Batch: 371 | Loss: 0.98813 | Accuracy: 58.46%\n",
            "Epoch: 2 | Mini-Batch: 372 | Loss: 1.28048 | Accuracy: 58.46%\n",
            "Epoch: 2 | Mini-Batch: 373 | Loss: 1.23605 | Accuracy: 58.47%\n",
            "Epoch: 2 | Mini-Batch: 374 | Loss: 1.25553 | Accuracy: 58.46%\n",
            "Epoch: 2 | Mini-Batch: 375 | Loss: 1.02543 | Accuracy: 58.48%\n",
            "Epoch: 2 | Mini-Batch: 376 | Loss: 1.08118 | Accuracy: 58.49%\n",
            "Epoch: 2 | Mini-Batch: 377 | Loss: 0.92941 | Accuracy: 58.52%\n",
            "Epoch: 2 | Mini-Batch: 378 | Loss: 1.02516 | Accuracy: 58.53%\n",
            "Epoch: 2 | Mini-Batch: 379 | Loss: 0.85975 | Accuracy: 58.56%\n",
            "Epoch: 2 | Mini-Batch: 380 | Loss: 0.91083 | Accuracy: 58.57%\n",
            "Epoch: 2 | Mini-Batch: 381 | Loss: 0.99757 | Accuracy: 58.59%\n",
            "Epoch: 2 | Mini-Batch: 382 | Loss: 1.04340 | Accuracy: 58.60%\n",
            "Epoch: 2 | Mini-Batch: 383 | Loss: 1.17966 | Accuracy: 58.60%\n",
            "Epoch: 2 | Mini-Batch: 384 | Loss: 1.05898 | Accuracy: 58.62%\n",
            "Epoch: 2 | Mini-Batch: 385 | Loss: 0.94772 | Accuracy: 58.63%\n",
            "Epoch: 2 | Mini-Batch: 386 | Loss: 0.97786 | Accuracy: 58.65%\n",
            "Epoch: 2 | Mini-Batch: 387 | Loss: 1.13239 | Accuracy: 58.64%\n",
            "Epoch: 2 | Mini-Batch: 388 | Loss: 1.01418 | Accuracy: 58.65%\n",
            "Epoch: 2 | Mini-Batch: 389 | Loss: 0.97678 | Accuracy: 58.67%\n",
            "Epoch: 2 | Mini-Batch: 390 | Loss: 1.18006 | Accuracy: 58.67%\n",
            "Epoch: 3 | Mini-Batch: 0 | Loss: 1.06952 | Accuracy: 57.81%\n",
            "Epoch: 3 | Mini-Batch: 1 | Loss: 0.98771 | Accuracy: 61.72%\n",
            "Epoch: 3 | Mini-Batch: 2 | Loss: 1.15508 | Accuracy: 61.46%\n",
            "Epoch: 3 | Mini-Batch: 3 | Loss: 1.08652 | Accuracy: 61.13%\n",
            "Epoch: 3 | Mini-Batch: 4 | Loss: 1.11507 | Accuracy: 61.09%\n",
            "Epoch: 3 | Mini-Batch: 5 | Loss: 0.87351 | Accuracy: 61.46%\n",
            "Epoch: 3 | Mini-Batch: 6 | Loss: 1.02184 | Accuracy: 61.72%\n",
            "Epoch: 3 | Mini-Batch: 7 | Loss: 0.94783 | Accuracy: 62.79%\n",
            "Epoch: 3 | Mini-Batch: 8 | Loss: 0.95295 | Accuracy: 63.54%\n",
            "Epoch: 3 | Mini-Batch: 9 | Loss: 0.94980 | Accuracy: 63.83%\n",
            "Epoch: 3 | Mini-Batch: 10 | Loss: 1.04969 | Accuracy: 63.57%\n",
            "Epoch: 3 | Mini-Batch: 11 | Loss: 1.17124 | Accuracy: 62.83%\n",
            "Epoch: 3 | Mini-Batch: 12 | Loss: 0.95914 | Accuracy: 62.74%\n",
            "Epoch: 3 | Mini-Batch: 13 | Loss: 1.01196 | Accuracy: 62.67%\n",
            "Epoch: 3 | Mini-Batch: 14 | Loss: 0.89983 | Accuracy: 62.92%\n",
            "Epoch: 3 | Mini-Batch: 15 | Loss: 1.04179 | Accuracy: 62.89%\n",
            "Epoch: 3 | Mini-Batch: 16 | Loss: 1.07141 | Accuracy: 62.78%\n",
            "Epoch: 3 | Mini-Batch: 17 | Loss: 1.13890 | Accuracy: 62.80%\n",
            "Epoch: 3 | Mini-Batch: 18 | Loss: 0.79557 | Accuracy: 63.32%\n",
            "Epoch: 3 | Mini-Batch: 19 | Loss: 1.03562 | Accuracy: 63.24%\n",
            "Epoch: 3 | Mini-Batch: 20 | Loss: 0.94735 | Accuracy: 63.28%\n",
            "Epoch: 3 | Mini-Batch: 21 | Loss: 1.19697 | Accuracy: 63.10%\n",
            "Epoch: 3 | Mini-Batch: 22 | Loss: 1.06235 | Accuracy: 62.94%\n",
            "Epoch: 3 | Mini-Batch: 23 | Loss: 1.16554 | Accuracy: 62.73%\n",
            "Epoch: 3 | Mini-Batch: 24 | Loss: 1.19340 | Accuracy: 62.59%\n",
            "Epoch: 3 | Mini-Batch: 25 | Loss: 0.97834 | Accuracy: 62.71%\n",
            "Epoch: 3 | Mini-Batch: 26 | Loss: 1.07417 | Accuracy: 62.67%\n",
            "Epoch: 3 | Mini-Batch: 27 | Loss: 1.05443 | Accuracy: 62.67%\n",
            "Epoch: 3 | Mini-Batch: 28 | Loss: 1.04347 | Accuracy: 62.74%\n",
            "Epoch: 3 | Mini-Batch: 29 | Loss: 0.98689 | Accuracy: 62.71%\n",
            "Epoch: 3 | Mini-Batch: 30 | Loss: 1.04903 | Accuracy: 62.70%\n",
            "Epoch: 3 | Mini-Batch: 31 | Loss: 1.08227 | Accuracy: 62.65%\n",
            "Epoch: 3 | Mini-Batch: 32 | Loss: 0.96626 | Accuracy: 62.69%\n",
            "Epoch: 3 | Mini-Batch: 33 | Loss: 1.03185 | Accuracy: 62.66%\n",
            "Epoch: 3 | Mini-Batch: 34 | Loss: 1.03065 | Accuracy: 62.81%\n",
            "Epoch: 3 | Mini-Batch: 35 | Loss: 1.15880 | Accuracy: 62.67%\n",
            "Epoch: 3 | Mini-Batch: 36 | Loss: 1.04896 | Accuracy: 62.56%\n",
            "Epoch: 3 | Mini-Batch: 37 | Loss: 1.05067 | Accuracy: 62.54%\n",
            "Epoch: 3 | Mini-Batch: 38 | Loss: 1.21133 | Accuracy: 62.40%\n",
            "Epoch: 3 | Mini-Batch: 39 | Loss: 0.96198 | Accuracy: 62.46%\n",
            "Epoch: 3 | Mini-Batch: 40 | Loss: 1.08901 | Accuracy: 62.42%\n",
            "Epoch: 3 | Mini-Batch: 41 | Loss: 0.84317 | Accuracy: 62.56%\n",
            "Epoch: 3 | Mini-Batch: 42 | Loss: 0.93713 | Accuracy: 62.72%\n",
            "Epoch: 3 | Mini-Batch: 43 | Loss: 0.96394 | Accuracy: 62.66%\n",
            "Epoch: 3 | Mini-Batch: 44 | Loss: 1.04686 | Accuracy: 62.69%\n",
            "Epoch: 3 | Mini-Batch: 45 | Loss: 1.02904 | Accuracy: 62.60%\n",
            "Epoch: 3 | Mini-Batch: 46 | Loss: 0.87858 | Accuracy: 62.72%\n",
            "Epoch: 3 | Mini-Batch: 47 | Loss: 1.00357 | Accuracy: 62.78%\n",
            "Epoch: 3 | Mini-Batch: 48 | Loss: 1.20380 | Accuracy: 62.61%\n",
            "Epoch: 3 | Mini-Batch: 49 | Loss: 1.04336 | Accuracy: 62.55%\n",
            "Epoch: 3 | Mini-Batch: 50 | Loss: 1.00531 | Accuracy: 62.52%\n",
            "Epoch: 3 | Mini-Batch: 51 | Loss: 1.03679 | Accuracy: 62.48%\n",
            "Epoch: 3 | Mini-Batch: 52 | Loss: 1.04098 | Accuracy: 62.46%\n",
            "Epoch: 3 | Mini-Batch: 53 | Loss: 0.77436 | Accuracy: 62.66%\n",
            "Epoch: 3 | Mini-Batch: 54 | Loss: 1.00230 | Accuracy: 62.67%\n",
            "Epoch: 3 | Mini-Batch: 55 | Loss: 1.01103 | Accuracy: 62.65%\n",
            "Epoch: 3 | Mini-Batch: 56 | Loss: 0.93206 | Accuracy: 62.76%\n",
            "Epoch: 3 | Mini-Batch: 57 | Loss: 1.05033 | Accuracy: 62.70%\n",
            "Epoch: 3 | Mini-Batch: 58 | Loss: 0.90725 | Accuracy: 62.75%\n",
            "Epoch: 3 | Mini-Batch: 59 | Loss: 1.02215 | Accuracy: 62.71%\n",
            "Epoch: 3 | Mini-Batch: 60 | Loss: 0.99070 | Accuracy: 62.70%\n",
            "Epoch: 3 | Mini-Batch: 61 | Loss: 1.22731 | Accuracy: 62.65%\n",
            "Epoch: 3 | Mini-Batch: 62 | Loss: 1.03934 | Accuracy: 62.72%\n",
            "Epoch: 3 | Mini-Batch: 63 | Loss: 1.24155 | Accuracy: 62.59%\n",
            "Epoch: 3 | Mini-Batch: 64 | Loss: 1.04148 | Accuracy: 62.57%\n",
            "Epoch: 3 | Mini-Batch: 65 | Loss: 1.24461 | Accuracy: 62.49%\n",
            "Epoch: 3 | Mini-Batch: 66 | Loss: 0.97969 | Accuracy: 62.53%\n",
            "Epoch: 3 | Mini-Batch: 67 | Loss: 1.00793 | Accuracy: 62.59%\n",
            "Epoch: 3 | Mini-Batch: 68 | Loss: 1.01422 | Accuracy: 62.62%\n",
            "Epoch: 3 | Mini-Batch: 69 | Loss: 1.08102 | Accuracy: 62.56%\n",
            "Epoch: 3 | Mini-Batch: 70 | Loss: 0.72827 | Accuracy: 62.76%\n",
            "Epoch: 3 | Mini-Batch: 71 | Loss: 0.81487 | Accuracy: 62.85%\n",
            "Epoch: 3 | Mini-Batch: 72 | Loss: 1.02317 | Accuracy: 62.89%\n",
            "Epoch: 3 | Mini-Batch: 73 | Loss: 1.11216 | Accuracy: 62.87%\n",
            "Epoch: 3 | Mini-Batch: 74 | Loss: 0.84245 | Accuracy: 62.96%\n",
            "Epoch: 3 | Mini-Batch: 75 | Loss: 1.13171 | Accuracy: 62.93%\n",
            "Epoch: 3 | Mini-Batch: 76 | Loss: 0.95468 | Accuracy: 62.94%\n",
            "Epoch: 3 | Mini-Batch: 77 | Loss: 0.92470 | Accuracy: 62.97%\n",
            "Epoch: 3 | Mini-Batch: 78 | Loss: 0.96717 | Accuracy: 63.03%\n",
            "Epoch: 3 | Mini-Batch: 79 | Loss: 0.93961 | Accuracy: 63.09%\n",
            "Epoch: 3 | Mini-Batch: 80 | Loss: 1.12882 | Accuracy: 63.00%\n",
            "Epoch: 3 | Mini-Batch: 81 | Loss: 0.85252 | Accuracy: 63.13%\n",
            "Epoch: 3 | Mini-Batch: 82 | Loss: 0.86258 | Accuracy: 63.21%\n",
            "Epoch: 3 | Mini-Batch: 83 | Loss: 1.02866 | Accuracy: 63.23%\n",
            "Epoch: 3 | Mini-Batch: 84 | Loss: 1.05204 | Accuracy: 63.28%\n",
            "Epoch: 3 | Mini-Batch: 85 | Loss: 1.24057 | Accuracy: 63.23%\n",
            "Epoch: 3 | Mini-Batch: 86 | Loss: 1.12214 | Accuracy: 63.20%\n",
            "Epoch: 3 | Mini-Batch: 87 | Loss: 0.89969 | Accuracy: 63.26%\n",
            "Epoch: 3 | Mini-Batch: 88 | Loss: 0.99106 | Accuracy: 63.28%\n",
            "Epoch: 3 | Mini-Batch: 89 | Loss: 0.99900 | Accuracy: 63.29%\n",
            "Epoch: 3 | Mini-Batch: 90 | Loss: 1.03338 | Accuracy: 63.32%\n",
            "Epoch: 3 | Mini-Batch: 91 | Loss: 0.94454 | Accuracy: 63.35%\n",
            "Epoch: 3 | Mini-Batch: 92 | Loss: 1.03231 | Accuracy: 63.31%\n",
            "Epoch: 3 | Mini-Batch: 93 | Loss: 0.98014 | Accuracy: 63.37%\n",
            "Epoch: 3 | Mini-Batch: 94 | Loss: 1.01216 | Accuracy: 63.36%\n",
            "Epoch: 3 | Mini-Batch: 95 | Loss: 1.00764 | Accuracy: 63.37%\n",
            "Epoch: 3 | Mini-Batch: 96 | Loss: 1.22770 | Accuracy: 63.32%\n",
            "Epoch: 3 | Mini-Batch: 97 | Loss: 1.10219 | Accuracy: 63.38%\n",
            "Epoch: 3 | Mini-Batch: 98 | Loss: 1.11871 | Accuracy: 63.35%\n",
            "Epoch: 3 | Mini-Batch: 99 | Loss: 0.99513 | Accuracy: 63.35%\n",
            "Epoch: 3 | Mini-Batch: 100 | Loss: 0.79942 | Accuracy: 63.41%\n",
            "Epoch: 3 | Mini-Batch: 101 | Loss: 0.76896 | Accuracy: 63.48%\n",
            "Epoch: 3 | Mini-Batch: 102 | Loss: 0.87038 | Accuracy: 63.56%\n",
            "Epoch: 3 | Mini-Batch: 103 | Loss: 1.00812 | Accuracy: 63.63%\n",
            "Epoch: 3 | Mini-Batch: 104 | Loss: 0.99150 | Accuracy: 63.60%\n",
            "Epoch: 3 | Mini-Batch: 105 | Loss: 1.02720 | Accuracy: 63.59%\n",
            "Epoch: 3 | Mini-Batch: 106 | Loss: 0.93116 | Accuracy: 63.64%\n",
            "Epoch: 3 | Mini-Batch: 107 | Loss: 1.10765 | Accuracy: 63.61%\n",
            "Epoch: 3 | Mini-Batch: 108 | Loss: 0.88334 | Accuracy: 63.68%\n",
            "Epoch: 3 | Mini-Batch: 109 | Loss: 1.10502 | Accuracy: 63.63%\n",
            "Epoch: 3 | Mini-Batch: 110 | Loss: 0.91895 | Accuracy: 63.65%\n",
            "Epoch: 3 | Mini-Batch: 111 | Loss: 0.87463 | Accuracy: 63.71%\n",
            "Epoch: 3 | Mini-Batch: 112 | Loss: 0.75483 | Accuracy: 63.75%\n",
            "Epoch: 3 | Mini-Batch: 113 | Loss: 0.93265 | Accuracy: 63.73%\n",
            "Epoch: 3 | Mini-Batch: 114 | Loss: 0.87004 | Accuracy: 63.76%\n",
            "Epoch: 3 | Mini-Batch: 115 | Loss: 1.19725 | Accuracy: 63.70%\n",
            "Epoch: 3 | Mini-Batch: 116 | Loss: 0.99724 | Accuracy: 63.73%\n",
            "Epoch: 3 | Mini-Batch: 117 | Loss: 1.06071 | Accuracy: 63.73%\n",
            "Epoch: 3 | Mini-Batch: 118 | Loss: 1.17049 | Accuracy: 63.69%\n",
            "Epoch: 3 | Mini-Batch: 119 | Loss: 1.00051 | Accuracy: 63.68%\n",
            "Epoch: 3 | Mini-Batch: 120 | Loss: 0.98140 | Accuracy: 63.66%\n",
            "Epoch: 3 | Mini-Batch: 121 | Loss: 0.96804 | Accuracy: 63.65%\n",
            "Epoch: 3 | Mini-Batch: 122 | Loss: 0.97194 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 123 | Loss: 1.01210 | Accuracy: 63.63%\n",
            "Epoch: 3 | Mini-Batch: 124 | Loss: 0.95299 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 125 | Loss: 1.13294 | Accuracy: 63.59%\n",
            "Epoch: 3 | Mini-Batch: 126 | Loss: 0.87506 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 127 | Loss: 0.92199 | Accuracy: 63.65%\n",
            "Epoch: 3 | Mini-Batch: 128 | Loss: 1.08621 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 129 | Loss: 1.12745 | Accuracy: 63.59%\n",
            "Epoch: 3 | Mini-Batch: 130 | Loss: 1.03055 | Accuracy: 63.57%\n",
            "Epoch: 3 | Mini-Batch: 131 | Loss: 0.93769 | Accuracy: 63.57%\n",
            "Epoch: 3 | Mini-Batch: 132 | Loss: 0.91643 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 133 | Loss: 1.15316 | Accuracy: 63.61%\n",
            "Epoch: 3 | Mini-Batch: 134 | Loss: 1.13598 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 135 | Loss: 0.97878 | Accuracy: 63.62%\n",
            "Epoch: 3 | Mini-Batch: 136 | Loss: 1.32745 | Accuracy: 63.55%\n",
            "Epoch: 3 | Mini-Batch: 137 | Loss: 1.25776 | Accuracy: 63.46%\n",
            "Epoch: 3 | Mini-Batch: 138 | Loss: 0.95136 | Accuracy: 63.47%\n",
            "Epoch: 3 | Mini-Batch: 139 | Loss: 0.87099 | Accuracy: 63.49%\n",
            "Epoch: 3 | Mini-Batch: 140 | Loss: 1.04655 | Accuracy: 63.46%\n",
            "Epoch: 3 | Mini-Batch: 141 | Loss: 1.18978 | Accuracy: 63.44%\n",
            "Epoch: 3 | Mini-Batch: 142 | Loss: 1.09476 | Accuracy: 63.43%\n",
            "Epoch: 3 | Mini-Batch: 143 | Loss: 1.09250 | Accuracy: 63.40%\n",
            "Epoch: 3 | Mini-Batch: 144 | Loss: 0.98115 | Accuracy: 63.38%\n",
            "Epoch: 3 | Mini-Batch: 145 | Loss: 1.10092 | Accuracy: 63.34%\n",
            "Epoch: 3 | Mini-Batch: 146 | Loss: 1.01082 | Accuracy: 63.36%\n",
            "Epoch: 3 | Mini-Batch: 147 | Loss: 1.06869 | Accuracy: 63.32%\n",
            "Epoch: 3 | Mini-Batch: 148 | Loss: 1.09195 | Accuracy: 63.30%\n",
            "Epoch: 3 | Mini-Batch: 149 | Loss: 1.02760 | Accuracy: 63.29%\n",
            "Epoch: 3 | Mini-Batch: 150 | Loss: 1.04247 | Accuracy: 63.25%\n",
            "Epoch: 3 | Mini-Batch: 151 | Loss: 0.99709 | Accuracy: 63.22%\n",
            "Epoch: 3 | Mini-Batch: 152 | Loss: 0.95977 | Accuracy: 63.22%\n",
            "Epoch: 3 | Mini-Batch: 153 | Loss: 0.97220 | Accuracy: 63.23%\n",
            "Epoch: 3 | Mini-Batch: 154 | Loss: 0.84039 | Accuracy: 63.28%\n",
            "Epoch: 3 | Mini-Batch: 155 | Loss: 0.82940 | Accuracy: 63.31%\n",
            "Epoch: 3 | Mini-Batch: 156 | Loss: 0.94802 | Accuracy: 63.33%\n",
            "Epoch: 3 | Mini-Batch: 157 | Loss: 1.02296 | Accuracy: 63.36%\n",
            "Epoch: 3 | Mini-Batch: 158 | Loss: 0.91422 | Accuracy: 63.41%\n",
            "Epoch: 3 | Mini-Batch: 159 | Loss: 0.94157 | Accuracy: 63.42%\n",
            "Epoch: 3 | Mini-Batch: 160 | Loss: 0.98254 | Accuracy: 63.45%\n",
            "Epoch: 3 | Mini-Batch: 161 | Loss: 1.00045 | Accuracy: 63.48%\n",
            "Epoch: 3 | Mini-Batch: 162 | Loss: 1.04039 | Accuracy: 63.47%\n",
            "Epoch: 3 | Mini-Batch: 163 | Loss: 1.05655 | Accuracy: 63.48%\n",
            "Epoch: 3 | Mini-Batch: 164 | Loss: 0.91162 | Accuracy: 63.48%\n",
            "Epoch: 3 | Mini-Batch: 165 | Loss: 0.92894 | Accuracy: 63.51%\n",
            "Epoch: 3 | Mini-Batch: 166 | Loss: 0.94225 | Accuracy: 63.51%\n",
            "Epoch: 3 | Mini-Batch: 167 | Loss: 1.02123 | Accuracy: 63.50%\n",
            "Epoch: 3 | Mini-Batch: 168 | Loss: 0.95864 | Accuracy: 63.51%\n",
            "Epoch: 3 | Mini-Batch: 169 | Loss: 1.10678 | Accuracy: 63.50%\n",
            "Epoch: 3 | Mini-Batch: 170 | Loss: 0.96917 | Accuracy: 63.50%\n",
            "Epoch: 3 | Mini-Batch: 171 | Loss: 0.97517 | Accuracy: 63.55%\n",
            "Epoch: 3 | Mini-Batch: 172 | Loss: 0.94822 | Accuracy: 63.55%\n",
            "Epoch: 3 | Mini-Batch: 173 | Loss: 1.01021 | Accuracy: 63.56%\n",
            "Epoch: 3 | Mini-Batch: 174 | Loss: 0.97339 | Accuracy: 63.55%\n",
            "Epoch: 3 | Mini-Batch: 175 | Loss: 0.95354 | Accuracy: 63.56%\n",
            "Epoch: 3 | Mini-Batch: 176 | Loss: 0.89660 | Accuracy: 63.59%\n",
            "Epoch: 3 | Mini-Batch: 177 | Loss: 0.86228 | Accuracy: 63.64%\n",
            "Epoch: 3 | Mini-Batch: 178 | Loss: 0.91205 | Accuracy: 63.65%\n",
            "Epoch: 3 | Mini-Batch: 179 | Loss: 0.83565 | Accuracy: 63.67%\n",
            "Epoch: 3 | Mini-Batch: 180 | Loss: 0.79840 | Accuracy: 63.72%\n",
            "Epoch: 3 | Mini-Batch: 181 | Loss: 0.91727 | Accuracy: 63.73%\n",
            "Epoch: 3 | Mini-Batch: 182 | Loss: 0.81692 | Accuracy: 63.77%\n",
            "Epoch: 3 | Mini-Batch: 183 | Loss: 0.99870 | Accuracy: 63.77%\n",
            "Epoch: 3 | Mini-Batch: 184 | Loss: 1.02435 | Accuracy: 63.78%\n",
            "Epoch: 3 | Mini-Batch: 185 | Loss: 0.99039 | Accuracy: 63.77%\n",
            "Epoch: 3 | Mini-Batch: 186 | Loss: 1.11466 | Accuracy: 63.76%\n",
            "Epoch: 3 | Mini-Batch: 187 | Loss: 0.81960 | Accuracy: 63.78%\n",
            "Epoch: 3 | Mini-Batch: 188 | Loss: 0.89947 | Accuracy: 63.81%\n",
            "Epoch: 3 | Mini-Batch: 189 | Loss: 0.91751 | Accuracy: 63.83%\n",
            "Epoch: 3 | Mini-Batch: 190 | Loss: 0.86577 | Accuracy: 63.87%\n",
            "Epoch: 3 | Mini-Batch: 191 | Loss: 1.03322 | Accuracy: 63.87%\n",
            "Epoch: 3 | Mini-Batch: 192 | Loss: 1.05500 | Accuracy: 63.88%\n",
            "Epoch: 3 | Mini-Batch: 193 | Loss: 0.97026 | Accuracy: 63.89%\n",
            "Epoch: 3 | Mini-Batch: 194 | Loss: 0.92269 | Accuracy: 63.91%\n",
            "Epoch: 3 | Mini-Batch: 195 | Loss: 0.95833 | Accuracy: 63.92%\n",
            "Epoch: 3 | Mini-Batch: 196 | Loss: 0.88882 | Accuracy: 63.94%\n",
            "Epoch: 3 | Mini-Batch: 197 | Loss: 1.04437 | Accuracy: 63.95%\n",
            "Epoch: 3 | Mini-Batch: 198 | Loss: 0.99739 | Accuracy: 63.95%\n",
            "Epoch: 3 | Mini-Batch: 199 | Loss: 1.14711 | Accuracy: 63.93%\n",
            "Epoch: 3 | Mini-Batch: 200 | Loss: 0.88410 | Accuracy: 63.96%\n",
            "Epoch: 3 | Mini-Batch: 201 | Loss: 1.01474 | Accuracy: 63.95%\n",
            "Epoch: 3 | Mini-Batch: 202 | Loss: 0.82909 | Accuracy: 63.97%\n",
            "Epoch: 3 | Mini-Batch: 203 | Loss: 0.95718 | Accuracy: 63.99%\n",
            "Epoch: 3 | Mini-Batch: 204 | Loss: 1.04195 | Accuracy: 63.98%\n",
            "Epoch: 3 | Mini-Batch: 205 | Loss: 1.04452 | Accuracy: 63.99%\n",
            "Epoch: 3 | Mini-Batch: 206 | Loss: 0.94131 | Accuracy: 63.99%\n",
            "Epoch: 3 | Mini-Batch: 207 | Loss: 0.91289 | Accuracy: 64.02%\n",
            "Epoch: 3 | Mini-Batch: 208 | Loss: 1.13933 | Accuracy: 64.01%\n",
            "Epoch: 3 | Mini-Batch: 209 | Loss: 0.98075 | Accuracy: 64.04%\n",
            "Epoch: 3 | Mini-Batch: 210 | Loss: 0.87985 | Accuracy: 64.05%\n",
            "Epoch: 3 | Mini-Batch: 211 | Loss: 1.00092 | Accuracy: 64.04%\n",
            "Epoch: 3 | Mini-Batch: 212 | Loss: 1.21719 | Accuracy: 64.03%\n",
            "Epoch: 3 | Mini-Batch: 213 | Loss: 1.09092 | Accuracy: 64.01%\n",
            "Epoch: 3 | Mini-Batch: 214 | Loss: 0.84928 | Accuracy: 64.04%\n",
            "Epoch: 3 | Mini-Batch: 215 | Loss: 0.88557 | Accuracy: 64.06%\n",
            "Epoch: 3 | Mini-Batch: 216 | Loss: 0.80828 | Accuracy: 64.09%\n",
            "Epoch: 3 | Mini-Batch: 217 | Loss: 1.02413 | Accuracy: 64.07%\n",
            "Epoch: 3 | Mini-Batch: 218 | Loss: 0.98473 | Accuracy: 64.08%\n",
            "Epoch: 3 | Mini-Batch: 219 | Loss: 0.92424 | Accuracy: 64.08%\n",
            "Epoch: 3 | Mini-Batch: 220 | Loss: 1.04567 | Accuracy: 64.09%\n",
            "Epoch: 3 | Mini-Batch: 221 | Loss: 0.84872 | Accuracy: 64.12%\n",
            "Epoch: 3 | Mini-Batch: 222 | Loss: 0.94422 | Accuracy: 64.12%\n",
            "Epoch: 3 | Mini-Batch: 223 | Loss: 0.98112 | Accuracy: 64.14%\n",
            "Epoch: 3 | Mini-Batch: 224 | Loss: 1.23213 | Accuracy: 64.13%\n",
            "Epoch: 3 | Mini-Batch: 225 | Loss: 0.83121 | Accuracy: 64.17%\n",
            "Epoch: 3 | Mini-Batch: 226 | Loss: 0.98260 | Accuracy: 64.17%\n",
            "Epoch: 3 | Mini-Batch: 227 | Loss: 1.03565 | Accuracy: 64.18%\n",
            "Epoch: 3 | Mini-Batch: 228 | Loss: 0.85813 | Accuracy: 64.22%\n",
            "Epoch: 3 | Mini-Batch: 229 | Loss: 0.85205 | Accuracy: 64.25%\n",
            "Epoch: 3 | Mini-Batch: 230 | Loss: 0.82187 | Accuracy: 64.29%\n",
            "Epoch: 3 | Mini-Batch: 231 | Loss: 0.98030 | Accuracy: 64.28%\n",
            "Epoch: 3 | Mini-Batch: 232 | Loss: 0.86072 | Accuracy: 64.28%\n",
            "Epoch: 3 | Mini-Batch: 233 | Loss: 1.03607 | Accuracy: 64.27%\n",
            "Epoch: 3 | Mini-Batch: 234 | Loss: 0.93843 | Accuracy: 64.28%\n",
            "Epoch: 3 | Mini-Batch: 235 | Loss: 0.99225 | Accuracy: 64.27%\n",
            "Epoch: 3 | Mini-Batch: 236 | Loss: 0.96762 | Accuracy: 64.27%\n",
            "Epoch: 3 | Mini-Batch: 237 | Loss: 0.91721 | Accuracy: 64.30%\n",
            "Epoch: 3 | Mini-Batch: 238 | Loss: 1.02381 | Accuracy: 64.28%\n",
            "Epoch: 3 | Mini-Batch: 239 | Loss: 0.90595 | Accuracy: 64.29%\n",
            "Epoch: 3 | Mini-Batch: 240 | Loss: 1.02005 | Accuracy: 64.29%\n",
            "Epoch: 3 | Mini-Batch: 241 | Loss: 0.77779 | Accuracy: 64.34%\n",
            "Epoch: 3 | Mini-Batch: 242 | Loss: 0.98652 | Accuracy: 64.34%\n",
            "Epoch: 3 | Mini-Batch: 243 | Loss: 0.96601 | Accuracy: 64.32%\n",
            "Epoch: 3 | Mini-Batch: 244 | Loss: 1.00692 | Accuracy: 64.31%\n",
            "Epoch: 3 | Mini-Batch: 245 | Loss: 1.14223 | Accuracy: 64.31%\n",
            "Epoch: 3 | Mini-Batch: 246 | Loss: 0.88246 | Accuracy: 64.33%\n",
            "Epoch: 3 | Mini-Batch: 247 | Loss: 0.97208 | Accuracy: 64.33%\n",
            "Epoch: 3 | Mini-Batch: 248 | Loss: 0.89355 | Accuracy: 64.35%\n",
            "Epoch: 3 | Mini-Batch: 249 | Loss: 0.90910 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 250 | Loss: 1.00860 | Accuracy: 64.39%\n",
            "Epoch: 3 | Mini-Batch: 251 | Loss: 1.03532 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 252 | Loss: 1.07564 | Accuracy: 64.36%\n",
            "Epoch: 3 | Mini-Batch: 253 | Loss: 0.81027 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 254 | Loss: 0.98140 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 255 | Loss: 1.19265 | Accuracy: 64.34%\n",
            "Epoch: 3 | Mini-Batch: 256 | Loss: 0.85257 | Accuracy: 64.37%\n",
            "Epoch: 3 | Mini-Batch: 257 | Loss: 0.90164 | Accuracy: 64.36%\n",
            "Epoch: 3 | Mini-Batch: 258 | Loss: 0.94167 | Accuracy: 64.36%\n",
            "Epoch: 3 | Mini-Batch: 259 | Loss: 0.99378 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 260 | Loss: 0.91022 | Accuracy: 64.40%\n",
            "Epoch: 3 | Mini-Batch: 261 | Loss: 0.99094 | Accuracy: 64.41%\n",
            "Epoch: 3 | Mini-Batch: 262 | Loss: 1.12187 | Accuracy: 64.39%\n",
            "Epoch: 3 | Mini-Batch: 263 | Loss: 0.89965 | Accuracy: 64.39%\n",
            "Epoch: 3 | Mini-Batch: 264 | Loss: 1.16036 | Accuracy: 64.38%\n",
            "Epoch: 3 | Mini-Batch: 265 | Loss: 0.85846 | Accuracy: 64.42%\n",
            "Epoch: 3 | Mini-Batch: 266 | Loss: 0.81569 | Accuracy: 64.45%\n",
            "Epoch: 3 | Mini-Batch: 267 | Loss: 0.99931 | Accuracy: 64.45%\n",
            "Epoch: 3 | Mini-Batch: 268 | Loss: 0.84919 | Accuracy: 64.48%\n",
            "Epoch: 3 | Mini-Batch: 269 | Loss: 0.84986 | Accuracy: 64.50%\n",
            "Epoch: 3 | Mini-Batch: 270 | Loss: 1.06680 | Accuracy: 64.49%\n",
            "Epoch: 3 | Mini-Batch: 271 | Loss: 0.86960 | Accuracy: 64.51%\n",
            "Epoch: 3 | Mini-Batch: 272 | Loss: 0.99908 | Accuracy: 64.51%\n",
            "Epoch: 3 | Mini-Batch: 273 | Loss: 0.90618 | Accuracy: 64.51%\n",
            "Epoch: 3 | Mini-Batch: 274 | Loss: 1.04683 | Accuracy: 64.50%\n",
            "Epoch: 3 | Mini-Batch: 275 | Loss: 0.83843 | Accuracy: 64.52%\n",
            "Epoch: 3 | Mini-Batch: 276 | Loss: 1.08676 | Accuracy: 64.51%\n",
            "Epoch: 3 | Mini-Batch: 277 | Loss: 0.90388 | Accuracy: 64.51%\n",
            "Epoch: 3 | Mini-Batch: 278 | Loss: 0.80732 | Accuracy: 64.52%\n",
            "Epoch: 3 | Mini-Batch: 279 | Loss: 0.91025 | Accuracy: 64.54%\n",
            "Epoch: 3 | Mini-Batch: 280 | Loss: 0.94675 | Accuracy: 64.55%\n",
            "Epoch: 3 | Mini-Batch: 281 | Loss: 0.89858 | Accuracy: 64.56%\n",
            "Epoch: 3 | Mini-Batch: 282 | Loss: 0.92974 | Accuracy: 64.57%\n",
            "Epoch: 3 | Mini-Batch: 283 | Loss: 0.86344 | Accuracy: 64.58%\n",
            "Epoch: 3 | Mini-Batch: 284 | Loss: 0.78952 | Accuracy: 64.62%\n",
            "Epoch: 3 | Mini-Batch: 285 | Loss: 1.06047 | Accuracy: 64.60%\n",
            "Epoch: 3 | Mini-Batch: 286 | Loss: 0.90187 | Accuracy: 64.60%\n",
            "Epoch: 3 | Mini-Batch: 287 | Loss: 1.03061 | Accuracy: 64.60%\n",
            "Epoch: 3 | Mini-Batch: 288 | Loss: 0.80346 | Accuracy: 64.63%\n",
            "Epoch: 3 | Mini-Batch: 289 | Loss: 1.06183 | Accuracy: 64.63%\n",
            "Epoch: 3 | Mini-Batch: 290 | Loss: 0.87261 | Accuracy: 64.64%\n",
            "Epoch: 3 | Mini-Batch: 291 | Loss: 0.67175 | Accuracy: 64.68%\n",
            "Epoch: 3 | Mini-Batch: 292 | Loss: 0.86743 | Accuracy: 64.69%\n",
            "Epoch: 3 | Mini-Batch: 293 | Loss: 0.83155 | Accuracy: 64.70%\n",
            "Epoch: 3 | Mini-Batch: 294 | Loss: 1.00472 | Accuracy: 64.68%\n",
            "Epoch: 3 | Mini-Batch: 295 | Loss: 0.91719 | Accuracy: 64.69%\n",
            "Epoch: 3 | Mini-Batch: 296 | Loss: 0.99942 | Accuracy: 64.69%\n",
            "Epoch: 3 | Mini-Batch: 297 | Loss: 0.85516 | Accuracy: 64.73%\n",
            "Epoch: 3 | Mini-Batch: 298 | Loss: 0.79726 | Accuracy: 64.74%\n",
            "Epoch: 3 | Mini-Batch: 299 | Loss: 0.86367 | Accuracy: 64.76%\n",
            "Epoch: 3 | Mini-Batch: 300 | Loss: 0.88889 | Accuracy: 64.78%\n",
            "Epoch: 3 | Mini-Batch: 301 | Loss: 0.74698 | Accuracy: 64.81%\n",
            "Epoch: 3 | Mini-Batch: 302 | Loss: 0.98256 | Accuracy: 64.80%\n",
            "Epoch: 3 | Mini-Batch: 303 | Loss: 1.04815 | Accuracy: 64.79%\n",
            "Epoch: 3 | Mini-Batch: 304 | Loss: 0.88232 | Accuracy: 64.80%\n",
            "Epoch: 3 | Mini-Batch: 305 | Loss: 0.91463 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 306 | Loss: 1.04187 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 307 | Loss: 0.96410 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 308 | Loss: 0.97422 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 309 | Loss: 1.00500 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 310 | Loss: 0.99141 | Accuracy: 64.81%\n",
            "Epoch: 3 | Mini-Batch: 311 | Loss: 0.84373 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 312 | Loss: 0.89084 | Accuracy: 64.82%\n",
            "Epoch: 3 | Mini-Batch: 313 | Loss: 0.81045 | Accuracy: 64.84%\n",
            "Epoch: 3 | Mini-Batch: 314 | Loss: 0.89582 | Accuracy: 64.84%\n",
            "Epoch: 3 | Mini-Batch: 315 | Loss: 0.75562 | Accuracy: 64.88%\n",
            "Epoch: 3 | Mini-Batch: 316 | Loss: 0.91307 | Accuracy: 64.88%\n",
            "Epoch: 3 | Mini-Batch: 317 | Loss: 0.90554 | Accuracy: 64.89%\n",
            "Epoch: 3 | Mini-Batch: 318 | Loss: 0.83400 | Accuracy: 64.90%\n",
            "Epoch: 3 | Mini-Batch: 319 | Loss: 0.75120 | Accuracy: 64.92%\n",
            "Epoch: 3 | Mini-Batch: 320 | Loss: 0.96460 | Accuracy: 64.94%\n",
            "Epoch: 3 | Mini-Batch: 321 | Loss: 0.81578 | Accuracy: 64.96%\n",
            "Epoch: 3 | Mini-Batch: 322 | Loss: 0.82795 | Accuracy: 64.98%\n",
            "Epoch: 3 | Mini-Batch: 323 | Loss: 0.99949 | Accuracy: 64.98%\n",
            "Epoch: 3 | Mini-Batch: 324 | Loss: 0.78270 | Accuracy: 65.00%\n",
            "Epoch: 3 | Mini-Batch: 325 | Loss: 0.94864 | Accuracy: 65.01%\n",
            "Epoch: 3 | Mini-Batch: 326 | Loss: 0.83722 | Accuracy: 65.03%\n",
            "Epoch: 3 | Mini-Batch: 327 | Loss: 0.88709 | Accuracy: 65.04%\n",
            "Epoch: 3 | Mini-Batch: 328 | Loss: 0.82207 | Accuracy: 65.06%\n",
            "Epoch: 3 | Mini-Batch: 329 | Loss: 0.89057 | Accuracy: 65.07%\n",
            "Epoch: 3 | Mini-Batch: 330 | Loss: 0.80547 | Accuracy: 65.09%\n",
            "Epoch: 3 | Mini-Batch: 331 | Loss: 0.94327 | Accuracy: 65.10%\n",
            "Epoch: 3 | Mini-Batch: 332 | Loss: 1.17556 | Accuracy: 65.08%\n",
            "Epoch: 3 | Mini-Batch: 333 | Loss: 1.03155 | Accuracy: 65.09%\n",
            "Epoch: 3 | Mini-Batch: 334 | Loss: 0.89870 | Accuracy: 65.10%\n",
            "Epoch: 3 | Mini-Batch: 335 | Loss: 1.14146 | Accuracy: 65.07%\n",
            "Epoch: 3 | Mini-Batch: 336 | Loss: 0.87183 | Accuracy: 65.07%\n",
            "Epoch: 3 | Mini-Batch: 337 | Loss: 0.92001 | Accuracy: 65.07%\n",
            "Epoch: 3 | Mini-Batch: 338 | Loss: 0.86789 | Accuracy: 65.09%\n",
            "Epoch: 3 | Mini-Batch: 339 | Loss: 0.93194 | Accuracy: 65.09%\n",
            "Epoch: 3 | Mini-Batch: 340 | Loss: 1.09295 | Accuracy: 65.09%\n",
            "Epoch: 3 | Mini-Batch: 341 | Loss: 0.99906 | Accuracy: 65.10%\n",
            "Epoch: 3 | Mini-Batch: 342 | Loss: 0.88808 | Accuracy: 65.12%\n",
            "Epoch: 3 | Mini-Batch: 343 | Loss: 0.84994 | Accuracy: 65.13%\n",
            "Epoch: 3 | Mini-Batch: 344 | Loss: 0.86809 | Accuracy: 65.14%\n",
            "Epoch: 3 | Mini-Batch: 345 | Loss: 0.97819 | Accuracy: 65.14%\n",
            "Epoch: 3 | Mini-Batch: 346 | Loss: 0.85809 | Accuracy: 65.15%\n",
            "Epoch: 3 | Mini-Batch: 347 | Loss: 0.90063 | Accuracy: 65.15%\n",
            "Epoch: 3 | Mini-Batch: 348 | Loss: 0.96249 | Accuracy: 65.14%\n",
            "Epoch: 3 | Mini-Batch: 349 | Loss: 0.90162 | Accuracy: 65.14%\n",
            "Epoch: 3 | Mini-Batch: 350 | Loss: 0.75267 | Accuracy: 65.15%\n",
            "Epoch: 3 | Mini-Batch: 351 | Loss: 0.87398 | Accuracy: 65.16%\n",
            "Epoch: 3 | Mini-Batch: 352 | Loss: 0.85542 | Accuracy: 65.18%\n",
            "Epoch: 3 | Mini-Batch: 353 | Loss: 0.94040 | Accuracy: 65.18%\n",
            "Epoch: 3 | Mini-Batch: 354 | Loss: 0.87614 | Accuracy: 65.18%\n",
            "Epoch: 3 | Mini-Batch: 355 | Loss: 1.02185 | Accuracy: 65.18%\n",
            "Epoch: 3 | Mini-Batch: 356 | Loss: 0.95269 | Accuracy: 65.19%\n",
            "Epoch: 3 | Mini-Batch: 357 | Loss: 0.86751 | Accuracy: 65.20%\n",
            "Epoch: 3 | Mini-Batch: 358 | Loss: 1.10041 | Accuracy: 65.19%\n",
            "Epoch: 3 | Mini-Batch: 359 | Loss: 0.88967 | Accuracy: 65.21%\n",
            "Epoch: 3 | Mini-Batch: 360 | Loss: 0.92759 | Accuracy: 65.22%\n",
            "Epoch: 3 | Mini-Batch: 361 | Loss: 0.75991 | Accuracy: 65.24%\n",
            "Epoch: 3 | Mini-Batch: 362 | Loss: 0.99457 | Accuracy: 65.24%\n",
            "Epoch: 3 | Mini-Batch: 363 | Loss: 0.73623 | Accuracy: 65.27%\n",
            "Epoch: 3 | Mini-Batch: 364 | Loss: 0.99431 | Accuracy: 65.27%\n",
            "Epoch: 3 | Mini-Batch: 365 | Loss: 0.97960 | Accuracy: 65.27%\n",
            "Epoch: 3 | Mini-Batch: 366 | Loss: 0.94138 | Accuracy: 65.27%\n",
            "Epoch: 3 | Mini-Batch: 367 | Loss: 0.81619 | Accuracy: 65.27%\n",
            "Epoch: 3 | Mini-Batch: 368 | Loss: 0.91736 | Accuracy: 65.28%\n",
            "Epoch: 3 | Mini-Batch: 369 | Loss: 0.86135 | Accuracy: 65.30%\n",
            "Epoch: 3 | Mini-Batch: 370 | Loss: 0.93269 | Accuracy: 65.30%\n",
            "Epoch: 3 | Mini-Batch: 371 | Loss: 0.91317 | Accuracy: 65.31%\n",
            "Epoch: 3 | Mini-Batch: 372 | Loss: 0.99802 | Accuracy: 65.30%\n",
            "Epoch: 3 | Mini-Batch: 373 | Loss: 0.73556 | Accuracy: 65.33%\n",
            "Epoch: 3 | Mini-Batch: 374 | Loss: 0.88684 | Accuracy: 65.34%\n",
            "Epoch: 3 | Mini-Batch: 375 | Loss: 0.73065 | Accuracy: 65.37%\n",
            "Epoch: 3 | Mini-Batch: 376 | Loss: 0.89946 | Accuracy: 65.36%\n",
            "Epoch: 3 | Mini-Batch: 377 | Loss: 0.91596 | Accuracy: 65.37%\n",
            "Epoch: 3 | Mini-Batch: 378 | Loss: 0.80858 | Accuracy: 65.38%\n",
            "Epoch: 3 | Mini-Batch: 379 | Loss: 0.94604 | Accuracy: 65.38%\n",
            "Epoch: 3 | Mini-Batch: 380 | Loss: 0.89378 | Accuracy: 65.39%\n",
            "Epoch: 3 | Mini-Batch: 381 | Loss: 0.85565 | Accuracy: 65.39%\n",
            "Epoch: 3 | Mini-Batch: 382 | Loss: 0.76679 | Accuracy: 65.41%\n",
            "Epoch: 3 | Mini-Batch: 383 | Loss: 0.81332 | Accuracy: 65.44%\n",
            "Epoch: 3 | Mini-Batch: 384 | Loss: 0.81799 | Accuracy: 65.45%\n",
            "Epoch: 3 | Mini-Batch: 385 | Loss: 0.86606 | Accuracy: 65.46%\n",
            "Epoch: 3 | Mini-Batch: 386 | Loss: 0.92738 | Accuracy: 65.46%\n",
            "Epoch: 3 | Mini-Batch: 387 | Loss: 0.88740 | Accuracy: 65.46%\n",
            "Epoch: 3 | Mini-Batch: 388 | Loss: 0.86328 | Accuracy: 65.47%\n",
            "Epoch: 3 | Mini-Batch: 389 | Loss: 1.00999 | Accuracy: 65.48%\n",
            "Epoch: 3 | Mini-Batch: 390 | Loss: 0.83089 | Accuracy: 65.49%\n",
            "Epoch: 4 | Mini-Batch: 0 | Loss: 1.05661 | Accuracy: 60.16%\n",
            "Epoch: 4 | Mini-Batch: 1 | Loss: 0.74533 | Accuracy: 68.36%\n",
            "Epoch: 4 | Mini-Batch: 2 | Loss: 0.70510 | Accuracy: 70.31%\n",
            "Epoch: 4 | Mini-Batch: 3 | Loss: 0.83063 | Accuracy: 69.53%\n",
            "Epoch: 4 | Mini-Batch: 4 | Loss: 0.76664 | Accuracy: 69.38%\n",
            "Epoch: 4 | Mini-Batch: 5 | Loss: 0.71956 | Accuracy: 70.44%\n",
            "Epoch: 4 | Mini-Batch: 6 | Loss: 0.78474 | Accuracy: 70.76%\n",
            "Epoch: 4 | Mini-Batch: 7 | Loss: 0.95236 | Accuracy: 69.82%\n",
            "Epoch: 4 | Mini-Batch: 8 | Loss: 0.79609 | Accuracy: 69.53%\n",
            "Epoch: 4 | Mini-Batch: 9 | Loss: 0.85569 | Accuracy: 69.45%\n",
            "Epoch: 4 | Mini-Batch: 10 | Loss: 0.83969 | Accuracy: 69.03%\n",
            "Epoch: 4 | Mini-Batch: 11 | Loss: 0.87195 | Accuracy: 68.82%\n",
            "Epoch: 4 | Mini-Batch: 12 | Loss: 0.92972 | Accuracy: 68.57%\n",
            "Epoch: 4 | Mini-Batch: 13 | Loss: 0.78928 | Accuracy: 68.64%\n",
            "Epoch: 4 | Mini-Batch: 14 | Loss: 0.97273 | Accuracy: 68.23%\n",
            "Epoch: 4 | Mini-Batch: 15 | Loss: 0.96604 | Accuracy: 68.07%\n",
            "Epoch: 4 | Mini-Batch: 16 | Loss: 0.95904 | Accuracy: 67.88%\n",
            "Epoch: 4 | Mini-Batch: 17 | Loss: 1.09027 | Accuracy: 67.62%\n",
            "Epoch: 4 | Mini-Batch: 18 | Loss: 0.64259 | Accuracy: 68.05%\n",
            "Epoch: 4 | Mini-Batch: 19 | Loss: 0.93807 | Accuracy: 68.05%\n",
            "Epoch: 4 | Mini-Batch: 20 | Loss: 0.89916 | Accuracy: 67.97%\n",
            "Epoch: 4 | Mini-Batch: 21 | Loss: 0.96434 | Accuracy: 68.04%\n",
            "Epoch: 4 | Mini-Batch: 22 | Loss: 0.74579 | Accuracy: 68.31%\n",
            "Epoch: 4 | Mini-Batch: 23 | Loss: 0.93735 | Accuracy: 68.26%\n",
            "Epoch: 4 | Mini-Batch: 24 | Loss: 0.84390 | Accuracy: 68.34%\n",
            "Epoch: 4 | Mini-Batch: 25 | Loss: 0.76798 | Accuracy: 68.57%\n",
            "Epoch: 4 | Mini-Batch: 26 | Loss: 0.93264 | Accuracy: 68.66%\n",
            "Epoch: 4 | Mini-Batch: 27 | Loss: 0.82340 | Accuracy: 68.75%\n",
            "Epoch: 4 | Mini-Batch: 28 | Loss: 0.77168 | Accuracy: 68.86%\n",
            "Epoch: 4 | Mini-Batch: 29 | Loss: 0.91326 | Accuracy: 68.91%\n",
            "Epoch: 4 | Mini-Batch: 30 | Loss: 0.96759 | Accuracy: 68.78%\n",
            "Epoch: 4 | Mini-Batch: 31 | Loss: 0.79353 | Accuracy: 68.80%\n",
            "Epoch: 4 | Mini-Batch: 32 | Loss: 0.93218 | Accuracy: 68.75%\n",
            "Epoch: 4 | Mini-Batch: 33 | Loss: 1.02340 | Accuracy: 68.52%\n",
            "Epoch: 4 | Mini-Batch: 34 | Loss: 0.86845 | Accuracy: 68.55%\n",
            "Epoch: 4 | Mini-Batch: 35 | Loss: 0.82913 | Accuracy: 68.55%\n",
            "Epoch: 4 | Mini-Batch: 36 | Loss: 0.75624 | Accuracy: 68.60%\n",
            "Epoch: 4 | Mini-Batch: 37 | Loss: 1.07888 | Accuracy: 68.46%\n",
            "Epoch: 4 | Mini-Batch: 38 | Loss: 0.93308 | Accuracy: 68.41%\n",
            "Epoch: 4 | Mini-Batch: 39 | Loss: 0.78275 | Accuracy: 68.52%\n",
            "Epoch: 4 | Mini-Batch: 40 | Loss: 0.89156 | Accuracy: 68.58%\n",
            "Epoch: 4 | Mini-Batch: 41 | Loss: 0.75179 | Accuracy: 68.69%\n",
            "Epoch: 4 | Mini-Batch: 42 | Loss: 0.80873 | Accuracy: 68.71%\n",
            "Epoch: 4 | Mini-Batch: 43 | Loss: 0.91725 | Accuracy: 68.63%\n",
            "Epoch: 4 | Mini-Batch: 44 | Loss: 0.87162 | Accuracy: 68.65%\n",
            "Epoch: 4 | Mini-Batch: 45 | Loss: 1.02463 | Accuracy: 68.51%\n",
            "Epoch: 4 | Mini-Batch: 46 | Loss: 0.78840 | Accuracy: 68.58%\n",
            "Epoch: 4 | Mini-Batch: 47 | Loss: 0.98997 | Accuracy: 68.49%\n",
            "Epoch: 4 | Mini-Batch: 48 | Loss: 0.90979 | Accuracy: 68.42%\n",
            "Epoch: 4 | Mini-Batch: 49 | Loss: 0.89347 | Accuracy: 68.45%\n",
            "Epoch: 4 | Mini-Batch: 50 | Loss: 0.76905 | Accuracy: 68.55%\n",
            "Epoch: 4 | Mini-Batch: 51 | Loss: 0.88818 | Accuracy: 68.51%\n",
            "Epoch: 4 | Mini-Batch: 52 | Loss: 0.83338 | Accuracy: 68.57%\n",
            "Epoch: 4 | Mini-Batch: 53 | Loss: 0.96394 | Accuracy: 68.50%\n",
            "Epoch: 4 | Mini-Batch: 54 | Loss: 0.92840 | Accuracy: 68.48%\n",
            "Epoch: 4 | Mini-Batch: 55 | Loss: 0.82345 | Accuracy: 68.60%\n",
            "Epoch: 4 | Mini-Batch: 56 | Loss: 0.91077 | Accuracy: 68.54%\n",
            "Epoch: 4 | Mini-Batch: 57 | Loss: 0.81784 | Accuracy: 68.66%\n",
            "Epoch: 4 | Mini-Batch: 58 | Loss: 0.80874 | Accuracy: 68.74%\n",
            "Epoch: 4 | Mini-Batch: 59 | Loss: 0.74843 | Accuracy: 68.80%\n",
            "Epoch: 4 | Mini-Batch: 60 | Loss: 0.87928 | Accuracy: 68.78%\n",
            "Epoch: 4 | Mini-Batch: 61 | Loss: 0.84921 | Accuracy: 68.78%\n",
            "Epoch: 4 | Mini-Batch: 62 | Loss: 0.90830 | Accuracy: 68.81%\n",
            "Epoch: 4 | Mini-Batch: 63 | Loss: 0.93176 | Accuracy: 68.81%\n",
            "Epoch: 4 | Mini-Batch: 64 | Loss: 0.82042 | Accuracy: 68.87%\n",
            "Epoch: 4 | Mini-Batch: 65 | Loss: 0.79786 | Accuracy: 68.92%\n",
            "Epoch: 4 | Mini-Batch: 66 | Loss: 1.02568 | Accuracy: 68.88%\n",
            "Epoch: 4 | Mini-Batch: 67 | Loss: 0.94838 | Accuracy: 68.88%\n",
            "Epoch: 4 | Mini-Batch: 68 | Loss: 0.87045 | Accuracy: 68.89%\n",
            "Epoch: 4 | Mini-Batch: 69 | Loss: 0.99804 | Accuracy: 68.86%\n",
            "Epoch: 4 | Mini-Batch: 70 | Loss: 0.84163 | Accuracy: 68.83%\n",
            "Epoch: 4 | Mini-Batch: 71 | Loss: 0.91403 | Accuracy: 68.83%\n",
            "Epoch: 4 | Mini-Batch: 72 | Loss: 0.90347 | Accuracy: 68.87%\n",
            "Epoch: 4 | Mini-Batch: 73 | Loss: 0.93747 | Accuracy: 68.90%\n",
            "Epoch: 4 | Mini-Batch: 74 | Loss: 0.80532 | Accuracy: 68.93%\n",
            "Epoch: 4 | Mini-Batch: 75 | Loss: 0.71541 | Accuracy: 68.99%\n",
            "Epoch: 4 | Mini-Batch: 76 | Loss: 1.03206 | Accuracy: 68.95%\n",
            "Epoch: 4 | Mini-Batch: 77 | Loss: 0.92215 | Accuracy: 68.91%\n",
            "Epoch: 4 | Mini-Batch: 78 | Loss: 0.97840 | Accuracy: 68.83%\n",
            "Epoch: 4 | Mini-Batch: 79 | Loss: 0.91389 | Accuracy: 68.86%\n",
            "Epoch: 4 | Mini-Batch: 80 | Loss: 0.90971 | Accuracy: 68.85%\n",
            "Epoch: 4 | Mini-Batch: 81 | Loss: 0.74625 | Accuracy: 68.90%\n",
            "Epoch: 4 | Mini-Batch: 82 | Loss: 0.98879 | Accuracy: 68.83%\n",
            "Epoch: 4 | Mini-Batch: 83 | Loss: 0.99752 | Accuracy: 68.78%\n",
            "Epoch: 4 | Mini-Batch: 84 | Loss: 1.00084 | Accuracy: 68.78%\n",
            "Epoch: 4 | Mini-Batch: 85 | Loss: 0.69610 | Accuracy: 68.89%\n",
            "Epoch: 4 | Mini-Batch: 86 | Loss: 0.65310 | Accuracy: 69.00%\n",
            "Epoch: 4 | Mini-Batch: 87 | Loss: 0.75053 | Accuracy: 69.03%\n",
            "Epoch: 4 | Mini-Batch: 88 | Loss: 0.78524 | Accuracy: 69.04%\n",
            "Epoch: 4 | Mini-Batch: 89 | Loss: 0.81805 | Accuracy: 69.02%\n",
            "Epoch: 4 | Mini-Batch: 90 | Loss: 0.84870 | Accuracy: 69.05%\n",
            "Epoch: 4 | Mini-Batch: 91 | Loss: 0.77732 | Accuracy: 69.12%\n",
            "Epoch: 4 | Mini-Batch: 92 | Loss: 0.86758 | Accuracy: 69.13%\n",
            "Epoch: 4 | Mini-Batch: 93 | Loss: 0.70613 | Accuracy: 69.18%\n",
            "Epoch: 4 | Mini-Batch: 94 | Loss: 0.89753 | Accuracy: 69.18%\n",
            "Epoch: 4 | Mini-Batch: 95 | Loss: 0.78455 | Accuracy: 69.19%\n",
            "Epoch: 4 | Mini-Batch: 96 | Loss: 0.86018 | Accuracy: 69.23%\n",
            "Epoch: 4 | Mini-Batch: 97 | Loss: 0.76377 | Accuracy: 69.27%\n",
            "Epoch: 4 | Mini-Batch: 98 | Loss: 0.84181 | Accuracy: 69.30%\n",
            "Epoch: 4 | Mini-Batch: 99 | Loss: 0.66054 | Accuracy: 69.38%\n",
            "Epoch: 4 | Mini-Batch: 100 | Loss: 0.71229 | Accuracy: 69.42%\n",
            "Epoch: 4 | Mini-Batch: 101 | Loss: 0.92220 | Accuracy: 69.42%\n",
            "Epoch: 4 | Mini-Batch: 102 | Loss: 0.89242 | Accuracy: 69.38%\n",
            "Epoch: 4 | Mini-Batch: 103 | Loss: 0.72328 | Accuracy: 69.41%\n",
            "Epoch: 4 | Mini-Batch: 104 | Loss: 0.69947 | Accuracy: 69.46%\n",
            "Epoch: 4 | Mini-Batch: 105 | Loss: 0.88148 | Accuracy: 69.46%\n",
            "Epoch: 4 | Mini-Batch: 106 | Loss: 0.83442 | Accuracy: 69.48%\n",
            "Epoch: 4 | Mini-Batch: 107 | Loss: 0.81806 | Accuracy: 69.52%\n",
            "Epoch: 4 | Mini-Batch: 108 | Loss: 0.71038 | Accuracy: 69.56%\n",
            "Epoch: 4 | Mini-Batch: 109 | Loss: 0.78680 | Accuracy: 69.60%\n",
            "Epoch: 4 | Mini-Batch: 110 | Loss: 0.75216 | Accuracy: 69.66%\n",
            "Epoch: 4 | Mini-Batch: 111 | Loss: 0.80278 | Accuracy: 69.66%\n",
            "Epoch: 4 | Mini-Batch: 112 | Loss: 0.71859 | Accuracy: 69.70%\n",
            "Epoch: 4 | Mini-Batch: 113 | Loss: 0.88220 | Accuracy: 69.72%\n",
            "Epoch: 4 | Mini-Batch: 114 | Loss: 0.89284 | Accuracy: 69.71%\n",
            "Epoch: 4 | Mini-Batch: 115 | Loss: 0.91999 | Accuracy: 69.70%\n",
            "Epoch: 4 | Mini-Batch: 116 | Loss: 0.87206 | Accuracy: 69.69%\n",
            "Epoch: 4 | Mini-Batch: 117 | Loss: 0.78815 | Accuracy: 69.73%\n",
            "Epoch: 4 | Mini-Batch: 118 | Loss: 0.74393 | Accuracy: 69.75%\n",
            "Epoch: 4 | Mini-Batch: 119 | Loss: 0.74213 | Accuracy: 69.79%\n",
            "Epoch: 4 | Mini-Batch: 120 | Loss: 0.96602 | Accuracy: 69.76%\n",
            "Epoch: 4 | Mini-Batch: 121 | Loss: 0.72298 | Accuracy: 69.81%\n",
            "Epoch: 4 | Mini-Batch: 122 | Loss: 0.94985 | Accuracy: 69.78%\n",
            "Epoch: 4 | Mini-Batch: 123 | Loss: 0.74362 | Accuracy: 69.84%\n",
            "Epoch: 4 | Mini-Batch: 124 | Loss: 0.71392 | Accuracy: 69.85%\n",
            "Epoch: 4 | Mini-Batch: 125 | Loss: 0.76905 | Accuracy: 69.85%\n",
            "Epoch: 4 | Mini-Batch: 126 | Loss: 0.81092 | Accuracy: 69.85%\n",
            "Epoch: 4 | Mini-Batch: 127 | Loss: 0.94684 | Accuracy: 69.79%\n",
            "Epoch: 4 | Mini-Batch: 128 | Loss: 0.94017 | Accuracy: 69.78%\n",
            "Epoch: 4 | Mini-Batch: 129 | Loss: 0.73420 | Accuracy: 69.80%\n",
            "Epoch: 4 | Mini-Batch: 130 | Loss: 0.71763 | Accuracy: 69.83%\n",
            "Epoch: 4 | Mini-Batch: 131 | Loss: 0.78208 | Accuracy: 69.86%\n",
            "Epoch: 4 | Mini-Batch: 132 | Loss: 0.76734 | Accuracy: 69.87%\n",
            "Epoch: 4 | Mini-Batch: 133 | Loss: 0.79779 | Accuracy: 69.90%\n",
            "Epoch: 4 | Mini-Batch: 134 | Loss: 0.80905 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 135 | Loss: 0.81693 | Accuracy: 69.93%\n",
            "Epoch: 4 | Mini-Batch: 136 | Loss: 0.95803 | Accuracy: 69.90%\n",
            "Epoch: 4 | Mini-Batch: 137 | Loss: 0.78236 | Accuracy: 69.92%\n",
            "Epoch: 4 | Mini-Batch: 138 | Loss: 0.78065 | Accuracy: 69.92%\n",
            "Epoch: 4 | Mini-Batch: 139 | Loss: 0.88857 | Accuracy: 69.93%\n",
            "Epoch: 4 | Mini-Batch: 140 | Loss: 0.84793 | Accuracy: 69.90%\n",
            "Epoch: 4 | Mini-Batch: 141 | Loss: 0.67504 | Accuracy: 69.93%\n",
            "Epoch: 4 | Mini-Batch: 142 | Loss: 0.86217 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 143 | Loss: 0.81032 | Accuracy: 69.97%\n",
            "Epoch: 4 | Mini-Batch: 144 | Loss: 0.92637 | Accuracy: 69.93%\n",
            "Epoch: 4 | Mini-Batch: 145 | Loss: 0.78157 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 146 | Loss: 0.64255 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 147 | Loss: 0.79652 | Accuracy: 70.02%\n",
            "Epoch: 4 | Mini-Batch: 148 | Loss: 0.79155 | Accuracy: 70.06%\n",
            "Epoch: 4 | Mini-Batch: 149 | Loss: 0.75797 | Accuracy: 70.08%\n",
            "Epoch: 4 | Mini-Batch: 150 | Loss: 0.89855 | Accuracy: 70.06%\n",
            "Epoch: 4 | Mini-Batch: 151 | Loss: 0.80068 | Accuracy: 70.07%\n",
            "Epoch: 4 | Mini-Batch: 152 | Loss: 0.81702 | Accuracy: 70.10%\n",
            "Epoch: 4 | Mini-Batch: 153 | Loss: 0.99601 | Accuracy: 70.10%\n",
            "Epoch: 4 | Mini-Batch: 154 | Loss: 0.79190 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 155 | Loss: 0.66694 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 156 | Loss: 0.75694 | Accuracy: 70.15%\n",
            "Epoch: 4 | Mini-Batch: 157 | Loss: 1.02930 | Accuracy: 70.13%\n",
            "Epoch: 4 | Mini-Batch: 158 | Loss: 0.70954 | Accuracy: 70.13%\n",
            "Epoch: 4 | Mini-Batch: 159 | Loss: 0.86225 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 160 | Loss: 0.91998 | Accuracy: 70.09%\n",
            "Epoch: 4 | Mini-Batch: 161 | Loss: 0.78900 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 162 | Loss: 1.10913 | Accuracy: 70.07%\n",
            "Epoch: 4 | Mini-Batch: 163 | Loss: 0.70041 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 164 | Loss: 0.75550 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 165 | Loss: 0.74517 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 166 | Loss: 0.86763 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 167 | Loss: 0.76307 | Accuracy: 70.17%\n",
            "Epoch: 4 | Mini-Batch: 168 | Loss: 1.00214 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 169 | Loss: 1.02504 | Accuracy: 70.11%\n",
            "Epoch: 4 | Mini-Batch: 170 | Loss: 0.74657 | Accuracy: 70.11%\n",
            "Epoch: 4 | Mini-Batch: 171 | Loss: 0.77836 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 172 | Loss: 0.92883 | Accuracy: 70.11%\n",
            "Epoch: 4 | Mini-Batch: 173 | Loss: 0.74071 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 174 | Loss: 1.00345 | Accuracy: 70.12%\n",
            "Epoch: 4 | Mini-Batch: 175 | Loss: 0.97735 | Accuracy: 70.09%\n",
            "Epoch: 4 | Mini-Batch: 176 | Loss: 0.78161 | Accuracy: 70.10%\n",
            "Epoch: 4 | Mini-Batch: 177 | Loss: 0.83635 | Accuracy: 70.11%\n",
            "Epoch: 4 | Mini-Batch: 178 | Loss: 0.84573 | Accuracy: 70.09%\n",
            "Epoch: 4 | Mini-Batch: 179 | Loss: 0.92609 | Accuracy: 70.08%\n",
            "Epoch: 4 | Mini-Batch: 180 | Loss: 1.09889 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 181 | Loss: 1.05105 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 182 | Loss: 0.76570 | Accuracy: 69.97%\n",
            "Epoch: 4 | Mini-Batch: 183 | Loss: 0.91126 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 184 | Loss: 0.76366 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 185 | Loss: 0.89206 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 186 | Loss: 0.76298 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 187 | Loss: 0.88880 | Accuracy: 69.98%\n",
            "Epoch: 4 | Mini-Batch: 188 | Loss: 0.83824 | Accuracy: 69.99%\n",
            "Epoch: 4 | Mini-Batch: 189 | Loss: 0.60751 | Accuracy: 70.03%\n",
            "Epoch: 4 | Mini-Batch: 190 | Loss: 0.87374 | Accuracy: 70.05%\n",
            "Epoch: 4 | Mini-Batch: 191 | Loss: 0.77309 | Accuracy: 70.07%\n",
            "Epoch: 4 | Mini-Batch: 192 | Loss: 0.94069 | Accuracy: 70.05%\n",
            "Epoch: 4 | Mini-Batch: 193 | Loss: 0.96652 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 194 | Loss: 1.03999 | Accuracy: 70.00%\n",
            "Epoch: 4 | Mini-Batch: 195 | Loss: 1.05225 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 196 | Loss: 0.85579 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 197 | Loss: 0.85749 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 198 | Loss: 0.78788 | Accuracy: 69.94%\n",
            "Epoch: 4 | Mini-Batch: 199 | Loss: 0.85497 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 200 | Loss: 0.83673 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 201 | Loss: 0.85267 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 202 | Loss: 0.78128 | Accuracy: 69.97%\n",
            "Epoch: 4 | Mini-Batch: 203 | Loss: 0.90820 | Accuracy: 69.95%\n",
            "Epoch: 4 | Mini-Batch: 204 | Loss: 0.72219 | Accuracy: 69.97%\n",
            "Epoch: 4 | Mini-Batch: 205 | Loss: 0.90002 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 206 | Loss: 0.86300 | Accuracy: 69.96%\n",
            "Epoch: 4 | Mini-Batch: 207 | Loss: 0.82294 | Accuracy: 69.97%\n",
            "Epoch: 4 | Mini-Batch: 208 | Loss: 0.75804 | Accuracy: 69.99%\n",
            "Epoch: 4 | Mini-Batch: 209 | Loss: 0.74574 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 210 | Loss: 0.81573 | Accuracy: 70.02%\n",
            "Epoch: 4 | Mini-Batch: 211 | Loss: 0.83897 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 212 | Loss: 0.91687 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 213 | Loss: 0.88255 | Accuracy: 69.98%\n",
            "Epoch: 4 | Mini-Batch: 214 | Loss: 0.75389 | Accuracy: 70.01%\n",
            "Epoch: 4 | Mini-Batch: 215 | Loss: 0.63800 | Accuracy: 70.06%\n",
            "Epoch: 4 | Mini-Batch: 216 | Loss: 0.94682 | Accuracy: 70.04%\n",
            "Epoch: 4 | Mini-Batch: 217 | Loss: 0.65288 | Accuracy: 70.08%\n",
            "Epoch: 4 | Mini-Batch: 218 | Loss: 0.72957 | Accuracy: 70.09%\n",
            "Epoch: 4 | Mini-Batch: 219 | Loss: 0.87367 | Accuracy: 70.07%\n",
            "Epoch: 4 | Mini-Batch: 220 | Loss: 0.65612 | Accuracy: 70.10%\n",
            "Epoch: 4 | Mini-Batch: 221 | Loss: 0.93989 | Accuracy: 70.09%\n",
            "Epoch: 4 | Mini-Batch: 222 | Loss: 0.92501 | Accuracy: 70.10%\n",
            "Epoch: 4 | Mini-Batch: 223 | Loss: 0.74846 | Accuracy: 70.13%\n",
            "Epoch: 4 | Mini-Batch: 224 | Loss: 0.69128 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 225 | Loss: 0.71934 | Accuracy: 70.14%\n",
            "Epoch: 4 | Mini-Batch: 226 | Loss: 0.64295 | Accuracy: 70.19%\n",
            "Epoch: 4 | Mini-Batch: 227 | Loss: 0.71981 | Accuracy: 70.19%\n",
            "Epoch: 4 | Mini-Batch: 228 | Loss: 0.75663 | Accuracy: 70.21%\n",
            "Epoch: 4 | Mini-Batch: 229 | Loss: 0.82161 | Accuracy: 70.20%\n",
            "Epoch: 4 | Mini-Batch: 230 | Loss: 0.67706 | Accuracy: 70.23%\n",
            "Epoch: 4 | Mini-Batch: 231 | Loss: 0.75519 | Accuracy: 70.26%\n",
            "Epoch: 4 | Mini-Batch: 232 | Loss: 0.82673 | Accuracy: 70.26%\n",
            "Epoch: 4 | Mini-Batch: 233 | Loss: 0.67894 | Accuracy: 70.29%\n",
            "Epoch: 4 | Mini-Batch: 234 | Loss: 0.53430 | Accuracy: 70.33%\n",
            "Epoch: 4 | Mini-Batch: 235 | Loss: 0.85916 | Accuracy: 70.33%\n",
            "Epoch: 4 | Mini-Batch: 236 | Loss: 1.05479 | Accuracy: 70.31%\n",
            "Epoch: 4 | Mini-Batch: 237 | Loss: 0.84476 | Accuracy: 70.30%\n",
            "Epoch: 4 | Mini-Batch: 238 | Loss: 0.82810 | Accuracy: 70.31%\n",
            "Epoch: 4 | Mini-Batch: 239 | Loss: 0.67482 | Accuracy: 70.35%\n",
            "Epoch: 4 | Mini-Batch: 240 | Loss: 0.62670 | Accuracy: 70.38%\n",
            "Epoch: 4 | Mini-Batch: 241 | Loss: 0.78045 | Accuracy: 70.40%\n",
            "Epoch: 4 | Mini-Batch: 242 | Loss: 0.78337 | Accuracy: 70.42%\n",
            "Epoch: 4 | Mini-Batch: 243 | Loss: 0.90955 | Accuracy: 70.39%\n",
            "Epoch: 4 | Mini-Batch: 244 | Loss: 0.90756 | Accuracy: 70.40%\n",
            "Epoch: 4 | Mini-Batch: 245 | Loss: 0.71589 | Accuracy: 70.40%\n",
            "Epoch: 4 | Mini-Batch: 246 | Loss: 0.79534 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 247 | Loss: 0.85312 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 248 | Loss: 0.83495 | Accuracy: 70.42%\n",
            "Epoch: 4 | Mini-Batch: 249 | Loss: 0.83370 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 250 | Loss: 0.93119 | Accuracy: 70.40%\n",
            "Epoch: 4 | Mini-Batch: 251 | Loss: 0.81841 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 252 | Loss: 0.94427 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 253 | Loss: 0.71262 | Accuracy: 70.42%\n",
            "Epoch: 4 | Mini-Batch: 254 | Loss: 0.84343 | Accuracy: 70.41%\n",
            "Epoch: 4 | Mini-Batch: 255 | Loss: 0.77475 | Accuracy: 70.43%\n",
            "Epoch: 4 | Mini-Batch: 256 | Loss: 0.90757 | Accuracy: 70.44%\n",
            "Epoch: 4 | Mini-Batch: 257 | Loss: 0.65190 | Accuracy: 70.47%\n",
            "Epoch: 4 | Mini-Batch: 258 | Loss: 0.83830 | Accuracy: 70.47%\n",
            "Epoch: 4 | Mini-Batch: 259 | Loss: 0.81189 | Accuracy: 70.47%\n",
            "Epoch: 4 | Mini-Batch: 260 | Loss: 0.77199 | Accuracy: 70.49%\n",
            "Epoch: 4 | Mini-Batch: 261 | Loss: 0.70528 | Accuracy: 70.52%\n",
            "Epoch: 4 | Mini-Batch: 262 | Loss: 0.94897 | Accuracy: 70.51%\n",
            "Epoch: 4 | Mini-Batch: 263 | Loss: 0.70625 | Accuracy: 70.52%\n",
            "Epoch: 4 | Mini-Batch: 264 | Loss: 0.66926 | Accuracy: 70.55%\n",
            "Epoch: 4 | Mini-Batch: 265 | Loss: 0.91485 | Accuracy: 70.53%\n",
            "Epoch: 4 | Mini-Batch: 266 | Loss: 0.79576 | Accuracy: 70.53%\n",
            "Epoch: 4 | Mini-Batch: 267 | Loss: 0.83225 | Accuracy: 70.53%\n",
            "Epoch: 4 | Mini-Batch: 268 | Loss: 0.71907 | Accuracy: 70.56%\n",
            "Epoch: 4 | Mini-Batch: 269 | Loss: 0.79149 | Accuracy: 70.58%\n",
            "Epoch: 4 | Mini-Batch: 270 | Loss: 0.91119 | Accuracy: 70.57%\n",
            "Epoch: 4 | Mini-Batch: 271 | Loss: 0.78805 | Accuracy: 70.56%\n",
            "Epoch: 4 | Mini-Batch: 272 | Loss: 0.87313 | Accuracy: 70.56%\n",
            "Epoch: 4 | Mini-Batch: 273 | Loss: 0.87749 | Accuracy: 70.58%\n",
            "Epoch: 4 | Mini-Batch: 274 | Loss: 0.68520 | Accuracy: 70.61%\n",
            "Epoch: 4 | Mini-Batch: 275 | Loss: 0.81543 | Accuracy: 70.60%\n",
            "Epoch: 4 | Mini-Batch: 276 | Loss: 0.84513 | Accuracy: 70.59%\n",
            "Epoch: 4 | Mini-Batch: 277 | Loss: 0.76483 | Accuracy: 70.62%\n",
            "Epoch: 4 | Mini-Batch: 278 | Loss: 0.76144 | Accuracy: 70.63%\n",
            "Epoch: 4 | Mini-Batch: 279 | Loss: 0.77481 | Accuracy: 70.64%\n",
            "Epoch: 4 | Mini-Batch: 280 | Loss: 0.81329 | Accuracy: 70.64%\n",
            "Epoch: 4 | Mini-Batch: 281 | Loss: 0.92430 | Accuracy: 70.63%\n",
            "Epoch: 4 | Mini-Batch: 282 | Loss: 0.83564 | Accuracy: 70.63%\n",
            "Epoch: 4 | Mini-Batch: 283 | Loss: 0.68169 | Accuracy: 70.65%\n",
            "Epoch: 4 | Mini-Batch: 284 | Loss: 1.01446 | Accuracy: 70.65%\n",
            "Epoch: 4 | Mini-Batch: 285 | Loss: 0.78232 | Accuracy: 70.66%\n",
            "Epoch: 4 | Mini-Batch: 286 | Loss: 0.77557 | Accuracy: 70.67%\n",
            "Epoch: 4 | Mini-Batch: 287 | Loss: 0.86708 | Accuracy: 70.68%\n",
            "Epoch: 4 | Mini-Batch: 288 | Loss: 0.62376 | Accuracy: 70.70%\n",
            "Epoch: 4 | Mini-Batch: 289 | Loss: 0.70884 | Accuracy: 70.72%\n",
            "Epoch: 4 | Mini-Batch: 290 | Loss: 0.75009 | Accuracy: 70.72%\n",
            "Epoch: 4 | Mini-Batch: 291 | Loss: 0.73625 | Accuracy: 70.73%\n",
            "Epoch: 4 | Mini-Batch: 292 | Loss: 0.87095 | Accuracy: 70.72%\n",
            "Epoch: 4 | Mini-Batch: 293 | Loss: 0.82793 | Accuracy: 70.71%\n",
            "Epoch: 4 | Mini-Batch: 294 | Loss: 0.79391 | Accuracy: 70.72%\n",
            "Epoch: 4 | Mini-Batch: 295 | Loss: 0.77244 | Accuracy: 70.73%\n",
            "Epoch: 4 | Mini-Batch: 296 | Loss: 0.73320 | Accuracy: 70.75%\n",
            "Epoch: 4 | Mini-Batch: 297 | Loss: 0.91536 | Accuracy: 70.73%\n",
            "Epoch: 4 | Mini-Batch: 298 | Loss: 0.75512 | Accuracy: 70.73%\n",
            "Epoch: 4 | Mini-Batch: 299 | Loss: 0.70276 | Accuracy: 70.74%\n",
            "Epoch: 4 | Mini-Batch: 300 | Loss: 0.73070 | Accuracy: 70.74%\n",
            "Epoch: 4 | Mini-Batch: 301 | Loss: 0.74707 | Accuracy: 70.75%\n",
            "Epoch: 4 | Mini-Batch: 302 | Loss: 0.83051 | Accuracy: 70.76%\n",
            "Epoch: 4 | Mini-Batch: 303 | Loss: 0.82575 | Accuracy: 70.75%\n",
            "Epoch: 4 | Mini-Batch: 304 | Loss: 0.71301 | Accuracy: 70.77%\n",
            "Epoch: 4 | Mini-Batch: 305 | Loss: 0.89587 | Accuracy: 70.78%\n",
            "Epoch: 4 | Mini-Batch: 306 | Loss: 0.96760 | Accuracy: 70.77%\n",
            "Epoch: 4 | Mini-Batch: 307 | Loss: 0.57445 | Accuracy: 70.81%\n",
            "Epoch: 4 | Mini-Batch: 308 | Loss: 0.84289 | Accuracy: 70.81%\n",
            "Epoch: 4 | Mini-Batch: 309 | Loss: 0.72903 | Accuracy: 70.82%\n",
            "Epoch: 4 | Mini-Batch: 310 | Loss: 0.65453 | Accuracy: 70.84%\n",
            "Epoch: 4 | Mini-Batch: 311 | Loss: 0.84467 | Accuracy: 70.84%\n",
            "Epoch: 4 | Mini-Batch: 312 | Loss: 0.71107 | Accuracy: 70.86%\n",
            "Epoch: 4 | Mini-Batch: 313 | Loss: 0.76274 | Accuracy: 70.86%\n",
            "Epoch: 4 | Mini-Batch: 314 | Loss: 0.60634 | Accuracy: 70.87%\n",
            "Epoch: 4 | Mini-Batch: 315 | Loss: 0.68324 | Accuracy: 70.88%\n",
            "Epoch: 4 | Mini-Batch: 316 | Loss: 0.85141 | Accuracy: 70.88%\n",
            "Epoch: 4 | Mini-Batch: 317 | Loss: 0.70727 | Accuracy: 70.90%\n",
            "Epoch: 4 | Mini-Batch: 318 | Loss: 0.76709 | Accuracy: 70.90%\n",
            "Epoch: 4 | Mini-Batch: 319 | Loss: 0.64348 | Accuracy: 70.93%\n",
            "Epoch: 4 | Mini-Batch: 320 | Loss: 0.90219 | Accuracy: 70.93%\n",
            "Epoch: 4 | Mini-Batch: 321 | Loss: 0.74818 | Accuracy: 70.94%\n",
            "Epoch: 4 | Mini-Batch: 322 | Loss: 0.56904 | Accuracy: 70.97%\n",
            "Epoch: 4 | Mini-Batch: 323 | Loss: 0.74967 | Accuracy: 70.98%\n",
            "Epoch: 4 | Mini-Batch: 324 | Loss: 0.63530 | Accuracy: 71.00%\n",
            "Epoch: 4 | Mini-Batch: 325 | Loss: 0.92946 | Accuracy: 70.98%\n",
            "Epoch: 4 | Mini-Batch: 326 | Loss: 0.79824 | Accuracy: 70.98%\n",
            "Epoch: 4 | Mini-Batch: 327 | Loss: 0.81944 | Accuracy: 70.98%\n",
            "Epoch: 4 | Mini-Batch: 328 | Loss: 0.98252 | Accuracy: 70.97%\n",
            "Epoch: 4 | Mini-Batch: 329 | Loss: 0.72929 | Accuracy: 70.98%\n",
            "Epoch: 4 | Mini-Batch: 330 | Loss: 0.65835 | Accuracy: 71.00%\n",
            "Epoch: 4 | Mini-Batch: 331 | Loss: 0.68713 | Accuracy: 71.02%\n",
            "Epoch: 4 | Mini-Batch: 332 | Loss: 0.84018 | Accuracy: 71.02%\n",
            "Epoch: 4 | Mini-Batch: 333 | Loss: 0.48735 | Accuracy: 71.06%\n",
            "Epoch: 4 | Mini-Batch: 334 | Loss: 0.80534 | Accuracy: 71.05%\n",
            "Epoch: 4 | Mini-Batch: 335 | Loss: 0.86065 | Accuracy: 71.05%\n",
            "Epoch: 4 | Mini-Batch: 336 | Loss: 0.84456 | Accuracy: 71.06%\n",
            "Epoch: 4 | Mini-Batch: 337 | Loss: 0.76580 | Accuracy: 71.07%\n",
            "Epoch: 4 | Mini-Batch: 338 | Loss: 0.80299 | Accuracy: 71.07%\n",
            "Epoch: 4 | Mini-Batch: 339 | Loss: 0.77783 | Accuracy: 71.07%\n",
            "Epoch: 4 | Mini-Batch: 340 | Loss: 0.58808 | Accuracy: 71.09%\n",
            "Epoch: 4 | Mini-Batch: 341 | Loss: 0.58959 | Accuracy: 71.11%\n",
            "Epoch: 4 | Mini-Batch: 342 | Loss: 0.89598 | Accuracy: 71.11%\n",
            "Epoch: 4 | Mini-Batch: 343 | Loss: 0.57910 | Accuracy: 71.13%\n",
            "Epoch: 4 | Mini-Batch: 344 | Loss: 0.69144 | Accuracy: 71.16%\n",
            "Epoch: 4 | Mini-Batch: 345 | Loss: 0.93697 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 346 | Loss: 0.71022 | Accuracy: 71.15%\n",
            "Epoch: 4 | Mini-Batch: 347 | Loss: 0.84641 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 348 | Loss: 0.86654 | Accuracy: 71.12%\n",
            "Epoch: 4 | Mini-Batch: 349 | Loss: 0.79042 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 350 | Loss: 0.82524 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 351 | Loss: 0.82785 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 352 | Loss: 0.83743 | Accuracy: 71.13%\n",
            "Epoch: 4 | Mini-Batch: 353 | Loss: 0.73854 | Accuracy: 71.14%\n",
            "Epoch: 4 | Mini-Batch: 354 | Loss: 0.75240 | Accuracy: 71.15%\n",
            "Epoch: 4 | Mini-Batch: 355 | Loss: 0.71640 | Accuracy: 71.16%\n",
            "Epoch: 4 | Mini-Batch: 356 | Loss: 0.80471 | Accuracy: 71.16%\n",
            "Epoch: 4 | Mini-Batch: 357 | Loss: 0.76371 | Accuracy: 71.16%\n",
            "Epoch: 4 | Mini-Batch: 358 | Loss: 0.70077 | Accuracy: 71.17%\n",
            "Epoch: 4 | Mini-Batch: 359 | Loss: 0.78020 | Accuracy: 71.18%\n",
            "Epoch: 4 | Mini-Batch: 360 | Loss: 0.66884 | Accuracy: 71.19%\n",
            "Epoch: 4 | Mini-Batch: 361 | Loss: 0.62866 | Accuracy: 71.21%\n",
            "Epoch: 4 | Mini-Batch: 362 | Loss: 0.89435 | Accuracy: 71.21%\n",
            "Epoch: 4 | Mini-Batch: 363 | Loss: 0.73182 | Accuracy: 71.21%\n",
            "Epoch: 4 | Mini-Batch: 364 | Loss: 0.67742 | Accuracy: 71.22%\n",
            "Epoch: 4 | Mini-Batch: 365 | Loss: 0.73106 | Accuracy: 71.22%\n",
            "Epoch: 4 | Mini-Batch: 366 | Loss: 0.78857 | Accuracy: 71.22%\n",
            "Epoch: 4 | Mini-Batch: 367 | Loss: 0.97144 | Accuracy: 71.21%\n",
            "Epoch: 4 | Mini-Batch: 368 | Loss: 0.60335 | Accuracy: 71.23%\n",
            "Epoch: 4 | Mini-Batch: 369 | Loss: 0.86576 | Accuracy: 71.23%\n",
            "Epoch: 4 | Mini-Batch: 370 | Loss: 0.82726 | Accuracy: 71.22%\n",
            "Epoch: 4 | Mini-Batch: 371 | Loss: 0.67154 | Accuracy: 71.23%\n",
            "Epoch: 4 | Mini-Batch: 372 | Loss: 0.60999 | Accuracy: 71.24%\n",
            "Epoch: 4 | Mini-Batch: 373 | Loss: 0.76377 | Accuracy: 71.25%\n",
            "Epoch: 4 | Mini-Batch: 374 | Loss: 0.75880 | Accuracy: 71.25%\n",
            "Epoch: 4 | Mini-Batch: 375 | Loss: 0.68677 | Accuracy: 71.25%\n",
            "Epoch: 4 | Mini-Batch: 376 | Loss: 0.69403 | Accuracy: 71.27%\n",
            "Epoch: 4 | Mini-Batch: 377 | Loss: 0.67095 | Accuracy: 71.28%\n",
            "Epoch: 4 | Mini-Batch: 378 | Loss: 0.72259 | Accuracy: 71.30%\n",
            "Epoch: 4 | Mini-Batch: 379 | Loss: 0.62922 | Accuracy: 71.32%\n",
            "Epoch: 4 | Mini-Batch: 380 | Loss: 0.91454 | Accuracy: 71.31%\n",
            "Epoch: 4 | Mini-Batch: 381 | Loss: 0.93658 | Accuracy: 71.29%\n",
            "Epoch: 4 | Mini-Batch: 382 | Loss: 0.80198 | Accuracy: 71.30%\n",
            "Epoch: 4 | Mini-Batch: 383 | Loss: 0.81882 | Accuracy: 71.30%\n",
            "Epoch: 4 | Mini-Batch: 384 | Loss: 0.86466 | Accuracy: 71.31%\n",
            "Epoch: 4 | Mini-Batch: 385 | Loss: 0.69243 | Accuracy: 71.32%\n",
            "Epoch: 4 | Mini-Batch: 386 | Loss: 0.79361 | Accuracy: 71.32%\n",
            "Epoch: 4 | Mini-Batch: 387 | Loss: 0.69717 | Accuracy: 71.33%\n",
            "Epoch: 4 | Mini-Batch: 388 | Loss: 0.86125 | Accuracy: 71.33%\n",
            "Epoch: 4 | Mini-Batch: 389 | Loss: 0.85579 | Accuracy: 71.33%\n",
            "Epoch: 4 | Mini-Batch: 390 | Loss: 1.07826 | Accuracy: 71.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0ES5MB3XXUs"
      },
      "source": [
        "**Note**: To score full points (10) for this section, ensure that:\n",
        "\n",
        "-- The train() function correctly creates the DataLoader for the CIFAR10 dataset.\n",
        "\n",
        "-- The training loop runs for 5 epochs and processes all minibatches.\n",
        "\n",
        "-- The model training is device-agnostic and runs on both CPU and GPU.\n",
        "\n",
        "-- The per-batch training loss and top-1 accuracy are calculated and printed for each minibatch.\n",
        "\n",
        "-- Proper usage of argparse to handle parameters like CUDA usage, data path,number of workers, and optimizer.\n",
        "\n",
        "-- The code is efficient and does not produce any errors during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGLQ2sVzNzUO"
      },
      "source": [
        "## C2: Time Measurement of code in C1 (10 points)\n",
        "\n",
        "Report the running time (by using `time.perf counter()` or other timers you are comfortable with) for the following sections of the code:\n",
        "\n",
        "\n",
        "**(C2.1)** Data-loading time for each epoch\n",
        "\n",
        "**(C2.2)** Training (i.e., mini-batch calculation) time for each epoch\n",
        "\n",
        "**(C2.3)** Total running time for each epoch.\n",
        "\n",
        "\n",
        "> **Note**: Data-loading time here is the time it takes to load batches from the generator (exclusive of the time it takes to move those batches to the device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_model_c2(model,\n",
        "          device,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          epochs,\n",
        "          root,\n",
        "          batch_size,\n",
        "          num_workers):\n",
        "\n",
        "    # Initialize the device\n",
        "    device = torch.device(device)\n",
        "    # Initialize the model\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    train_loader = get_dataset(train=True,\n",
        "                               root=root,\n",
        "                               batch_size=batch_size,\n",
        "                               num_workers=num_workers)\n",
        "    for epoch in range(epochs):\n",
        "        data_loading_time = 0\n",
        "        epoch_total_time = 0\n",
        "        total_training_time = 0\n",
        "        epoch_start_time = time.perf_counter()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        data_start_time = time.perf_counter()\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            data_end_time = time.perf_counter()\n",
        "            data_loading_time += data_end_time - data_start_time\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_start_time = time.perf_counter()\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_end_time = time.perf_counter()\n",
        "            train_time = train_end_time - train_start_time\n",
        "            total_training_time += train_time\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            data_start_time = time.perf_counter() # To reset the timer to calculate at the end of each epoch\n",
        "\n",
        "        epoch_end_time = time.perf_counter()\n",
        "        epoch_total_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "         # Print time calculations for each epoch\n",
        "        print(f'=== Epoch {epoch+1}/{epochs} Completed ===')\n",
        "        print(f'Data-loading time: {data_loading_time:.4f} seconds')\n",
        "        print(f'Training time: {total_training_time:.4f} seconds')\n",
        "        print(f'Total epoch time: {epoch_total_time:.4f} seconds\\n')"
      ],
      "metadata": {
        "id": "8neFpo9FsCwQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  parser = argparse.ArgumentParser(description=\"Arguments for the ResNet18 Model for CIFAR10 Dataset\")\n",
        "  parser.add_argument('--use_cuda', action='store_true', help='Use CUDA if available')\n",
        "  parser.add_argument('--data_path', default='./data', type=str, help='Path to CIFAR10 data')\n",
        "  parser.add_argument('--num_workers', default=2, type=int, help='Number of workers for DataLoader')\n",
        "  parser.add_argument('--optimizer', default='sgd', type=str, help='Optimizer to use: sgd or adam')\n",
        "  parser.add_argument('--batch_size', default=128, type=int, help='Batch size for DataLoader')\n",
        "  parser.add_argument('--epochs', default=5, type=int, help='Number of epochs to train the model')\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  device = torch.device('cuda' if args.use_cuda and torch.cuda.is_available() else 'cpu')\n",
        "  model = ResNet18()\n",
        "  if args.optimizer == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "  elif args.optimizer == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  train_model_c2(model=model,\n",
        "              device=device,\n",
        "              optimizer=optimizer,\n",
        "              criterion=nn.CrossEntropyLoss(),\n",
        "              epochs=args.epochs,\n",
        "              root=args.data_path,\n",
        "              batch_size=args.batch_size,\n",
        "              num_workers=args.num_workers)"
      ],
      "metadata": {
        "id": "PNIcmJaa6d9L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFXNsjcg6rra",
        "outputId": "8a3d1a47-76f2-41e1-a666-d6847864f9db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "=== Epoch 1/5 Completed ===\n",
            "Data-loading time: 19.1776 seconds\n",
            "Training time: 3.9397 seconds\n",
            "Total epoch time: 55.4738 seconds\n",
            "\n",
            "=== Epoch 2/5 Completed ===\n",
            "Data-loading time: 19.2848 seconds\n",
            "Training time: 3.9341 seconds\n",
            "Total epoch time: 55.5894 seconds\n",
            "\n",
            "=== Epoch 3/5 Completed ===\n",
            "Data-loading time: 19.1822 seconds\n",
            "Training time: 3.8720 seconds\n",
            "Total epoch time: 55.4793 seconds\n",
            "\n",
            "=== Epoch 4/5 Completed ===\n",
            "Data-loading time: 19.3739 seconds\n",
            "Training time: 3.9167 seconds\n",
            "Total epoch time: 55.6597 seconds\n",
            "\n",
            "=== Epoch 5/5 Completed ===\n",
            "Data-loading time: 19.3792 seconds\n",
            "Training time: 3.9356 seconds\n",
            "Total epoch time: 55.6727 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gEjBoqSYscz"
      },
      "source": [
        "Note: To score full points (10) for this section, ensure that:\n",
        "\n",
        "The time.perf_counter() (or equivalent) is correctly used to measure the following:\n",
        "\n",
        "    (C2.1) Data-loading time for each epoch.\n",
        "\n",
        "    (C2.2) Training (mini-batch computation) time for each epoch.\n",
        "\n",
        "    (C2.3) Total running time for each epoch.\n",
        "-- The times are accurately measured and printed for each epoch.\n",
        "\n",
        "-- Clear separation of data-loading and training times is maintained.\n",
        "\n",
        "-- Output of each timing section should be well-formatted and easy to read."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLXsO9Q7KjCb"
      },
      "source": [
        "## C3: I/O optimization for Code in C2 (10 points)\n",
        "\n",
        "**(C3.1)** Report the total time spent for the Dataloader varying the number of workers starting from zero and increment the number of workers by 4 (0,4,8,12,16...) until the I/O time does not decrease anymore.\n",
        "\n",
        "*Draw the results in a graph to illustrate the performance you are getting as you increase the number of workers*\n",
        "\n",
        "\n",
        "**(C3.2)** Report how many workers are needed for the best runtime performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_with_workers(model, device, optimizer, criterion, epochs, root, batch_size, threshold=0.01):\n",
        "    workers = []\n",
        "    data_loading_times = []\n",
        "\n",
        "    num_workers = 0\n",
        "    prev_loading_time = None\n",
        "\n",
        "    while True and num_workers<50:\n",
        "        print(f\"\\n=== Running Experiment with {num_workers} workers ===\")\n",
        "        data_loading_time = train_model_c3(\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            epochs=epochs,\n",
        "            root=root,\n",
        "            batch_size=batch_size,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "\n",
        "        workers.append(num_workers)\n",
        "        data_loading_times.append(data_loading_time)\n",
        "\n",
        "        # Check if we should stop based on the change in loading time\n",
        "        if prev_loading_time is not None:\n",
        "            if abs(prev_loading_time - data_loading_time) < threshold and num_workers>40:\n",
        "                print(f\"Stopping condition met. Data loading time change is less than {threshold:.2f} seconds.\")\n",
        "                break\n",
        "\n",
        "        prev_loading_time = data_loading_time\n",
        "        num_workers += 4\n",
        "\n",
        "    return workers, data_loading_times"
      ],
      "metadata": {
        "id": "m1xPNQ7WZey1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_c3(model,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   criterion,\n",
        "                   epochs,\n",
        "                   root,\n",
        "                   batch_size,\n",
        "                   num_workers):\n",
        "\n",
        "    # Initialize the model and move it to the device\n",
        "    device = torch.device(device)\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Load the data with the specified number of workers\n",
        "    train_loader = get_dataset(train=True,\n",
        "                               root=root,\n",
        "                               batch_size=batch_size,\n",
        "                               num_workers=num_workers)\n",
        "    data_time_epochs = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        total_data_loading_time = 0\n",
        "        data_start_time = time.perf_counter()\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            data_end_time = time.perf_counter()\n",
        "            total_data_loading_time += data_end_time - data_start_time\n",
        "            # Move inputs and targets to the device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Train as usual\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        data_time_epochs += total_data_loading_time\n",
        "    # Return total data-loading time for all epochs\n",
        "    avg_data_loading_time = data_time_epochs / epochs\n",
        "    print(f\"Average Data Loading Time with {num_workers} workers: {avg_data_loading_time:.4f} seconds\")\n",
        "    return avg_data_loading_time"
      ],
      "metadata": {
        "id": "Ol_bgArUZrce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call this function to run the experiment and gather results\n",
        "model=ResNet18()\n",
        "workers, data_loading_times = run_experiment_with_workers(\n",
        "    model=model,\n",
        "    device=\"cuda\",\n",
        "    optimizer=optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4),\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    epochs=1,\n",
        "    root='./data',\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(workers, data_loading_times, marker='o')\n",
        "plt.title(\"Effect of Number of Workers on Data-Loading Time\")\n",
        "plt.xlabel(\"Number of Workers\")\n",
        "plt.ylabel(\"Average Data-Loading Time (seconds)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PgbdY-RH_8X9",
        "outputId": "1105389c-4746-481d-a35b-46017c314135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Running Experiment with 0 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 0 workers: 7832.3202 seconds\n",
            "\n",
            "=== Running Experiment with 4 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 4 workers: 7826.3871 seconds\n",
            "\n",
            "=== Running Experiment with 8 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 8 workers: 7905.1169 seconds\n",
            "\n",
            "=== Running Experiment with 12 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 12 workers: 7789.8197 seconds\n",
            "\n",
            "=== Running Experiment with 16 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 16 workers: 7751.3910 seconds\n",
            "\n",
            "=== Running Experiment with 20 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 20 workers: 7766.5772 seconds\n",
            "\n",
            "=== Running Experiment with 24 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 24 workers: 7783.1881 seconds\n",
            "\n",
            "=== Running Experiment with 28 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 28 workers: 7748.6650 seconds\n",
            "\n",
            "=== Running Experiment with 32 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 32 workers: 7744.6372 seconds\n",
            "\n",
            "=== Running Experiment with 36 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 36 workers: 7769.9789 seconds\n",
            "\n",
            "=== Running Experiment with 40 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 40 workers: 7748.0113 seconds\n",
            "\n",
            "=== Running Experiment with 44 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 44 workers: 7744.2556 seconds\n",
            "\n",
            "=== Running Experiment with 48 workers ===\n",
            "Files already downloaded and verified\n",
            "Average Data Loading Time with 48 workers: 7754.6633 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we increase worker count by 4, the optimal count is at 4.\n",
        "\n",
        "However, on doing a sweep with worker count increasing by 1, the optimal worker count is 2."
      ],
      "metadata": {
        "id": "o9TxZvp2naQm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Us6m8kzY82G"
      },
      "source": [
        "Note: To score full points (10) for this section, ensure that:\n",
        "\n",
        "\n",
        "-- The train() function is modified to measure I/O time based on the number of workers.\n",
        "\n",
        "-- The number of workers is incremented by 4 (0, 4, 8, 12, 16, etc.) until no further I/O time reduction is observed.\n",
        "\n",
        "-- DataLoader times for each worker configuration are recorded and stored.\n",
        "\n",
        "-- A graph is plotted showing the number of workers vs. I/O times.\n",
        "\n",
        "--The number of workers that gives the best runtime performance is correctly identified and reported.\n",
        "\n",
        "-- Ensure that the code runs efficiently with varying numbers of workers and provides accurate performance insights."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "6TPNYgMgdbMI",
        "KPY718AHg-er",
        "7c6274ce-a622-4735-bad6-d82c38a73398"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}